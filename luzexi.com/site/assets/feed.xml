<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title></title>
        <description>技术，哲学，金融</description>
        <link>http://www.luzexi.com</link>
        <atom:link href="http://www.luzexi.com/assets/feed.xml" rel="self" type="application/rss+xml" />
        
            <item>
               <title>改造jekyll 为iframe框架的博客内容</title>
               <description>
&lt;div class=&quot;static_post&quot;&gt;
&lt;iframe src=&quot;/static-page/post-2021-02-10/改造jekyll 为iframe框架的博客内容.html&quot; width=&quot;100%&quot; height=&quot;100%&quot;&gt; &lt;/iframe&gt;
&lt;/div&gt;

</description>
               <pubDate>Wed, 10 Feb 2021 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2021/02/10/%E6%94%B9%E9%80%A0jekyll%E4%B8%BAiframe%E6%A1%86%E6%9E%B6%E7%9A%84%E5%8D%9A%E5%AE%A2%E5%86%85%E5%AE%B9</link>
               <guid isPermaLink="true">http://www.luzexi.com/2021/02/10/%E6%94%B9%E9%80%A0jekyll%E4%B8%BAiframe%E6%A1%86%E6%9E%B6%E7%9A%84%E5%8D%9A%E5%AE%A2%E5%86%85%E5%AE%B9</guid>
            </item>
        
            <item>
               <title>思路探讨(五十五) 第一性原理</title>
               <description>&lt;p&gt;最近越来越经常写文章但很少发出来（基本都是每周一篇总结 + 每日一篇自我反省的文章），没能分享到博客的原因第一是写的文章有些是属于公司保密级的，不能发布在博客上，甚至有几篇文章完全不能脱敏。第二是自己写的向内看系列的内容，真的越来越向内看越来越私密，由于太私密触及内心的兴奋与失落，起伏过大所以也不好拿出来跟大家分享。&lt;/p&gt;

&lt;p&gt;​在公众号中，我秉持着开放的态度与自己对话，也常与朋友和同事们聊聊自己的想法。
希望能从不同的角度来看待事物，也希望能从各个方向上来改善自己做人做事的态度。&lt;/p&gt;

&lt;p&gt;由于年底事情特别多，也特别繁杂，因此只能将有限的精力用在照顾自己的工作和学习进度。在此跟大家说声抱歉。
2021年会继续跟大家分享我的所思所想，以及公开自己的所学所为。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;前面听过第一性原理的概念，但没有了解的很清楚，在放假回老家最后一天突然兴致勃勃的看了，张善友教授讲的第一性原理的视频。&lt;/p&gt;

&lt;p&gt;感觉讲的很不错，也契合我一直以来秉持的理念，在听了他所讲的内容后，对这块理念更加深刻。&lt;/p&gt;

&lt;p&gt;什么是第一性原理？
第一性原理，事物背后的不变的理念(原理)，根据这个原理可以推出所有的其他东西出来。这个理念就叫第一性原理。&lt;/p&gt;

&lt;p&gt;第一性原理是事物的本质、本性，是事物背后支配性的理念，而不是现象层面流变的物质。一旦在逻辑上导通一个共同的抽象概念，与此相关的所有具象问题，立即全部化解。&lt;/p&gt;

&lt;p&gt;随着我们年龄增大，接触的事情越来越复杂，处理这件复杂的事物需要花费的精力也通常越来越复杂。
第一性原理告诉我们，越高深的事物，底层理念越简约，其原理通常具有简一性，即简约和单纯。
找到第一性原理，就像是找到了支配事物运动的发动机。&lt;/p&gt;

&lt;p&gt;计算机程序执行原理、操作系统内核原理，对于每个编程的人来说都是第一性原理。为技术人拓展更扎实的编程思路提供了底层支撑。
抽象能力是软件架构设计的第一性原理。为技术人拓展更简洁实用的架构能力提供了底层支撑。
尊严与诚信是人在社会生存是第一性原理。为社会人拓展生活和工作中的方方面面提供了支撑。
能量守恒是宇宙的第一性原理。为物理、化学的研究工作提供了支撑。等等等&lt;/p&gt;

&lt;p&gt;人们常说，道理说的很好，但听过就忘了。显然大多数人都没有将人生的底层原理铭刻在心中，时刻忘记遵守事物的本质规律，也时常不得不在所谓的现实面前妥协。&lt;/p&gt;

&lt;p&gt;你找到生活中的真正的第一性原理了吗？
当第一性原理（事物的本质）和现象冲突的时候，你选择了什么？&lt;/p&gt;

&lt;p&gt;每个你的选择都决定了你今后的道路，你是坚持本质还是妥协现象，N个选择积累后，最终成为了今天的你。&lt;/p&gt;

&lt;p&gt;当然我们也需要注意下，第一性原理不是绝对真理，虽然事物的本质和原理适用于每个人，但对于每个人来说都需要有不同方式去执行。​&lt;/p&gt;

</description>
               <pubDate>Tue, 09 Feb 2021 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2021/02/09/%E6%80%9D%E8%B7%AF%E6%8E%A2%E8%AE%A855</link>
               <guid isPermaLink="true">http://www.luzexi.com/2021/02/09/%E6%80%9D%E8%B7%AF%E6%8E%A2%E8%AE%A855</guid>
            </item>
        
            <item>
               <title>向内看自己(十二) 精力训练</title>
               <description>&lt;p&gt;健身一整年的体会与变化，精力训练的一整年。&lt;/p&gt;

&lt;p&gt;体会 + 对策 + 图 + 视频&lt;/p&gt;

&lt;h2 id=&quot;点击查看内容&quot;&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/PkEWsEOxpRmdIm8AdV2OPA&quot;&gt;点击查看内容&lt;/a&gt;&lt;/h2&gt;

</description>
               <pubDate>Sun, 24 Jan 2021 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2021/01/24/%E5%90%91%E5%86%85%E7%9C%8B%E8%87%AA%E5%B7%B112</link>
               <guid isPermaLink="true">http://www.luzexi.com/2021/01/24/%E5%90%91%E5%86%85%E7%9C%8B%E8%87%AA%E5%B7%B112</guid>
            </item>
        
            <item>
               <title>向内看自己(十一) 底层能力和核心</title>
               <description>&lt;p&gt;最近一直在学习技术，由于几篇文章是跟项目有关的所以得脱敏后才能发。由于技术聊的太多，感觉自己脑袋闭塞了，这篇我想聊聊别的，可能有点乱。&lt;/p&gt;

&lt;p&gt;最近有点苦闷。&lt;/p&gt;

&lt;p&gt;又到了，阶段性怀疑人生的时刻。&lt;/p&gt;

&lt;p&gt;工作上的、生活上的、学习上的都有一些。&lt;/p&gt;

&lt;p&gt;最近接触了些自己以前没有接触过的东西，包括，冥想，专注练习，分析和整理的方法，这些可以说是以前没有在意的东西。&lt;/p&gt;

&lt;p&gt;在我看了《十分钟冥想》、《心流》、《金字塔原理》这三本书后，发现书中的这些方法在我们生活中特别重要。&lt;/p&gt;

&lt;p&gt;于是我开始学习冥想、学习如何保持专注、学习整理和分析知识和经验的方法，但收效甚微。&lt;/p&gt;

&lt;p&gt;由于开始注重自己的心境、自己的专注力、自己的分析方法，发现自己在这方面能力值好低，瓶颈好大，思路狭窄。&lt;/p&gt;

&lt;p&gt;以前并没有这么觉得，因为我没有注重这些技巧的运用，都是猛打猛冲的在向前进发。&lt;/p&gt;

&lt;p&gt;看了大师们的解说，再自己去试行，才发现好难。&lt;/p&gt;

&lt;p&gt;所以挫败感很强烈。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;做这些目的是想把自己的底层能力巩固一下，没想到的是原来自己的底层能力这么差。&lt;/p&gt;

&lt;p&gt;为什么要去打造底层能力这个问题，也是我从健身中感悟到。&lt;/p&gt;

&lt;p&gt;在一开始健身的时候，会无脑的去跑步、去跳操，一段时间后接触了固定器械健身，以及固定肌肉部位的健身，觉得这样的效率会更高，于是开始了固定肌肉和器械的健身方式，过了一段时间，但这导致了我的核心没有被训练到，肌肉是上来了，但核心没有变强，腿部、腹部、身体的整个平衡能力，耐力，都没有变强。&lt;/p&gt;

&lt;p&gt;只是改善了外观，增加了肌肉，降低了体脂，但核心体魄上完全没有变化，甚至变的更弱了。&lt;/p&gt;

&lt;p&gt;没有抓住核心导致我虽然外观改善了，但内在却没有改善。&lt;/p&gt;

&lt;p&gt;这也是我为什么要执著于打造底层能力的原因。&lt;/p&gt;

&lt;p&gt;万事万物都要是一个道理，万事万物都要是一个道理，要抓住核心。&lt;/p&gt;

&lt;p&gt;写程序、做游戏的道理也是一样，做游戏要先做核心战斗，有了核心战斗，周边的功能开发才有意义。
写程序也是一个道理，理解底层原理，熟悉底层机制，去实践底层逻辑，核心的组件做出来，围绕核心做业务才会更稳，否则就像豆腐渣工程很容易倒塌，底层不牢固。（其实每个模块有核心，先做核心，再做周边是比较好的顺序）&lt;/p&gt;

&lt;p&gt;延展到生活中也是如此，核心我认为除了工作外的生活中核心是家庭，我们应该把重心放在家庭上，而家庭中，成员之间的的默契程度是核心，因此我们要团结友爱，互帮互助，分工合作来努力让这个核心更加稳固。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;这个世界证明了未来总是不可预测的，历史总是固定并有理有据的。&lt;/p&gt;

&lt;p&gt;我们常去预测未来，认为根据历史经验就能知道未来，认为至少知道个大概。&lt;/p&gt;

&lt;p&gt;不要去预测未来，我们大部分人都不肯接受不确定性，有些人希望能控制未来，那更是不可能。&lt;/p&gt;

&lt;p&gt;我们能做只能是尝试去稳定未来的发展方向，至于未来到底会发生什么，我们完全控制不了。&lt;/p&gt;

&lt;p&gt;我们能控制的只有自己，做好自己该做的事情，不断完善自己，完善底层能力，再在自己能力范围内尽可能照顾好周围的人。&lt;/p&gt;

&lt;p&gt;至于那些我们不能控制的未来，永远都会让我们焦虑，并借此扰乱我们的心智。&lt;/p&gt;
</description>
               <pubDate>Sat, 23 Jan 2021 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2021/01/23/%E5%90%91%E5%86%85%E7%9C%8B%E8%87%AA%E5%B7%B111</link>
               <guid isPermaLink="true">http://www.luzexi.com/2021/01/23/%E5%90%91%E5%86%85%E7%9C%8B%E8%87%AA%E5%B7%B111</guid>
            </item>
        
            <item>
               <title>Perfetto内存工具分析</title>
               <description>&lt;p&gt;用Markdown在贴图方面不是很方便，于是用印象笔记写了篇文章，尝试一下新的方式。&lt;/p&gt;

&lt;p&gt;我越来越觉得图对理解的重要性，所以想把更多文字转为以图文结合的方式表达，这样会更加清晰一些，也更易于理解。&lt;/p&gt;

&lt;p&gt;后面会更多的尝试用这样方式来写文章，即，用印象笔记写完后，导出html放在博客上。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/static-page/Perfetto/Index/Perfetto内存工具分析.html&quot;&gt;点击查看文章内容&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;static_post&quot;&gt;
&lt;iframe src=&quot;/static-page/Perfetto/Index/Perfetto内存工具分析.html&quot; width=&quot;100%&quot; height=&quot;100%&quot;&gt; &lt;/iframe&gt;
&lt;/div&gt;

</description>
               <pubDate>Wed, 20 Jan 2021 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2021/01/20/Perfetto%E5%86%85%E5%AD%98%E5%B7%A5%E5%85%B7%E5%88%86%E6%9E%90</link>
               <guid isPermaLink="true">http://www.luzexi.com/2021/01/20/Perfetto%E5%86%85%E5%AD%98%E5%B7%A5%E5%85%B7%E5%88%86%E6%9E%90</guid>
            </item>
        
            <item>
               <title>读书笔记(十八) 《C++性能优化指南》三</title>
               <description>&lt;p&gt;此篇主要介绍热点代码、I/O、以及并行部分的优化，我们会从原理出发来，再根据原理讲优化，这样即学习了原理，又知道了优化的来龙去脉。&lt;/p&gt;

&lt;h2 id=&quot;热点代码&quot;&gt;热点代码&lt;/h2&gt;

&lt;p&gt;这里作者带我们聊一聊关于代码细节的优化，虽然语句的细节优化并不能带来非常明显的提升，但是也是非常有必要的优化步骤，尤其在那些追求极致高性能或精小的组件中，代码细节的优化决定了组件与组件之间的差异。&lt;/p&gt;

&lt;p&gt;语句细节的优化，其实质是对CPU指令的优化，可以认为是从执行指令流中移除指令的过程。下面先来阐述一下细节优化的原理。&lt;/p&gt;

&lt;h3 id=&quot;语句的细节优化其实质是执行指令数量的优化指令跳转次数的优化向栈中保存临时寄存器次数的优化以及内存分配次数的优化&quot;&gt;语句的细节优化，其实质是执行指令数量的优化，指令跳转次数的优化，向栈中保存临时寄存器次数的优化，以及内存分配次数的优化。&lt;/h3&gt;

&lt;p&gt;执行指令数量减少了可以减少CPU在执行程序时的耗时我们很好理解，指令跳转则是因为指令也是被放在内存中的数据，因此它也会被高速缓存cache，长距离跳转会让高速缓存失效，静态函数调用和非成员函数调用通常都是长距离指令跳转的典型案例。&lt;/p&gt;

&lt;p&gt;函数调用开销不可忽视，即使一个空函数，在调用时也会有性能开销（编译器可能会帮我们优化掉空函数），有时为了极致的优化，我们应该最大限度的减少调用函数的频率，特别是频率最高的top3。&lt;/p&gt;

&lt;p&gt;因为在函数被调用时会保存当前函数的数据，包括参数、局部变量、当前指令地址、临时寄存器和标记寄存器等，每次调用一个函数会做如下处理：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;	1.当调用函数时，先保存当前函数的临时变量、参数、临时寄存器、标记寄存器。
	
	2.将这些每个要保存的数据都复制到栈中。
	
	3.当前执行的地址复制到栈中。

	4.将指令指针寄存器IP指向要执行的函数体的第一句

	5.执行函数体中的指令

	6.将函数调用结果保存到寄存器

	7.从栈中推出要返回的地址，并复制给指令寄存器IP

	8.推出栈中的临时寄存器、参数、局部变量、标记寄存器都重新还原回去

	9.继续执行剩下的指令直到遇到下一个函数。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果遇到成员函数是虚函数的，还得先从虚表中偏移并取出函数地址再调用，这里又多了2次计算，即先取出虚表地址、再根据虚表地址偏移获得真正的函数地址、最后再才能跳转过去。如果是多重继承、或者是多重继承的继承类中的虚函数成员，则需要再加一次地址偏移计算。&lt;/p&gt;

&lt;p&gt;inline内联是减少函数调用的最佳方式，内联函数并不像一般函数那样会保存数据并且跳转指令，因为编译器会就地展开内联函数中的指令，因此没有推栈入栈保存数据到栈和跳转指令到函数再返回的步骤，取而代之的是就地直接执行指令。&lt;/p&gt;

&lt;p&gt;这样看来减少函数调用(或让函数内联)的同时也减少了入栈、出栈、复制数据的指令数量，也减少了指令跳转的丢失高速缓存的概率。&lt;/p&gt;

&lt;p&gt;不必要的内存分配也是在代码细节中常犯的错误，尤其指向堆内存分配，当函数中需要某个容器或者类实例时，常会临时向堆内存申请一次以用来计算。&lt;/p&gt;

&lt;p&gt;我们来看看以上这说的7个细节的具体例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
for(int i = 0 ; i&amp;lt;strlen(str) ; i++)
	...

//改为

for(int i = 0, n = strlen(str) ; i&amp;lt;n ; i++)
	...

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1.将重复计算提到前面，但这里不一定有优化，因为编译器可能会识别这类循环并将实时计算移出去，不过不能保证编译器一定会这么干，所以我们最好做人为的优化，保证不重复计算。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
void function()
{
	list = new list();
	for(int i = 0 ; i&amp;lt;n ; i++)
	{
		list.Add(xx);
	}

	return;
}

//改为

public static list = new list(); //改为全局变量

void function()
{
	list.Clear();
	for(int i = 0 ; i&amp;lt;n ; i++)
	{
		list.Add(xx);
	}

	return;
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.函数中临时的堆内存分配，改为全局的共用内存，只要分配一次，每次使用前先清理就能节省开销。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
int k = 0;
for(int i = 0 ; i&amp;lt;100 ; i++)
{
	int j = sin(100) + cos(50);
	k = j*i;
}

//改为

int k = 0;
int j = sin(100) + cos(5);
for(int i = 0 ; i&amp;lt;100 ; i++)
{
	k = j*i;
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.移除循环中不变的计算，减少不必要的指令，可能会被编译器优化掉。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;for(int i = 0 ; i&amp;lt;10 ; i++)
{
	int b = Add(3,5);
	...
}

//改为

int b = 0
for(int i = 0 ; i&amp;lt;10 ; i++)
{
	b = 3 + 5;
	...
}

//或者将Add函数内联

inline int Add(a,b)
{
	...
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4.用内联或者手动内联的方式，减少循环中的函数调用开销。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
string str = &quot;a&quot;;

str = &quot;&amp;lt;p&amp;gt;&quot; + str + &quot;&amp;lt;/p&amp;gt;&quot;;

//改为

str = string.format(&quot;&amp;lt;p&amp;gt;{0}&amp;lt;/p&amp;gt;&quot;,str);

//或者

str = StringCacheMgr.instance.Format(&quot;&amp;lt;p&amp;gt;{0}&amp;lt;/p&amp;gt;&quot;,str);

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5.减少字符串内存分配次数，将原来要分配两次的字符串，改为只要分配1次。或者使用自制的字符串内存管理方式管理分配和操作字符串(前面的内存优化那一节我们讲过这种方式)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
for(int i = 0 ; i&amp;lt;1000 ; i++)
{
	test();
}

//改为

test();

void test()
{
	for(int i = 0 ; i&amp;lt;1000 ;i++)
	{
		...
	}
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;6.将1000次调用函数的开销改为1次，节省函数调用的开销。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
if(x == a)
{
	...
}
else if(xx == a)
{
	...
}
else if(xxx == a)
{
	...
}
else ...

//改为

switch(a)
{
	case x:
		break;
	case xx:
		break;
	case xxx:
		break;
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;7.通常switch都会被编译器优化为索引的方式去跳转，因此用switch比if效率高的多，也不用我们自己对数据排序。&lt;/p&gt;

&lt;p&gt;最后说下异常try catch的开销，在早期C++的try catch机制会在栈帧上包含一个异常上下文，这些上下文会随着异常抛出或者作用范围结束而销毁，增加性能开销。现在则不同了，上下文开销都没有了，只是会在开始try时多几个指令更改中断程序的指向，退出时再改回来，但是即使这样，我们也不能有太多try catch，因为try catch太多仍然会多出很多额外的指令消耗。&lt;/p&gt;

&lt;h3 id=&quot;我们做个小结我们说语句的细节优化实质是减少执行指令数量减少指令跳转次数减少函数调用以及减少内存分配次数我们用代码细节来解释有哪些细节是可以遵从我们的原理来优化的这些细节的优化在性能要求比较高的组件上会比较有用好的代码细节是业务逻辑优化的前提业务逻辑上当我们更多运用的是调整实现方式调整数据结构的方式调整业务逻辑策略的方式时这些细节的优化则成了底层的支柱&quot;&gt;我们做个小结，我们说语句的细节优化，实质是减少执行指令数量，减少指令跳转次数，减少函数调用，以及减少内存分配次数。我们用代码细节来解释有哪些细节是可以遵从我们的原理来优化的，这些细节的优化，在性能要求比较高的组件上会比较有用，好的代码细节是业务逻辑优化的前提。业务逻辑上，当我们更多运用的是调整实现方式，调整数据结构的方式，调整业务逻辑策略的方式时，这些细节的优化则成了底层的支柱。&lt;/h3&gt;

&lt;h2 id=&quot;io-文件操作&quot;&gt;I/O 文件操作&lt;/h2&gt;

&lt;h3 id=&quot;io操作的优化空间相对比较小是因为它主要的工作大部分由操作系统完成因此我们先介绍下操作系统中io的读写原理再从原理出发优化io操作效率包括降低读写次数减少读取时间和优化体验俩个方面&quot;&gt;I/O操作的优化空间相对比较小，是因为它主要的工作大部分由操作系统完成。因此我们先介绍下操作系统中I/O的读写原理，再从原理出发优化I/O操作效率，包括降低读写次数减少读取时间和优化体验俩个方面。&lt;/h3&gt;

&lt;p&gt;操作系统中为了分割操作内容让调用更安全，分为‘用户态’和‘内核态’，当用户态需要内核态工作时我们称为‘系统调用’，我们平常写的程序只要不涉及系统调用的都是用户态完成的，一旦涉及到需要操作系统工作的部分，就要先切到内核态完成工作，结束后再切回用户态继续执行后面的程序，这个切换的过程是比较费时费力的，I/O调用就是其中一种需要切换内核态的系统调用。&lt;/p&gt;

&lt;p&gt;操作系统可以支持多种底层不同的文件系统（比如NTFS, FAT, ext3, ext4），为了给内核和用户进程提供统一的文件系统视图，Linux在用户进程和底层文件系统之间加入了一个抽象层，即虚拟文件系统(Virtual File System, VFS)，进程所有的文件操作都通过VFS，由VFS来适配各种底层不同的文件系统，完成实际的文件操作。&lt;/p&gt;

&lt;h3 id=&quot;这里我们来了解下虚拟文件系统构成和主要模块&quot;&gt;这里我们来了解下虚拟文件系统构成和主要模块：&lt;/h3&gt;

&lt;h3 id=&quot;超级块super_block&quot;&gt;超级块（super_block）&lt;/h3&gt;

&lt;p&gt;用于保存一个文件系统的所有元数据，相当于这个文件系统的信息库，为其他的模块提供信息。&lt;/p&gt;

&lt;p&gt;因此一个超级块可代表一个文件系统，文件系统的任意元数据修改都要通过超级块修改，超级块对象是常驻内存并被缓存起来的。&lt;/p&gt;

&lt;h3 id=&quot;目录项模块&quot;&gt;目录项模块&lt;/h3&gt;

&lt;p&gt;是管理路径的目录项，比如一个路径 /home/foo/hello.txt，那么目录项有home, foo, hello.txt三个。&lt;/p&gt;

&lt;p&gt;每个目录项的块，存储的是这个目录下的所有的文件的inode号和文件名等信息。其内部是树形结构，操作系统检索一个文件是从根目录开始，按层次解析路径中的所有目录，直到定位到具体文件。&lt;/p&gt;

&lt;h3 id=&quot;inode模块&quot;&gt;inode模块&lt;/h3&gt;

&lt;p&gt;管理的是一个具体的文件，是文件的唯一标识，一个文件对应一个inode。&lt;/p&gt;

&lt;p&gt;通过inode可以方便的找到文件在磁盘扇区的位置，同时inode模块可链接到address_space模块，方便查找自身文件数据是否已经被缓存在内存中。&lt;/p&gt;

&lt;h3 id=&quot;打开文件列表模块&quot;&gt;打开文件列表模块&lt;/h3&gt;

&lt;p&gt;包含所有内核已经打开的文件，已经打开的文件对象由open系统调用在内核中创建，也叫文件句柄。&lt;/p&gt;

&lt;p&gt;打开文件列表模块中包含一个列表，列表表项是一个结构体struct file，结构体中的信息存储了打开的一个文件的各种状态参数。&lt;/p&gt;

&lt;h3 id=&quot;file_operations模块&quot;&gt;file_operations模块&lt;/h3&gt;

&lt;p&gt;模块中维护一个数据结构，是一系列函数指针的集合，其中包含所有可以使用的系统调用函数，例如open、read、write、mmap等。&lt;/p&gt;

&lt;p&gt;每个打开文件（打开文件列表模块的一个表项）都可以连接到file_operations模块，从而对任何已打开的文件，通过系统调用函数，实现各种操作。&lt;/p&gt;

&lt;h3 id=&quot;address_space模块&quot;&gt;address_space模块&lt;/h3&gt;

&lt;p&gt;记录了文件在页缓存中已经缓存了的物理页信息，是页缓存和外部设备中文件系统的桥梁。如果将文件系统可以理解成数据源，内存中的页缓存是已经读取的内容，那么address_space可以说是内存系统和文件系统的中间层。&lt;/p&gt;

&lt;h3 id=&quot;所有文件信息保存在超级块中通过目录项模块找到文件所在位置所有被打开的文件放在文件列表模块中file_operations模块负责操作文件每个文件都有唯一标识inode磁盘数据与内存缓存通过address_space联接与映射&quot;&gt;所有文件信息保存在超级块中，通过目录项模块找到文件所在位置，所有被打开的文件放在文件列表模块中，file_operations模块负责操作文件，每个文件都有唯一标识inode，磁盘数据与内存缓存通过address_space联接与映射。&lt;/h3&gt;

&lt;h3 id=&quot;下面我们来看看读写入文件时的基本流程&quot;&gt;下面我们来看看读写入文件时的基本流程：&lt;/h3&gt;

&lt;h3 id=&quot;读文件&quot;&gt;读文件&lt;/h3&gt;

&lt;p&gt;1、进程调用库函数向内核发起读文件请求；&lt;/p&gt;

&lt;p&gt;2、内核通过检查进程的文件描述符定位到虚拟文件系统的已打开文件列表表项；&lt;/p&gt;

&lt;p&gt;3、调用该文件可用的系统调用函数read()&lt;/p&gt;

&lt;p&gt;read()函数通过文件表项链接到目录项模块，根据传入的文件路径，在目录项模块中检索，找到该文件的inode；&lt;/p&gt;

&lt;p&gt;4、在inode中，通过文件内容偏移量计算出要读取的页；&lt;/p&gt;

&lt;p&gt;5、通过inode找到文件对应的address_space；&lt;/p&gt;

&lt;p&gt;6、在address_space中访问该文件的页缓存树，查找对应的页缓存结点：&lt;/p&gt;

&lt;p&gt;（1）如果页缓存命中，那么直接返回文件内容；&lt;/p&gt;

&lt;p&gt;（2）如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过inode找到文件该页的磁盘地址，读取相应的页填充该缓存页；重新进行第6步查找页缓存；&lt;/p&gt;

&lt;p&gt;7、文件内容读取成功。&lt;/p&gt;

&lt;h3 id=&quot;写文件&quot;&gt;写文件&lt;/h3&gt;

&lt;p&gt;前5步和读文件一致，在address_space中查询对应页的页缓存是否存在：&lt;/p&gt;

&lt;p&gt;6、如果页缓存命中，直接把文件内容修改更新在页缓存的页中。写文件就结束了。这时候文件修改位于页缓存，并没有写回到磁盘文件中去。&lt;/p&gt;

&lt;p&gt;7、如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过inode找到文件该页的磁盘地址，读取相应的页填充该缓存页。此时缓存页命中，进行第6步。&lt;/p&gt;

&lt;p&gt;8、一个页缓存中的页如果被修改，那么会被标记成脏页。脏页需要写回到磁盘中的文件块。有两种方式可以把脏页写回磁盘：&lt;/p&gt;

&lt;p&gt;（1）手动调用sync()或者fsync()系统调用把脏页写回&lt;/p&gt;

&lt;p&gt;（2）pdflush进程会定时把脏页写回到磁盘&lt;/p&gt;

&lt;p&gt;同时注意，脏页不能被置换出内存，如果脏页正在被写回，那么会被设置写回标记，这时候该页就被上锁，其他写请求被阻塞直到锁释放。&lt;/p&gt;

&lt;h3 id=&quot;页缓存实际上就是一个基数树结构它将一个文件的内容组织起来存放在struct-page结构中文件越大树形结构越庞大每一页都记录着文件内容的页信息和缓存信息&quot;&gt;页缓存实际上就是一个基数树结构，它将一个文件的内容组织起来存放在struct page结构中，文件越大树形结构越庞大，每一页都记录着文件内容的页信息和缓存信息。&lt;/h3&gt;

&lt;p&gt;另外内核使用task_struct来表示单个进程的描述符，其中包含维护一个进程的所有信息。task_struct结构体中维护了一个 files的指针（和“已打开文件列表”上的表项是不同的指针）来指向结构体files_struct，files_struct中包含文件描述符表和打开的文件对象信息，这使得系统能够：&lt;/p&gt;

&lt;p&gt;1、多个进程可以同时指向一个打开文件对象（文件列表表项）。&lt;/p&gt;

&lt;p&gt;2、一个进程可以多次打开一个文件，生成不同的文件描述符，每个文件描述符指向不同的文件列表表项。但是由于是同一个文件，inode唯一，所以这些文件列表表项都指向同一个inode。&lt;/p&gt;

&lt;h3 id=&quot;我们知道了文件的读写原理再来看看我们在平时编写文件操作时的优化思路&quot;&gt;我们知道了文件的读写原理再来看看我们在平时编写文件操作时的优化思路。&lt;/h3&gt;

&lt;p&gt;1.减少读写次数，减少读写时间。&lt;/p&gt;

&lt;p&gt;由于每次读取文件内容都会从用户态转到内核态，完成后再切回来，这种切换的消耗是比较重的，因此我们应该尽量减少读写次数。&lt;/p&gt;

&lt;p&gt;在读取一个文件时，尽量将需要的内容一次性读取完毕，甚至可以预先读取未来的内容，以避免多次读取。在写文件时也是同样，尽量一次性写入硬盘，避免多次写入。例如下面代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
while(getline(file,line))
{
	doSomeThing(line);
}

//改为

lines = getlines(file);

for(int i = 0 ,n = len(lines) ; i&amp;lt; n ; ++i)
{
	doSomeThing(lines[i]);
}

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;一次性读取所有行再对每行做处理&quot;&gt;一次性读取所有行，再对每行做处理。&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
void write_lines(std::ostream&amp;amp; file std::string const&amp;amp; lines[])
{
	for(int i = 0,n = len(lines) ; i&amp;lt;n ; ++i)
	{
		file &amp;lt;&amp;lt; lines[i]
		file-&amp;gt;flush();
	}
}

//改为

void write_lines(std::ostream&amp;amp; file std::string const&amp;amp; lines[])
{
	for(int i = 0,n = len(lines) ; i&amp;lt;n ; ++i)
	{
		file &amp;lt;&amp;lt; lines[i];
	}
	file-&amp;gt;flush();
}

//或用内存池的方式改为

void write_lines(std::ostream&amp;amp; file std::string const&amp;amp; lines[])
{
	int str_size = 0;
	for(int i = 0,n = len(lines) ; i&amp;lt;n ; ++i)
	{
		str_size += len(lines[i] + 1)*sizeof(char);
	}
	
	byte[] data = MemoryPool.instance.AllocMemory(str_size);

	CombineStringData(lines, data); //将lines中的数据都拷贝到data中

	file-&amp;gt;write(data);
	file-&amp;gt;flush();

	MemoryPool.instance.Free(data);
}

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;每次写入文件时系统并不会立即写入文件而是存放在页缓存如果我们每次刷新则会每次都同步到硬盘写入硬盘速度比较内存慢很多会消耗比较长时间所以要减少刷新调用次数&quot;&gt;每次写入文件时系统并不会立即写入文件，而是存放在页缓存，如果我们每次刷新，则会每次都同步到硬盘，写入硬盘速度比较内存慢很多，会消耗比较长时间，所以要减少刷新调用次数。&lt;/h3&gt;

&lt;h3 id=&quot;只是减少刷新次数但依然减少不了内核态切换的次数于是我们用内存池的方式减少内存分配的时间将内存分配的耗时降低将原本要调用很多次系统调用的次数降低为了一次从而减少了内核态切换的次数&quot;&gt;只是减少刷新次数，但依然减少不了内核态切换的次数。于是我们用内存池的方式减少内存分配的时间，将内存分配的耗时降低，将原本要调用很多次系统调用的次数降低为了一次，从而减少了内核态切换的次数。&lt;/h3&gt;

&lt;p&gt;2.优化体验&lt;/p&gt;

&lt;p&gt;用阻塞读取的方式，由于线程要等待磁盘设备的工作，对于整个程序的效率来说是比较低的，因为硬盘设备读写的速度比较慢，主线程要等待硬盘设备工作完毕后才进行后面的工作。因此为了能让程序的整体效率提升，我们可以用异步读取的方式来优化整体的程序时间，即在读取或写入文件的同时，其他程序工作同步进行。&lt;/p&gt;

&lt;p&gt;最常见的是游戏的开机画面，加载画面，切换场景画面，甚至有些游戏中边加载边进行的部分，都是可以通过并行来优化体验的。&lt;/p&gt;

&lt;h3 id=&quot;文件读写并发通常都是开启线程后的读写操作与阻塞内容一样只是更多的利用可利用的cpu时间而不让线程空闲等待硬盘原理是我们尽力能让计算机中的所有设备资源都满负荷运转并很好的协作而不是相互牵制&quot;&gt;文件读写并发通常都是开启线程后的读写操作，与阻塞内容一样，只是更多的利用可利用的CPU时间而不让线程空闲等待硬盘，原理是我们尽力能让计算机中的所有设备资源都满负荷运转并很好的协作，而不是相互牵制。&lt;/h3&gt;

&lt;p&gt;下面我们就来讲讲并发的优化内容。&lt;/p&gt;

&lt;h2 id=&quot;并发&quot;&gt;并发&lt;/h2&gt;

&lt;p&gt;并发的方案有很多特别是在业务层上有很多技巧，这里只是选取与语言相关部分。我们将从原理出发讲一讲，线程同步中的技巧、原子性、以及无锁容器的原理。&lt;/p&gt;

&lt;p&gt;由于设备资源并不总是运行，因为我们的程序并没有使用到这些资源，或者说有时没有同一时间同时让它们一起运转，这使得资源的闲置造成了浪费，如果能在当某个程序在执行指令时，另一个设备在满负荷运作，这样就相当于提高了运行效率。&lt;/p&gt;

&lt;h3 id=&quot;并发的挑战是找到足够多的独立任务来充分地使用所有可用的计算机资源让资源都能满负荷的执行提高整体运行效率其中cpu资源是最稀缺也是使用最频繁的资源如果能让多核中所有cpu都满负荷工作不考虑降频问题程序的效率就能提高很多即使不满负荷也能提其他cpu分担不少工作让降频的概率减少到最低&quot;&gt;并发的挑战是找到足够多的独立任务来充分地使用所有可用的计算机资源，让资源都能满负荷的执行，提高整体运行效率。其中CPU资源是最稀缺，也是使用最频繁的资源，如果能让多核中所有CPU都满负荷工作(不考虑降频问题)程序的效率就能提高很多，即使不满负荷，也能提其他CPU分担不少工作，让降频的概率减少到最低。&lt;/h3&gt;

&lt;p&gt;首先我们来梳理下操作系统中的进程、线程、时间片的概念。&lt;/p&gt;

&lt;p&gt;线程是实际工作的单元，进程只是一个容器用来管理线程。严格来说Linux内核其实不区分进程和线程，内核把执行单元叫做任务(Task)。操作系统实际上调度的是进程，进程通过fork()来创建同样的另一个进程。每个进程有一个PID，同一组进程中最先启动的那个还有一个TGID，严格来说前者应该叫线程ID，后者应该叫进程ID，其实它们都是Linux的Task。&lt;/p&gt;

&lt;p&gt;多线程能同时做好几件事情以提高效率，但实际问题是，CPU的数量（核心数）是有限的，而且并不多。如果你的CPU有8个核，并且整个操作系统中有8个线程的话，不考虑中断等因素，每个线程理论上能一直执行下去。然而多于8个线程以后，操作系统就必须进行调度，也就是分配时间片。具体的分配方案，或者说调度算法有很多种。如果一个进程创建了很多线程的话，最多也只有8个能够处于执行的状态(这里说的是物理线程，有别于逻辑线程)，其余的线程必须等待调度。线程被调度的时候需要进行上下文切换，这个操作是一种额外的开销。当线程数量过多的时候，上下文切换产生的额外开销会对系统的效率造成负面影响。&lt;/p&gt;

&lt;p&gt;线程的调度算法和进程一样通常有优先级之分，优先级高的线程可以比优先级低的线程多抢占些CPU时间片。甚至不同的线程可以通过系统调用将线程绑定在某个CPU核上。因此我们也可以通过将线程绑某个cpu核的方式来强制执行线程调度，从而优化并行开销。&lt;/p&gt;

&lt;h3 id=&quot;线程同步&quot;&gt;线程同步&lt;/h3&gt;

&lt;p&gt;通常我们在多个线程交叉执行时最关心的是同步问题。解决这个问题我们可以用，减少锁的占用时间、减少锁的颗粒度、无锁容器三个方式。前两者更好理解些，也用的比较多，最后一个需要阐明下原理。&lt;/p&gt;

&lt;p&gt;通常我们使用锁和互斥量来解决线程间的同步问题，但这会带来潜在问题，就是由于锁的原因导致线程间的等待时间变长，实际执行的效率可能并没有因此而增加。&lt;/p&gt;

&lt;p&gt;因此锁的范围必须被压缩到最小，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
void doFunction(item)
{
	lock(obj)
	{
		doSomeThing1();

		list.push(item); //must lock

		doSomeThing2();
	}
}

//改为

void doFunction(item)
{
	doSomeThing1();

	lock(obj)
	{
		list.push(item); //must lock
	}

	doSomeThing2();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;尽可能的缩小锁的范围减少锁等待时间&quot;&gt;尽可能的缩小锁的范围，减少锁等待时间。&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
void doFunction1()
{
	lock(obj)
	{
		...
	}
}

void doFunction2()
{
	lock(obj)
	{
		...
	}
}

//改为

void doFunction1()
{
	lock(obj1)
	{
		...
	}
}

void doFunction2()
{
	lock(obj2)
	{
		...
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;减少锁的颗粒度让各自的锁只负责自己一小部分的内容这里也涉及到细粒度锁算法它通常基于轻量级原子性原语由于并不是基于系统提供的同步原语所以性能开销很小但在高并发的情况下细粒度锁算法就会成为程序的瓶颈&quot;&gt;减少锁的颗粒度，让各自的锁只负责自己一小部分的内容。这里也涉及到细粒度锁(算法)，它通常基于轻量级原子性原语，由于并不是基于系统提供的同步原语所以性能开销很小，但在高并发的情况下，细粒度锁(算法)就会成为程序的瓶颈。&lt;/h3&gt;

&lt;p&gt;由于指定锁某些局部的计算范围或者函数，锁的时间太长并不划算，所以我们通常在两个线程间的协作上使用消息队列(或者其他容器)让线程更大程度的并行，但这依然需要对容器加锁，以使得操作不冲突。&lt;/p&gt;

&lt;p&gt;为了能让容器冲突时间更小，当只有两个线程操作容器时，我们通常会采用些技巧。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;例如双队列，设置两个队列，其中一个用于处理消息，另一个用于接收消息，当处理消息时，两个队列的头指针交换一下再处理，这样就能让接收的队列继续接收，处理的队列独自处理，这种方式的缩短了锁的占用时间，锁的时间缩短到了变量交换时间。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;以及循环队列的方式，用头尾循环的方式做队列，一个线程只对尾部操作，另一个线程只对头部操作，发送数据的线程向尾部推入数据，接收数据的线程从头部取出数据，循环操作队列，只有当队列满时才需要停一停等待数据
处理，其他时候，两者永远都不需要相互等待。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;无锁容器&quot;&gt;无锁容器&lt;/h3&gt;

&lt;p&gt;无锁容器的复杂度有点高，它适用于高并发场景，这里不便深入，其原理是原子操作。虽然我们不深入无锁容器的具体写法，但我们用问答的方式来解释下原子操作。&lt;/p&gt;

&lt;h3 id=&quot;什么是原子性&quot;&gt;什么是原子性？&lt;/h3&gt;

&lt;p&gt;如果一个更新操作不会计算到一半的时候被另外一个线程看到，就叫原子性。&lt;/p&gt;

&lt;p&gt;原子操作可认为是一个不可分的操作；要么发生，要么没发生，我们看不到任何执行的中间过程，不存在部分结果(partial effects)。可以想象的到，原子操作要保证要么全部发生，要么全部没发生，这样原子操作绝对不是一个廉价的消耗低的指令，相反，原子操作是一个较为昂贵的指令。&lt;/p&gt;

&lt;h3 id=&quot;非原子操作为什么会更新到一半被另一个线程看到&quot;&gt;非原子操作，为什么会更新到一半被另一个线程看到？&lt;/h3&gt;

&lt;p&gt;即使一个简单的整型变量的赋值操作，也有可能更新到一半被另一个线程看到，这是为什么呢？原因就是高速缓存中的旧数据。&lt;/p&gt;

&lt;p&gt;由于每个cpu除了共享一个内存设备外还有各自的高速缓存，一个cpu更新了内存中的内容后，其实并没有通知其他cpu中的缓存去掉该内容，这导致其他cpu中的高速缓存存储的仍然是旧的数据。当这些CPU读取这个变量时会从缓存中取得旧数据，直到缓存中的这个数据被丢弃或更新。&lt;/p&gt;

&lt;h3 id=&quot;原子操作做了什么使得更新不被其他线程看到&quot;&gt;原子操作，做了什么使得更新不被其他线程看到？&lt;/h3&gt;

&lt;p&gt;CPU的高速缓存间有一个MESI协议(cache一致性协议，4个关键词 Modifed Exclusive Shared Invalid 拼凑起来的缩写)，通过这个消息协议，CPU可以查看其他CPU高速缓存中的数据状态，就像不同设备间通信那样。&lt;/p&gt;

&lt;p&gt;当执行原子操作 store 即写入数据时，先查看当前cpu高速缓存中有没有数据，如果没有，则通知其他cpu中的高速缓存该数据切为无效状态，等待所有cpu都将该数据切为无效状态后，此cpu才开始发起写入内存和高速缓存的操作，并标记该值为修改状态。如果有，则更新高速缓存中的值，并通知其他cpu中的高速缓存该值已经不合法，最后此cpu并没有将该值写入内存，而是在高速缓存中标记该值被修改，以便下次再利用，或者等到丢弃时再写入内存。&lt;/p&gt;

&lt;p&gt;当执行原子操作 load 即读取数据时，先查看当前cpu高速缓存中有没有该数据，如果没有(或者是无效的)，则从先从查看其他cpu中查看该数据，如果有则获取，没有则从内存中获取。如果当前cpu高速缓存中有该数据，则直接使用该数据(必须不是无效的)。&lt;/p&gt;

&lt;h3 id=&quot;其他并行优化&quot;&gt;其他并行优化&lt;/h3&gt;

&lt;p&gt;1.分割资源，减少线程间的争夺。&lt;/p&gt;

&lt;p&gt;分割或者复制一块内存出来，让某个线程专门使用，这样就不会与其他线程冲突，计算结束时再考虑合并的事。&lt;/p&gt;

&lt;p&gt;此方法在Unity引擎的 Job System中有使用到，即给Job System一块独立的内存来处理自己的事物，与其他线程不冲突。&lt;/p&gt;

&lt;p&gt;2.散列容器，减少锁的范围，和前面介绍的细粒度锁(算法）稍微有点不一样，这种容器是散列的，冲突更少但使用范围很小。&lt;/p&gt;

&lt;p&gt;3.SIMD指令虽然不是并行，但由于它可以同时处理4个数据的运算，也算是勉强算并行处理了。&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/huxiao-tee/p/4657851.html&quot;&gt;《从内核文件系统看文件读写过程》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/64723752&quot;&gt;《Linux系统中 进程 、线程 、时间片的关系》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.jiqizhixin.com/articles/2019-01-22-12&quot;&gt;《说说无锁(Lock-Free)编程那些事》&lt;/a&gt;&lt;/p&gt;
</description>
               <pubDate>Sun, 27 Dec 2020 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2020/12/27/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B018</link>
               <guid isPermaLink="true">http://www.luzexi.com/2020/12/27/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B018</guid>
            </item>
        
            <item>
               <title>给女儿的信(七)</title>
               <description>&lt;p&gt;Hi 陆秀恩&lt;/p&gt;

&lt;p&gt;圣诞快乐，今年的圣诞爸爸在很远的深圳，爸爸好想跟你一起过圣诞，爸爸一直很想念你，也一直很关注你。&lt;/p&gt;

&lt;p&gt;我知道你与同学相处的越来越融洽了，在学校里的表现很积极很开朗，大家都喜欢跟你交朋友，因为你懂得关心朋友。&lt;/p&gt;

&lt;p&gt;你的画画和跳舞越来越棒了，对自己喜欢的事很专注。我跟秀恩一样也很专注呢。我还听妈妈说你越来越自律了，这是个不错的开始喔。&lt;/p&gt;

&lt;p&gt;爸爸一直在学习如何学习，想把学习的技巧再多研究一下，让自己更懂得如何高效学习，以前爸爸学习总是很低效，注意力很难集中，浪费了很多时间，现在我想改变一下自己。&lt;/p&gt;

&lt;p&gt;这是一条漫长的路，爸爸每天都在坚持，坚持每天看点书，每天运动一下，每天学习一下，这样一天天积累下来，1年就会有大的不同，3、5年就有翻天覆地的变化。我想成为一个知识渊博的人，可能成不了科学家，但可以成为一个有价值的人，一个自律、智慧、有爱的人。&lt;/p&gt;

&lt;p&gt;爸爸很想念你，祝你圣诞快乐，加油陆秀恩 ：）&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Hi 陆安妮&lt;/p&gt;

&lt;p&gt;圣诞快乐，爸爸很想念你。&lt;/p&gt;

&lt;p&gt;我常听妈妈说你也很想念爸爸，爸爸心里暖暖的很高兴。&lt;/p&gt;

&lt;p&gt;在幼儿园里的日子还好么，和朋友们相处的还融洽么，爸爸很想过来每天都陪着你，但爸爸有点忙，需要在深圳工作几年。&lt;/p&gt;

&lt;p&gt;爸爸知道最近你跟姐姐一起开始学习写字和数学，爸爸知道你很努力，跟爸爸一起加油喔。你会慢慢的找到自己学习的节奏的，安妮。你很棒哎，要坚持住喔。爸爸也在深圳努力呢，每天都有学习和健身，爸爸跟你一起做身体壮壮的、学习棒棒的好孩子，比心。&lt;/p&gt;

&lt;p&gt;爸爸拿着你送给我的画，每天都放在床头看一下，一看到这幅画爸爸就想到你，下次记得再送爸爸一副画哦。最近去台上表演时心里紧张吗，爸爸看了你跳舞的视频，很不错哎，我们再接再厉，一起加油。&lt;/p&gt;

&lt;p&gt;爸爸、妈妈、小姨妈、安妮、秀恩都一起加油，加~油~！&lt;/p&gt;

&lt;p&gt;圣诞快乐安妮，想念你的爸爸 ：）&lt;/p&gt;

</description>
               <pubDate>Fri, 25 Dec 2020 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2020/12/25/%E7%BB%99%E5%A5%B3%E5%84%BF%E7%9A%84%E4%BF%A17</link>
               <guid isPermaLink="true">http://www.luzexi.com/2020/12/25/%E7%BB%99%E5%A5%B3%E5%84%BF%E7%9A%84%E4%BF%A17</guid>
            </item>
        
            <item>
               <title>读书笔记(十七) 《C++性能优化指南》二</title>
               <description>&lt;h3 id=&quot;字符串问题&quot;&gt;字符串问题&lt;/h3&gt;

&lt;p&gt;这里作者讲的有点啰嗦，没有围绕着重点去讲，所以这里我吸收下他的知识点并总结下自己的知识点和经验。&lt;/p&gt;

&lt;p&gt;把字符串问题单独拎出来说是因为字符串问题比较大，也比较隐性，常常容易引起性能问题。字符串在概念上很简单，它就是一个字符数组，但是想要实现高效的字符串却非常不容易。&lt;/p&gt;

&lt;p&gt;首先字符串内存是动态分配的，其次是字符串常常被用来当成一个值来使用，这导致字符串操作常常带来大量不必要的内存分配和内存复制。&lt;/p&gt;

&lt;p&gt;字符串问题的重点在内存分配问题和字符串查找。字符串操作带来的内存频繁的分配和浪费导致程序性能效率大大降低，操作包括，字符串拼接、字符串拆分、字符串大小写切换等，每次操作字符串都会新分配一个字符串内存或者字符串内存集，而查找字符串，即使使用算法通常也会逐字比较，效率比价差，特别是在一个集合中查找某个字符串对应的值时，需要完整的比较两者字符串是否完全一致。&lt;/p&gt;

&lt;p&gt;改善内存分配效率，我们可以使用预分配和内存池机制。字符串内存预分配可以有2种，一种预先分配很多个长度不同的字符串缓存起来，使用时给出去，例如分别预分配1-50长度的字符串各100个，当逻辑需要时再给出去，用完了再收回来。另一种是先分配多个长一点的字符串，例如分配100个100长度的字符串，让字符串能够在拼接时不用再分配内存，由于本身字符串长度足够长，所以可以直接在当前字符数组中改写内容。&lt;/p&gt;

&lt;p&gt;除了预分配，我们也可以将已经分配的字符串加入到字符串缓冲池中去，来管理这些预先分配好的字符串，需要时给予，不用时回收，不够时再分配一批，这样就能重复利用已经分配的字符串内存，将分配内存的工作集中起来消耗在某个点上。&lt;/p&gt;

&lt;p&gt;我们常会去比较和查找字符串，查找字符串中的字符串有很多算法，但比较两个字符串是否相同如果仍然使用查找算法去做就是一种浪费，那么我们应该怎样去做两个字符串的比较呢，最好用哈希的方式，把字符串计算出一个哈希值，用这个哈希值来比较是否相等就快很多了。例如我们常常在业务逻辑中判断两个字符串是否相等，每次比较都会浪费掉很多计算量，用哈希的方式就会快很多，因为比较的是两个整数，在每次更新字符串时只需要重新计算一次哈希值就可以，由于通常字符串更新的并不频繁，所以计算哈希的消耗远比每次遍历两个字符串所带来的消耗要小的多。但哈希计算不一定能够获得一个唯一值，所以它只能被用来判断是否不同，即当哈希值不同时，两个字符串一定不同，而两个哈希值相同时有可能不同，此时再比较两者是否真的相同。虽然无法直接比较相同的字符串，但仍然大大减少了不同的两个字符串的比较的计算。&lt;/p&gt;

&lt;h3 id=&quot;算法&quot;&gt;算法&lt;/h3&gt;

&lt;p&gt;算法是性能优化中的精髓，多数平庸的优化方法对性能改善都是线性的，但算法不同，如果说一个高效的算法替换了一个低效的算法性能可能呈现指数级的增长。&lt;/p&gt;

&lt;p&gt;算法时间开销一般有O(1)，O(log2(N))，O(N)，O(Nlog2(N))，O(N^2)，O(N^3)，O(2^N)，从高效到低效的排列，大多数算法如果能到log2(N)已经是非常优秀了，再进一步到O(1)则通常要付出巨大的内存代价。&lt;/p&gt;

&lt;p&gt;作者对二分查找、哈希、散列查找算法特别中意，于是讲了散列算法是怎样的和关键点是什么。我们在用在用查找算法时log2(N)的算法已经是非常不错的查找效率了，所以二分查找是效率比较高的，但它仍然是建立在有序队列的基础上，需要先排序再查找，排序比查找更能耗时，而且后续的元素加入需要插入到有序队列中。而散列算法则不同，排序和查找会更快，前提是数据特性能够散列，或者说散列的冲突不会那么高，于是他告诉我们哈希算法对于散列的重要性。&lt;/p&gt;

&lt;p&gt;这里作者讲的查找和排序内容比较浅，我融入了一些自己的经验。&lt;/p&gt;

&lt;p&gt;算法通常是根据数据特效来定制的，所以对数据独有的特性分析是重点。就我的理解，算法并一定要局限于当前的结构，可以重新创建一个全新的结构方式，这样在用算法去优化程序的时候思路会更开阔。例如我们在全地图寻找某个人的时候并不一定要在查找函数上优化算法，而可以重新制造一个方格结构体把世界分割成不同的方块，找人时只要收集四周方块内的人就可以更快的找到。&lt;/p&gt;

&lt;p&gt;算法也可以是局部的，因为数据多少和数据的特性可以由不同算法处理，所以我们在处理一大堆数据时可以拆分成不同的数据集进行处理，这些数据集的大小和特性也有所不同，针对性的处理会得到更有效的算法效率，例如快速排序算法，可以由不同的算法组成，由于它的中间值决定了快排速度，所以中间值我们可以用三个值取中间数的算法来找到更加稳定的中间值，当数段被分割成多个区间并且单个区间小于等于8个数时，插入排序其实比快排会更加快一些，因此我们在快排中间当数据量小于8时选择用插入排序算法。&lt;/p&gt;

&lt;p&gt;作者列举了一些常用的算法优化思路和套路。&lt;/p&gt;

&lt;p&gt;套路有：预计算、延迟计算、批量处理、缓存、特化、提高处理量、提示、优化执行路径、散列法、双重检查。&lt;/p&gt;

&lt;h3 id=&quot;预计算&quot;&gt;预计算&lt;/h3&gt;

&lt;p&gt;提前计算好一些可以离线完成计算量存储在文件中，这样可以省去了实时计算的开销。&lt;/p&gt;

&lt;h3 id=&quot;延迟计算&quot;&gt;延迟计算&lt;/h3&gt;

&lt;p&gt;先让所有中间过程改变完成后再对最后的结果计算，这样就省去了每次都需要计算全路径的消耗，例如引擎中通常有节点相互的挂载，每次赋值节点position时都会去计算重新计算子节点的位置，这时就要思考如何让计算延后，每次子节点的真实位置只要在帧结束时计算一遍就可以了，不用每次改变position时都去全路径计算一遍所有子节点。&lt;/p&gt;

&lt;h3 id=&quot;批量处理&quot;&gt;批量处理&lt;/h3&gt;

&lt;p&gt;某些具有相同性质的数据不要一个个处理，因为一起同一类型的数据处理起来会有更优的方法，例如堆排序如果一个个插入的元素的话性能开销是O(Nlog2(N))，而一次性构建一个堆的话只需要O(N)。&lt;/p&gt;

&lt;h3 id=&quot;缓存&quot;&gt;缓存&lt;/h3&gt;

&lt;p&gt;不要每次都计算，然后拿着结果去比较，计算完后缓存起来，一直用缓存的值，直到需要更改时再计算一遍。&lt;/p&gt;

&lt;h3 id=&quot;特化&quot;&gt;特化&lt;/h3&gt;

&lt;p&gt;一堆数据处理时它们都会消耗一些计算量，如果某个数据是特别的，不需要计算或者计算量可以很小，则另外开辟一个通道给它，让它少消耗一些。&lt;/p&gt;

&lt;h3 id=&quot;提高处理量&quot;&gt;提高处理量&lt;/h3&gt;

&lt;p&gt;一次处理多个数据而不是一个个处理，例如写日志不要每次都写，每隔一段时间写一次，类似这样的操作，先把准备的数据集中起来，集中起来的数据可能会有更多相似的特性可以用来优化。&lt;/p&gt;

&lt;h3 id=&quot;提示&quot;&gt;提示&lt;/h3&gt;

&lt;p&gt;当处理数据的时候，给予一个提示，这样我们就能知道该如何更好更快的处理，例如在插入一个数据到队列里去时，告诉插入函数，这个数是个比较大的值或者是一个比较小的值，这样我们在做插入时就有了更多优化提示。&lt;/p&gt;

&lt;h3 id=&quot;优化执行路径&quot;&gt;优化执行路径&lt;/h3&gt;

&lt;p&gt;程序语句里有很多个if…else，如果95%的语句都进某个if，那么最好把它提前到语句前，这样就不用执行其他的if里的计算了。&lt;/p&gt;

&lt;h3 id=&quot;散列法&quot;&gt;散列法&lt;/h3&gt;

&lt;p&gt;哈希值比较法，数据结构和字符串在比较时比较费时，用哈希值比较则比较方便，为它们计算一个哈希值，当两个哈希值不同时，它们一定不同，如果哈希值相同则再比较是否真的相同。&lt;/p&gt;

&lt;h3 id=&quot;双重检查&quot;&gt;双重检查&lt;/h3&gt;

&lt;p&gt;数据其实有很多个特征可供我们使用来优化我们的算法，比如长度，如果两个数组长度不一样，那么它们两个的内容肯定是不一样的。类似这样的特征还有数据结构的某个字段或者某几个字段可以决定算法的计算路径，我们只要判断这几个字段就能排除很多计算量。&lt;/p&gt;

&lt;h3 id=&quot;套路只是方法论&quot;&gt;套路只是方法论&lt;/h3&gt;

&lt;p&gt;很多时候技巧谁都知道，实际运用时却能难灵活自如，如果你不常用它们，它们就不回成为你思考的一部分。&lt;/p&gt;

&lt;h3 id=&quot;容器&quot;&gt;容器&lt;/h3&gt;

&lt;p&gt;作者对容器类数据结构性能做了一些介绍，从本质和测试标准两个方面做了讲解。&lt;/p&gt;

&lt;p&gt;不管C++标准库和Boost中的容纳器，还是其他语言的标准容器，它们都是非常通用且性价比不错的容器。但是如果你想让容器的性能发挥到最佳状态，就得自己去改造它。为什么要改造呢？因为首先标准容器内存的分配方式对具体的业务逻辑并不友好，我们可以把跟业务强相关的内存分配方式和内存池的技巧用在容器上以提高内存分配效率，其次容器中数据结构的插入、删除、查找的算法跟业务匹配上并不是最佳的，所以我们要根据我们的实际情况来改造这些算法以提高性能效率。&lt;/p&gt;

&lt;p&gt;容器包括，序列容器和关联容器，序列容器有string，vector，deque，list，forward_list，大都是以数组或链表形式存在的容器，而关联容器则以map和set为代表，用来建立key和value之间联系的容器，包括map、multimap、set、multiset等。&lt;/p&gt;

&lt;p&gt;我们在构造完自己的容器后，需要跟标准容器进行比较，只有这样才能知道我们改造的与业务强相关的容器是否比标准容器更加高效。&lt;/p&gt;

&lt;p&gt;容器性能测试标准就是为了判断容器的在各方面的性能是否更优秀，测试内容需要包含向一个没有内容的容器中以及向一个有数万条记录的容器中插入，删除，查找十万个不同的元素所需要消耗的纳秒数，比较拥有相同功能的容器在执行同一功能的操作时所消耗的时间。我们在测试时用到的数据也会遇到问题，十万个元素也并不能代表数据的典型性，所以很多时候我们需要离线Random随机1000组不同的数据以覆盖所有测试范围。&lt;/p&gt;

&lt;p&gt;由于我们自己不可能对所有容器进行重构，所以第三方容器库也是我们需要关注的地方，包括Boost、EASTL等都是我们需要参考的对象。&lt;/p&gt;

&lt;h2 id=&quot;内存分配&quot;&gt;内存分配&lt;/h2&gt;

&lt;p&gt;提升内存分配效率是提升程序性能非常有效的手段，其实质就是减少内存分配次数，减少内存分配次数就意味着减少内存分配带来的消耗，因此关键的关键还是如何减少内存分配次数，注意，是次数，不是大小，也不是释放。&lt;/p&gt;

&lt;p&gt;讲内存分配之前，我们先来了解下内存分配接口以及内存分配的底层原理。&lt;/p&gt;

&lt;p&gt;C++中内存管理函数有new，delete，malloc，free，其中new，delete运算符可以被类重载为 new()，new&lt;a href=&quot;&quot;&gt;&lt;/a&gt;，delete()，delete&lt;a href=&quot;&quot;&gt;&lt;/a&gt;，他们与class强相关，而malloc()和free()则是经典的C函数库中的内存管理函数，它们分配和释放的是无类型内存块，当无类型内存块被创建出来后，可以被强制指定为是某个变量、数据结构或者类实例。&lt;/p&gt;

&lt;p&gt;从概念上来说，分配内存的函数会从内存中寻找一块可以使用的内存来满足请求，但事实上并没有这么简单。作者没有详细介绍内存分配和释放的底层原理，但我觉得这部分的底层原理是值得挖掘和说明的，作为一个频繁与内存打交道的程序员来说，知道内存是如何分配和释放的是非常有必要的。&lt;/p&gt;

&lt;p&gt;我们的程序被加载到内存后分为几个内存段，包括指令段，数据段，bss段，栈段，堆段，指令段放具体指令，数据段放常量数据，bss段放静态和全局变量，栈段放调用栈、临时寄存器和临时变量，以上几个段都是固定的，不会有扩容一说，只有堆段是可扩容的。new和malloc分配的内存就在这个堆段中。&lt;/p&gt;

&lt;p&gt;堆段会事先分配一段内存，当malloc请求分配的内存时，如果剩余空的内存足够，则分配返回一段足够大小的内存，如果不足则再申请内存。&lt;/p&gt;

&lt;p&gt;堆段在向系统申请内存时类似于提高内存块大小，分配新内存这个操作需要系统将用户态切换到内核态再切回来，因此性能损耗是比较大的。其实malloc分配了内存，也并不代表实际物理内存中申请了某块内存，因为进程所面对的虚拟内存地址空间，只有按页映射到物理内存地址，才能真正使用。而且分配了新的内存，物理内存上实际没有此内存空间，只有当我们memset实际使用它时系统发现了物理内存缺页情况时才真正分配实际物理内存空间。&lt;/p&gt;

&lt;p&gt;从这个角度看，内存分配在操作系统底层上会稍显复杂。那么申请内存在系统底层到底是如何操作的呢？我们来深究一下。&lt;/p&gt;

&lt;p&gt;在Linux中进程由进程控制块(PCB)描述，用一个task_struct 数据结构表示，这个数据结构记录了所有进程信息，包括进程状态、进程调度信息、标示符、进程通信相关信息、进程连接信息、时间和定时器、文件系统信息、虚拟内存信息等. 和malloc密切相关的就是虚拟内存信息，定义为struct mm_struct描述了进程的地址空间。&lt;/p&gt;

&lt;p&gt;mm_struct结构对整个用户空间（进程空间）的描述如下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c&quot;&gt;///include/linux/sched.h 

struct mm_struct {
  struct vm_area_struct * mmap;  /* 指向虚拟区间（VMA）链表 */
  rb_root_t mm_rb;         /*指向red_black树*/
  struct vm_area_struct * mmap_cache;     /* 指向最近找到的虚拟区间*/
  pgd_t * pgd;             /*指向进程的页目录*/
  atomic_t mm_users;                   /* 用户空间中的有多少用户*/                                     
  atomic_t mm_count;               /* 对&quot;struct mm_struct&quot;有多少引用*/                                     
  int map_count;                        /* 虚拟区间的个数*/
  struct rw_semaphore mmap_sem;
  spinlock_t page_table_lock;        /* 保护任务页表和 mm-&amp;gt;rss */       
  struct list_head mmlist;            /*所有活动（active）mm的链表 */
  unsigned long start_code, end_code, start_data, end_data; /* 代码段、数据段 起始地址和结束地址 */
  unsigned long start_brk, brk, start_stack; /* 栈区 的起始地址，堆区 起始地址和结束地址 */
  unsigned long arg_start, arg_end, env_start, env_end; /*命令行参数 和 环境变量的 起始地址和结束地址*/
  unsigned long rss, total_vm, locked_vm;
  unsigned long def_flags;
  unsigned long cpu_vm_mask;
  unsigned long swap_address;

  unsigned dumpable:1;
  /* Architecture-specific MM context */
  mm_context_t context;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中start_brk和brk分别是堆的起始和终止地址，我们使用malloc动态分配的内存就在这之间。系统分配堆空间时，进程通过malloc()库函数在堆上进行空间动态分配，堆空间如果不够用，malloc就进行系统调用增大brk的值。malloc只知道start_brk 和brk之间连续可用的内存空间它可用任意分配，如果不够用了就向系统申请增大brk。&lt;/p&gt;

&lt;p&gt;我们看到实际堆内存在虚拟空间中是可以不断向上扩张的，虽然实际物理内存中不是这样，但至少在虚拟空间中我们可以认为堆内存是一段连续的内存空间地址。&lt;/p&gt;

&lt;p&gt;由于我们分配的内存空间都在虚拟空间当中，我们看到的都是虚拟的地址，实际物理内存分配并不是我们想象的那样连续，也有可能在分配时由于物理内存不足我们拿到的空间是从硬盘空间上的一段数据交换到内存上来的。所以很多时候即使我们分配了连续的空间，在物理内存上也并不是连续的，只能说连续的概率比较大而已。&lt;/p&gt;

&lt;p&gt;其实还有很多分配内存在操作系统层面的原理，这里暂时不深究下去。&lt;/p&gt;

&lt;p&gt;作者指出提高内存分配效率的方法有两种，一种是减少不必要的内存复制的情况，另一种是用固定大小内存分配器解决减少内存分配次数。&lt;/p&gt;

&lt;p&gt;其中内存复制现象常会存在于对象初始化、赋值运算、函数参数、函数返回、插入一个元素到标准容器中，这几种情况是我们需要特别注意的，常常会由于失误编码而导致内存复制的情况，特别是针对一些常用的结构体和非指针类型的实例传递。&lt;/p&gt;

&lt;p&gt;固定大小内存管理器，意思是分配的内存块大小是固定的，这块内存可以是某个类或数据结构相匹配的一个固定大小，也可以是按某固定大小的内存块，这块内存能容纳某个范围内的一个类或数据结构的实例，这个内存管理器专门管理这个类或数据结构的所有内存的，或者专门管理某个固定大小内存块的管理类，这样在分配某一类大小实例时可以专门使用这样的内存管理器(有冗余不可避免)。&lt;/p&gt;

&lt;p&gt;在固定大小内存管理器中，会预加载一段内存以便给足够数量的类和数据结构使用，并且在回收时存储在管理器中以便重复利用，这样既减少了内存分配次数，也减少了内存碎片。&lt;/p&gt;

&lt;p&gt;这样一来，内存块的管理，可以分为，专门为某个类设计的内存管理类，和专门为某个大小范围内设计的内存管理类，我们可以称它们为通用的内存块管理类。&lt;/p&gt;

&lt;p&gt;在实际编程中，我们在写一个固定大小的内存分配管理器时，如果某个类使用数量比较固定和分配释放率比较频繁的话，可以专门为这个类做一个分配器是性价比比较高的。我们通常也会写一个比较通用的内存管理器，用大小不同的内存块来进行区分，例如我们可以为64byte，128byte，256byte，512byte，1k，2k，这几档大小分别预分配几十个内存块存储在通用内存分配管理器中，当程序请求内存时，将请求大小四舍五入后变为2的下一个幂，这样就能获得一个最快适配的内存管理器，当然在使用完毕释放时也同样只是回到这个内存管理器中存储起来以便重复利用，就像内存池和对象池那样。&lt;/p&gt;

&lt;h2 id=&quot;热点代码&quot;&gt;热点代码&lt;/h2&gt;

&lt;p&gt;这周依然没有写完，下周继续最后一部分的总结。&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《malloc和free的实现原理解析》https://jacktang816.github.io/post/mallocandfree/&lt;/p&gt;

</description>
               <pubDate>Sun, 13 Dec 2020 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2020/12/13/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B017</link>
               <guid isPermaLink="true">http://www.luzexi.com/2020/12/13/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B017</guid>
            </item>
        
            <item>
               <title>读书笔记(十六) 《C++性能优化指南》一</title>
               <description>&lt;p&gt;这本书给我的感受是，有技巧有细节也有许多不足，作者介绍了大部分程序上性能优化的方案和思路，也从原理上讲了性能问题的根本原理，但没能做得通俗易懂、深入浅出，书本有几处地方在故弄玄虚以及凑字数，也许是我的功力不足没能理解，这部分无法理解的杂乱无章的内容，可以留到以后再慢慢回顾。&lt;/p&gt;

&lt;p&gt;整本书其实并不是针对C++写的，而是面向程序执行而效率写的，其他语言也一样通用。我结合我的经历和经验写下我的理解，以及我从书中学到的知识，或许过几年回头看会是另一番情景，但现在我需要把它们拎出来总结一下。&lt;/p&gt;

&lt;p&gt;作者是一个有30多年编程经历的人，对编程依然保持的狂热兴趣，注意，他从未去过微软、谷歌等知名公司，这本书就是在这样的一个前提下写下的。&lt;/p&gt;

&lt;p&gt;作者认为我们在优化程序的时候，很多时候都是靠‘猜测’而不是实际的去测试，这是一个比较大的问题。实际上我们并不知道某段程序是否有性能问题，因为有可能编译器已经将它优化了，或者某段程序在我们优化后是否真的有性能提升，因为很多时候我们只是肉眼去代码或是用脑袋去猜，不知道性能问题出在哪里就花费很多时间去优化这是不行的。而且我们也不能因为优化程序性能而破坏了程序的稳定性，如果从中制造出Bug导致产品崩溃那是非常得不偿失的。&lt;/p&gt;

&lt;p&gt;另外他提出了一个比较重要的理念，即大部分性能问题在代码层面上的分布都是‘90/10规则’，也就是说，90%的性能问题出在10%的代码上。因此为了我们在做性能优化时提高效率，应该重点去找出这影响90%性能问题的那10%的代码，它们就是性能问题的重点。不过这10%的代码并不是集中在某处，而是分散在各个模块中，需要我们去找出来，因此按照我的经验和他的理念来理解性能优化的90/10规则，是说我们需要改动的代码远比整体代码要少的多，而我们必须精准的找出这部分少数代码并优化它。&lt;/p&gt;

&lt;p&gt;原书内容比较繁杂，我又重新归类，我把它归类为，计算机执行原理、性能测试、字符串问题、算法、内存分配、热点代码、IO、并发，这八个方面。下面就让我们来讲讲我从书本中学到的对性能优化的理解。&lt;/p&gt;

&lt;h2 id=&quot;计算机执行原理&quot;&gt;计算机执行原理&lt;/h2&gt;

&lt;p&gt;代码从被编译到成为可执行文件也就是机器码，这个过程就是一个从本文字符串翻译成机器码的过程，当我们执行它们的时候，它可机器码被放入了内存，内存中也有分块，包括数据段、栈段、指令段。&lt;/p&gt;

&lt;p&gt;CPU在执行指令时是从内存中将指令送入CPU的，而执行指令的速度通常比读取内存的快很多，因此读取指令也成为了瓶颈的一种。CPU在读取指令时也并不会一行一行的读取，因为这样效率太差，取而代之的是它会把一大块内容读取到高速缓存从而加快执行速度，指令会顺序执行直到结束或有跳转。&lt;/p&gt;

&lt;p&gt;而内存芯片也有自己的工作原理，它相当于另一个CPU，它只有在顺序访问时才能在一个周期内完成，而访问一个非连续的位置则会花费更多周期。&lt;/p&gt;

&lt;p&gt;这里就涉及到了内存在访问时的形式，每次访问内存都是以某个大小为单位，例如x86机器，每次访问内存时都是以4个字节为单位访问，一个int整数为4个字节需要一次访问，但如果这个int整数内存没有对齐，那么可能就需要访问两次才能获得这个值，因为构成这个内存的物理结构可能是垮了两个物理内存字。&lt;/p&gt;

&lt;p&gt;不过请注意，现代编译器都会默认对对象和数据结构做内存对齐操作，除非我们告诉编译器某个数据结构不做内存对齐。对齐时编译器也会优化内存结构让高速缓存命中率提高，关于class的内存布局我们在《深度探索C++对象模型》总结中有详细的讲解。&lt;/p&gt;

&lt;p&gt;作者没有细说关于不对齐时内存访问的来龙去脉，不过我们来举个例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c&quot;&gt;[-][-][x][x][x][x][-][-]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例如上面这个非对齐的内存空间，‘x’表示某个int变量占用的4个字节，‘-’表示其他，当CPU读取这个int整数时，其实是先读取&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c&quot;&gt;[-][-][x][x]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再读取&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[x][x][-][-]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;拼接完成后为&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[x][x][x][x]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后交给寄存器。实际上访问非内存对齐并没有我们想象的那么简单，一个内存实际上有很多个内存芯片共同组成。为了提高访问的带宽，通常会将存储地址分开放在不同的芯片上，例如上面位置0，1，2，3，这4个byte分别存放在芯片1，芯片2，芯片3，芯片4中，当需要它们时，可以一次性全部读取，即如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c&quot;&gt;偏移量/芯片存储空间
   x1 x2 x3 x4
0 [-][x][x][x]
1 [x][-][-][-]
2 [-][-][-][-]
3 [-][-][-][-]
4 [-][-][-][-]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;图中x为要读取的数据，每一列为一个芯片负责的空间，每一行为一个偏移量。这就是说，内存实际上并不是完全以连续byte形式组织的，而是以偏移(offset)量给出具体地址。当我们读取[0][1][2][3]这4个byte数据时可以一次性读取，但如果从1开始读取1，2，3，4时就要多一次偏移(offset)的操作，即先让4个芯片读取偏移量为0时的数据，再让它们读取偏移量为1的数据。&lt;/p&gt;

&lt;p&gt;为了改善内存速度，高速缓存被大量运用，即我们说的L1、L2、L3、L4四级高速缓存，它们每一层的速度大约是下一层的10倍左右。当执行单位需要的内容不在高速缓存中时，需要从内存中加载数据到高速缓存中，并同时将一部分内容舍弃以换取足够的空间，通常会选择放弃的数据都是最近被使用频率比较低的数据。在读取一个不在高速缓存中的数据时通常会将临近的数据也被缓存起来，从访问概率上来说做了加速了数据访问，即概率上来说临近的数据访问概率比较高的特点。&lt;/p&gt;

&lt;p&gt;这意味着频繁被访问的数据和频繁被访问的周围附近的数据都会因为高速缓存而加速。不仅仅是变量数据，机器指令也是数据的一种，超远的if和goto跳转以及远地址function函数调用同样会让高速缓存失效，其原理是执行指令地址从一处跳到另一处导致执行指令不连续。&lt;/p&gt;

&lt;p&gt;内存的访问也会有不够的时候，这时虚拟内存带来了很大的便利，但也给性能带来了很大影响。在虚拟内存机制中，当内存不够时需要借用磁盘空间来扩充，这让内存制造出拥有充足物理空间的假象，将使用频率小的内存数据作为文件存放在磁盘上，当使用时再读区进内存同时更换部分内存到硬盘上，我们常称它们为内存swap操作。由于swap操作很费时，因此检测swap次数也常被纳入性能监控中。&lt;/p&gt;

&lt;p&gt;通常我们一个操作系统中有多个程序需要同时内存访问，而内存总线就只有一个，内存芯片必须一个个去完成CPU分配给它的任务，有时甚至是经常不连续的内存访问，由此看来，内存的读写负担是相当重的。如果未来有更多的处理器内核增加，而内存接口和读取速度没有增加的话，那么其实这些内核对性能的改善效果也是趋于递减的，因为虽然有多个CPU来处理指令，但内存并没有被加速。&lt;/p&gt;

&lt;p&gt;接着我们来看看线程和进程如何影响执行效率，由于操作系统会执行一个线程很短时间然后将上下文切换到其他线程或进程。导致在切换时会浪费掉很多时间，操作系统需要暂停当前的线程并且保存处理器中的寄存器到内存，然后为即将被执行的线程加载之前保存过的寄存器。如果新的线程的数据不在高速缓存中，那么还需要从内存中加载数据到高速缓存，因此上下文切换的代价比我们想象的高。&lt;/p&gt;

&lt;h3 id=&quot;这里做个小结以上讲的都是些计算机执行原理我们需要明白的原理才能真正明白优化背后的逻辑首先内存效率没有我们想象那么快非对齐内存会多一次开销编译器通常都有做内存对齐指令远距离跳转和内存远距离访问都会让高速缓存命中丢失频繁访问的数据和附近的数据会比较快虚拟内存扩充了内存但swap时性能开销很大多个进程和线程争夺内存使用权是性能瓶颈之一太多线程和进程上下文切换代价较大会导致执行效率降低&quot;&gt;这里做个小结，以上讲的都是些计算机执行原理，我们需要明白的原理才能真正明白优化背后的逻辑。首先内存效率没有我们想象那么快，非对齐内存会多一次开销(编译器通常都有做内存对齐)，指令远距离跳转和内存远距离访问都会让高速缓存命中丢失，频繁访问的数据和附近的数据会比较快，虚拟内存扩充了内存但swap时性能开销很大，多个进程和线程争夺内存使用权是性能瓶颈之一，太多线程和进程上下文切换代价较大，会导致执行效率降低。&lt;/h3&gt;

&lt;h2 id=&quot;性能测试&quot;&gt;性能测试&lt;/h2&gt;

&lt;p&gt;性能测试对于性能优化来说是关键的关键，就像作者提到的那样，我们不能靠猜来判断哪些代码需要优化，或者代码执行效率提升了多少不能由某个人说了算。&lt;/p&gt;

&lt;p&gt;那些具有最让人折服的优化技巧的开发人员都会系统地完成如下步骤：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
1.测试出哪些地方是可优化的，做出预测并记录预测。

2.保留优化的代码记录

3.用测试工具进行测量优化前后的数据对比

4.保留实验结果并做详细的笔记。

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上列的四项步骤是性能优化过程中必须不断实践的技能，现实中多数开发人员都想当然的去优化代码，而不是按照上面的方式有条不紊的进行优化，这是优化过程中最糟糕的一点，即不知道自己该从哪里开始优化，优化结束时不知道是否真的优化了优化了多少，有可能更加糟糕，过了段时间甚至记不起来优化了什么。&lt;/p&gt;

&lt;p&gt;除了实际的去测量和记录，我们在性能测试时要注意哪些关键点呢？作者给出了自己的经验。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1.测量程序的启动时间，执行时间，退出时间。

通常人们总是忘了启动和退出时间，这导致部分测量范围不够或者测量不准确。

2.测量的数据和环境必须是可重复的。

只有两个数据和环境是可重复的，才有可能让两次测量在同一个标准中进行。

3.测量必须有一个标准和一致的范围。

如果前后两次测量的环境、测量内容、测试的持续时间不一致，则测量出来的数据是无效的，这种情况下的任何优化数据都是可笑的。

4.测量数据通常都是波动的，没有不波动的测量数据。

因此我们需要通过反复测量多次给出平均值的方式来确定最后的数据。

5.其他进程会影响测量结果。

关闭其他会导致影响的进程，或者提高测量进程为最高级别。

6.测量工具很重要

测量工具包括类似Stopwatch方式的打点，抓取堆栈调用时间，内存分配，内存快照等方式。

7.分析代码和测量运行时间是帮助找出可优化代码的两种有效途径。

只分析代码是行不通的，只测量运行时间也不可行。要分析代码与测量相互迭代，分析后测量，测量后分析，以此方式不断找出可优化的代码。

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;开发人员需要向同事和领导展示他们在性能优化中取得的进展，我们需要精准的测量和详细的记录，如果凭直觉进行优化，也不发表结果，或者发表了结果也会遭到质疑，这是因为他们分不清你到底是在用高度专业的直觉进行优化还是只是在碰运气。&lt;/p&gt;

&lt;h2 id=&quot;字符串问题&quot;&gt;字符串问题&lt;/h2&gt;

&lt;p&gt;这把字符串问题单独拎出来说是因为字符串问题比较大，也比较隐性，常常容易引起性能问题。字符串在概念上很简单，它就是一个字符数组，但是想要实现高效的字符串却非常不容易。&lt;/p&gt;

&lt;h3 id=&quot;这周太忙暂时写到这里下周继续&quot;&gt;这周太忙，暂时写到这里，下周继续…&lt;/h3&gt;

</description>
               <pubDate>Sun, 06 Dec 2020 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2020/12/06/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B016</link>
               <guid isPermaLink="true">http://www.luzexi.com/2020/12/06/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B016</guid>
            </item>
        
            <item>
               <title>给女儿的信(六)</title>
               <description>&lt;p&gt;Hi Sharon and Anne，爸爸好想你们，爸爸喜欢你们。爸爸还在深圳呢，要再过大概1个月才能回来呢。&lt;/p&gt;

&lt;p&gt;爸爸最近在给自己安排任务，以前爸爸常常等公司给我安排任务，这样会有个问题，爸爸总是会忙于公司的事，没有空去做自己想做的事情了。爸爸觉得这样不行，爸爸必须做些自己想做的事情，但又不能将公司的事情落下，于是爸爸就想到自己给自己安排任务，每天晚上都写下爸爸明天要做的事情，把公司的事和自己的事都兼顾起来，每天都做完他们，当然爸爸在指定任务的时候都是指定一天里能做完的，做不完的后面分成一天天的小任务去做。就像老师给你们安排作业一样，这些都是别人要你们做的，有些被动，做被动的事情的时候其实没有灵魂，不如反过来，每天晚上写下明天自己要做的事情，第二天的时候去做自己写下的列表上的事情，这样会更快乐哦。&lt;/p&gt;

&lt;p&gt;加油Sharon，加油Anne！&lt;/p&gt;

</description>
               <pubDate>Wed, 02 Dec 2020 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2020/12/02/%E7%BB%99%E5%A5%B3%E5%84%BF%E7%9A%84%E4%BF%A16</link>
               <guid isPermaLink="true">http://www.luzexi.com/2020/12/02/%E7%BB%99%E5%A5%B3%E5%84%BF%E7%9A%84%E4%BF%A16</guid>
            </item>
        
    </channel>
</rss>