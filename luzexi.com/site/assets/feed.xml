<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title></title>
        <description>漫漫人生,记录点滴技术,始于2013</description>
        <link>http://www.luzexi.com</link>
        <atom:link href="http://www.luzexi.com/assets/feed.xml" rel="self" type="application/rss+xml" />
        
            <item>
               <title>《Unity3D高级编程之进阶主程》第七章，渲染管线与图形学(三) - 渲染原理与知识3</title>
               <description>&lt;h3&gt;GPU Instancing 的来龙去脉&lt;/h3&gt;

&lt;p&gt;GPU Instancing 初次听到这个名词时还有点疑惑，其实翻译过来应该是GPU多实例化渲染，它本身是GPU的一个功能接口，Unity3D将它变得更简单实用。&lt;/p&gt;

&lt;p&gt;===&lt;/p&gt;

&lt;p&gt;前面讲过一些关于Unity3D的动态合批(Dynamic batching)与静态合批(Static batching)的功能，GPU Instancing 实际上与他们一样都是为了减少Drawcall而存在。&lt;/p&gt;

&lt;p&gt;有了动态合批和静态合批为什么还需要 GPU Instancing 呢，究竟他们之间有什么区别呢，我们不妨来简单回顾一下Unity3D动态合批(Dynamic batching)与静态合批(Static batching)。&lt;/p&gt;

&lt;h6&gt;开启动态合批(Dynamic batching)时，Unity3D引擎检测视野范围内的非动画物体(通过遍历所有渲染模型，计算包围盒在视锥体中的位置，如果完全不在视锥体中则抛弃)，如果在视锥体内并且符合条件的就进行合批操作，将他们的网格合并后与材质球一并传给GPU去绘制。&lt;/h6&gt;

&lt;p&gt;需要符合什么条件呢：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    1，900个顶点以下的模型。

    2，如果我们使用了顶点坐标，法线，UV，那么就只能最多300个顶点。

    3，如果我们使用了UV0，UV1，和切线，又更少了，只能最多150个顶点。

    4，如果两个模型缩放大小不同，不能被合批的，即模型之间的缩放必须一致。

    5，如果是不同的材质球实例同样不能被合批，即使他们一模一样。即材质球属性不能被修改，材质球对象实例必须是同一个。

    6，如果他们有lightmap的数据，必须是相同的才有机会合批。

    7，多个pass的Shader是绝对不会被合批。

    8，延迟渲染是无法被合批。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;条件比较苛刻，一不小心就无法达到合并条件。为什么它要使用这么苛刻的条件呢，我们来了解下设计动态合批这个功能的意图。&lt;/p&gt;

&lt;h6&gt;动态合批(Dynamic batching)这个功能的目标是以最小的代价合并小型网格模型，减少Drawcall调用。&lt;/h6&gt;

&lt;p&gt;很多人会想既然合并了为什么不把所有的模型都合并呢，这样不是更减少Drawcall的开销。如果把各种情况的中大型网格都合并进来，就需要消耗巨大的CPU资源，而且在摄像机移动过程中，每帧都要进行合并网格的消耗，CPU算力消耗太大，得不偿失。于是Unity3D就对这种极其消耗CPU算力的功能做了如此多的的限制，就是为了让它在运作时性价比更高。&lt;/p&gt;

&lt;p&gt;与动态合批不同，静态合批(Static batching)并不实时合并网格，而是会在离线状态下生成合并的网格，所有被标记为静态物体的模型，只要拥有相同实例的材质球都会被一并合并成网格。&lt;/p&gt;

&lt;p&gt;静态合批有诸多优点，但也存在不少弊端。被合批的是静态物体，它们是不能被移动旋转和缩放的，也只有这样我们在离线状态下生成的网格才是有效的（离线的网格数据不需要重新计算），生成的离线数据被放在Vertex buffer和Index buffer中。&lt;/p&gt;

&lt;h6&gt;静态合批生成的离线网格将导致存放在内存的网格数据量剧增，因为在静态合批中每个模型都会独立生成一份网格数据，无论他们所使用的网格是否相同，也就是说场景中有多少个静态模型就有多少个网格，与原本只需要一个网格就能渲染所有相同模型的情况不一样了。&lt;/h6&gt;

&lt;p&gt;好处是静态合批后同一材质球实例(材质球实例必须相同，因为材质球的参数要一致)调用Drawcall的数量合并了，另外合批也不会额外消耗CPU算力因为它们是在离线时生成的合批数据(也就是网格数据)，在实时渲染时如果该模型在视锥体范围内，三角形索引被部分提取出来合并后提交，而那些早就被生成的网格将被整体提交(整体网格过大时则会导致CPU和GPU的带宽消耗过大)，最后再一并发送给GPU进行渲染。&lt;/p&gt;

&lt;h6&gt;简而言之，动态合批为了平衡CPU消耗和GPU性能优化，将实时合批条件限制在比较狭窄的范围内。静态合批则牺牲了大量的内存和带宽，以使得合批工作能够快速有效的进行。&lt;/h6&gt;

&lt;p&gt;GPU Instancing 没有动态合批对网格数量的限制，也没有静态网格需要这么大的内存，很好的弥补了这两者的缺陷，但也有存在着比较大的优缺点，我们下面来逐一阐述。&lt;/p&gt;

&lt;p&gt;GPU Instancing 并不像动态和静态合批那样通过对网格的合并操作进行优化，GPU Instancing 的目标是只用一个模型网格绘制很多个地方，这些地方绘制的网格缩放大小，旋转角度和坐标可以不一样，材质球虽然相同但材质球属性可以各自有各自的区别。&lt;/p&gt;

&lt;p&gt;本质上来说 GPU Instancing 调用的是 OpenGL 和 DirectX 里的多实例渲染接口。我们拿 OpenGL 来说:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;glDrawArraysInstanced&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GLenum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GLint&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GLsizei&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Glsizei&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;primCount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;glDrawElementsInstanced&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GLenum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GLsizei&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GLenum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GLsizei&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;primCount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;glDrawElementsInstancedBaseVertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GLenum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GLsizei&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GLenum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GLsizei&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instanceCount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GLuint&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;baseVertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这三个接口正是 GPU Instancing 调用多实例渲染的接口，第一个是无索引的顶点网格集多实例渲染，第二个是索引网格的多实例渲染，第三个是索引基于偏移的网格多实例渲染。调用这三个接口会向GPU传入渲染数据并开启渲染，与平时渲染多次要多次执行整个渲染管线不同的是，这三个接口会分别将模型渲染多次，并且是在一个渲染管线内。&lt;/p&gt;

&lt;p&gt;如果只是一个坐标上渲染多次模型是没有意义的，我们需要将一个模型渲染到不同的多个地方，并且以不同的缩放大小和旋转角度，以及不同的材质球参数，这才是我们真正需要的。&lt;/p&gt;

&lt;p&gt;GPU Instancing 正我们提供这个功能，上面三个渲染接口告知Shader着色器传开启一个叫 InstancingID 的变量，这个变量可以确定在着色计算时使用哪个实例的属性。&lt;/p&gt;

&lt;p&gt;有了这个 InstancingID 就能使得我们在多实例渲染中，辨识到底使用哪个属性参数。Shader的顶点着色器和片元着色器可以通过这个变量来获取模型矩阵、颜色等不同变化的参数。&lt;/p&gt;

&lt;p&gt;我们来看看Unity3D是怎么做的:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Shader&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;SimplestInstancedShader&amp;quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Properties&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;_Color&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Color&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;SubShader&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Tags&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;RenderType&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Opaque&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;LOD&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;Pass&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;CGPROGRAM&lt;/span&gt;
            &lt;span class=&quot;cp&quot;&gt;#pragma vertex vert&lt;/span&gt;
            &lt;span class=&quot;cp&quot;&gt;#pragma fragment frag&lt;/span&gt;
            &lt;span class=&quot;cp&quot;&gt;#pragma multi_compile_instancing&lt;/span&gt;
            &lt;span class=&quot;cp&quot;&gt;#include&lt;/span&gt; &lt;span class=&quot;cpf&quot;&gt;&amp;quot;UnityCG.cginc&amp;quot;&lt;/span&gt;&lt;span class=&quot;cp&quot;&gt;&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;appdata&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;vertex&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;POSITION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;UNITY_VERTEX_INPUT_INSTANCE_ID&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//顶点着色器的 InstancingID定义&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v2f&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;vertex&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SV_POSITION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;UNITY_VERTEX_INPUT_INSTANCE_ID&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//片元着色器的 InstancingID定义&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;UNITY_INSTANCING_BUFFER_START&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Props&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 定义多实例变量数组&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;UNITY_DEFINE_INSTANCED_PROP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_Color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;UNITY_INSTANCING_BUFFER_END&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Props&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;v2f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;appdata&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;v2f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

                &lt;span class=&quot;n&quot;&gt;UNITY_SETUP_INSTANCE_ID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//装配 InstancingID&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;UNITY_TRANSFER_INSTANCE_ID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//输入到结构中传给片元着色器&lt;/span&gt;

                &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;UnityObjectToClipPos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;fixed4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v2f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SV_Target&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;UNITY_SETUP_INSTANCE_ID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//装配 InstancingID&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;UNITY_ACCESS_INSTANCED_PROP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Props&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_Color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//提取多实例中的当前实例的Color属性变量值&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;ENDCG&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上述是一个很普通的调用 Instancing 的Shader，其中&lt;em&gt;Color 和 unity&lt;/em&gt;ObjectToWorld (模型矩阵)是多实例化的，他们通过 InstancingID 索引来确定取数组中的哪个变量。&lt;/p&gt;

&lt;p&gt;为什么这么说呢？我们来看看Shader中这些包含有 INSTANCE 字样的宏定义。&lt;/p&gt;

&lt;p&gt;首先编译命令 multi&lt;em&gt;compile&lt;/em&gt;instancing 会告知着色器我们将会使用多实例变量。&lt;/p&gt;

&lt;p&gt;其次在顶点着色器和片元着色的输入输出结构中，加入 UNITY&lt;em&gt;VERTEX&lt;/em&gt;INPUT&lt;em&gt;INSTANCE&lt;/em&gt;ID 告知结构中多一个变量即：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    uint instanceID : SV_InstanceID;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;每个顶点和片元数据结构中都定义了 instanceID 这个变量，这个变量将被用于确定使用多实例数据数组中的哪个实例参数，很关键。&lt;/p&gt;

&lt;p&gt;接着Shader中要把需要用到的多实例变量参数定义起来:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;UNITY_INSTANCING_BUFFER_START&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Props&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;UNITY_DEFINE_INSTANCED_PROP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_Color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;UNITY_INSTANCING_BUFFER_END&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Props&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上述中的宏很容易从字面看出它们为&amp;quot;开始多实例宏定义&amp;quot;，&amp;quot;对多实例宏属性定义参数&amp;quot;，以及&amp;quot;结束多实例宏定义&amp;quot;。&lt;/p&gt;

&lt;p&gt;这三个宏定义我们可以在 UnityInstancing.cginc 中看到，即:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span&gt;&lt;/span&gt;        &lt;span class=&quot;cp&quot;&gt;#define UNITY_INSTANCING_BUFFER_START(buf)      UNITY_INSTANCING_CBUFFER_SCOPE_BEGIN(UnityInstancing_##buf)&lt;/span&gt;
        &lt;span class=&quot;cp&quot;&gt;#define UNITY_INSTANCING_BUFFER_END(arr)        UNITY_INSTANCING_CBUFFER_SCOPE_END&lt;/span&gt;
        &lt;span class=&quot;cp&quot;&gt;#define UNITY_DEFINE_INSTANCED_PROP(type, var)  type var[UNITY_INSTANCED_ARRAY_SIZE];&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;我们可以上述的宏定义中理解到，这三个宏可以对多实例的多属性数组进行定义。&lt;/p&gt;

&lt;p&gt;于是在顶点着色器与片元着色中，我们对 InstancingID 进行装配，即宏定义：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    UNITY_SETUP_INSTANCE_ID(v) 和 UNITY_SETUP_INSTANCE_ID(i);

    装配过程其实就是从基数偏移的过程 unity_InstanceID = inputInstanceID + unity_BaseInstanceID;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;最终我们通过 UNITY&lt;em&gt;SETUP&lt;/em&gt;INSTANCE&lt;em&gt;ID 装配得到了 unity&lt;/em&gt;InstanceID 即当前渲染的多实例索引ID。&lt;/p&gt;

&lt;p&gt;有了多实例的索引ID，我们就可以通过这个变量获取对应的当前实例的属性值，于是就有了以下的宏定义 UNITY&lt;em&gt;ACCESS&lt;/em&gt;INSTANCED_PROP 以及通过这个宏定义获取变量的代码。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;cp&quot;&gt;#define UNITY_ACCESS_INSTANCED_PROP(arr, var)   var[unity_InstanceID]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;UNITY_ACCESS_INSTANCED_PROP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Props&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_Color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//提取多实例中的当前实例的Color属性变量值&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h6&gt;有了类似_Color的多实例属性操作，在模型矩阵变化中也需要具备同样的操作，我们没看到模型矩阵多实例是因为Unity在Shader编写时用宏定义把它们隐藏起来了，它就是 UnityObjectToClipPos。&lt;/h6&gt;

&lt;p&gt;UnityObjectToClipPos 其实是一个宏定义，当多实例渲染开启时，它被定义成了如下:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;cp&quot;&gt;#define unity_ObjectToWorld     UNITY_ACCESS_INSTANCED_PROP(unity_Builtins0, unity_ObjectToWorldArray)&lt;/span&gt;

&lt;span class=&quot;kr&quot;&gt;inline&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;UnityObjectToClipPosInstanced&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;float3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UNITY_MATRIX_VP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unity_ObjectToWorld&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)));&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;kr&quot;&gt;inline&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;UnityObjectToClipPosInstanced&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;UnityObjectToClipPosInstanced&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xyz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#define UnityObjectToClipPos UnityObjectToClipPosInstanced&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这个定义也同样可以在 UnityInstancing.cginc 中找到，其中unity_ObjectToWorld是关键，它从多实例数组中取出了当前实例的模型矩阵，再与坐标相乘后计算投影空间的坐标。也就是说当开启 Instancing 多实例渲染时，UnityObjectToClipPos 会从多实例数据数组中取模型矩阵来做模型到投影空间的转换。而当不开启 Instancing 时，UnityObjectToClipPos 则只是用当前独有的模型矩阵来计算顶点坐标投影空间的位置。&lt;/p&gt;

&lt;p&gt;到此我们就从着色器中获取了多实例的属性变量，根据不同实例的不同索引获取不同属性变量包括模型矩阵，从而渲染不同位置，不同的旋转角度，不同的缩放大小，以及更多比如_Color的其他属性，整个过程都是围绕着 InstancingID 来做索引操作。&lt;/p&gt;

&lt;h6&gt;知道了 GPU Instancing 是如何渲染还不够，我们还要知道数据是怎么传进去的。&lt;/h6&gt;

&lt;p&gt;我们还是拿 OpenGL 接口编程来分析。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;//获取各属性的索引&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;position_loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;glGetAttribLocation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prog&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;position&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normal_loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;glGetAttribLocation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prog&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;normal&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color_loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;glGetAttribLocation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prog&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;color&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matrix_loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;glGetAttribLocation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prog&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;model_matrix&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//按正常流程配置顶点和法线&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;glBindBuffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GL_ARRAY_BUFFER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;position_buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//绑定顶点数组&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;glVertexAttribPointer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;position_loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GL_FLOAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GL_FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//定义顶点数据规范&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;glEnableVertexAttribArray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;position_loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//按上述规范，将坐标数组应用到顶点属性中去&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;glBindBuffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GL_ARRAY_BUFFER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normal_buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//绑定发现数组&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;glBertexAttribPointer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal_loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GL_FLOAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GL_FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//定义发现数据规范&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;glEnableVertexAttribArray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal_loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//按上述规范，将法线数组应用到顶点属性中去&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//开始多实例化配置&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//设置颜色的数组。我们希望几何体的每个实例都有一个不同的颜色，&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//将颜色值置入缓存对象中，然后设置一个实例化的顶点属性&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;glBindBuffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GL_ARRAY_BUFFER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color_buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//绑定颜色数组&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;glVertexAttribPointer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color_loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GL_FLOAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GL_FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//定义颜色数据在color_loc索引位置的数据规范&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;glEnableVertexAttribArray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color_loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//按照上述的规范，将color_loc数据应用到顶点属性上去&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;glVertexattribDivisor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color_loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//开启颜色属性的多实例化，1表示每隔1个实例时共用一个数据&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;glBindBuffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GL_ARRAY_BUFFER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_matrix_buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//绑定矩阵数组&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;//设置矩阵第一行的数据规范&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;glVertexAttribPointer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matrix_loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GL_FLOAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GL_FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sizeof&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mat4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;sizeof&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;//将第一行的矩阵数据应用到顶点属性上去&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;glEnableVertexAttribArray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matrix_loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;//开启第一行矩阵数据的多实例化，1表示每隔1个实例时共用一个数据&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;glVertexattribDivisor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matrix_loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这个示例很精准的表达了数据是如何从CPU应用层传输到GPU上再进行实例化的过程。&lt;/p&gt;

&lt;p&gt;我在代码上做了比较详尽的注释，首先获取需要推入顶点属性的数据的索引，再将数组数据与OpenGL
缓存进行绑定，这样才能注入到OpenGL里去，接着告诉 OpenGL 每个数据对应的格式，然后再根据前一步描述的格式应用到顶点属性中去，最后如果做的是 GPU Instancing 多实例的属性数据则开启多实例化属性接口，让 InstancingID 起效。&lt;/p&gt;

&lt;p&gt;总结，我们解析了 GPU Instancing 在 Unity3D 中的工作方式，得知了它能用同一个模型同一个材质球渲染不同的位置、角度、缩放大小、以及不同颜色等属性。这种没有对模型网格数量限制，没有占用大量内存的性能优化来说，很好的弥补了动态合批(Dynamic batching)与静态合批(Static batching)的不足。&lt;/p&gt;

&lt;p&gt;但是它毕竟是只能围绕一个模型来操作，只有相同网格(Mesh)和相同的材质球实例(参数可以不同，但必须使用API来设置不同参数)的情况下才能做到多个实例在同一个渲染管线中一次性渲染的优化操作，而动态合批和静态合批却只需要材质球实例一致，网格是可以有差别的。&lt;/p&gt;

&lt;p&gt;三者利弊各不同，有互相弥补的地方，各自本身也存在着不同程度的限制和优缺点。从整体上来看，GPU Instancing 更适合同一个模型渲染多次的情况，而动态合批(Dynamic batching)更适合同一个材质球并且模型面数小的情况，静态合批(Static batching)更适合当我们能容忍内存扩大的情况。&lt;/p&gt;
</description>
               <pubDate>Wed, 20 Nov 2019 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com//2019/11/20/Unity3D%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%9B%E9%98%B6%E4%B8%BB%E7%A8%8B-%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF%E4%B8%8E%E5%9B%BE%E5%BD%A2%E5%AD%A68.html</link>
               <guid isPermaLink="true">http://www.luzexi.com//2019/11/20/Unity3D%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%9B%E9%98%B6%E4%B8%BB%E7%A8%8B-%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF%E4%B8%8E%E5%9B%BE%E5%BD%A2%E5%AD%A68.html</guid>
            </item>
        
            <item>
               <title>思路探讨(三十一) 钱、才、运</title>
               <description>&lt;p&gt;最近几年一直在突破自己的认知，可能是我本身从小对世界的认知水平就比较狭小的缘故，努力了好几年才只是普通人的水平，但对我来说已经是很厉害了，我很满足，山外有山，人外有人，一山还有一山高，一水还有一水深，做好自己最重要。&lt;/p&gt;

&lt;p&gt;从小到大一直无法想明白的一件事是，‘有才’为什么不一定有钱，有钱人为什么不是因为‘有才’才赚到钱。&lt;/p&gt;

&lt;p&gt;===&lt;/p&gt;

&lt;h6&gt;后来才渐渐明白，这是我人生中一个比较大的认知错误，认为钱和才是对等的。&lt;/h6&gt;

&lt;p&gt;钱和才，虽然谈不上完全是两码事，但他们之间的联系确实没有这么紧密，不过‘有才’至少能让你解决温饱问题。&lt;/p&gt;

&lt;h6&gt;一个人有价值(就是有知识，有技能，有经验)和赚到大钱是两码事，很多时候有价值的人能被人看重，但并不一定能赚到钱，因为公司或者说组织不一定能成事，他是厉害了，周围的人不配合不协作，各怀鬼胎，一个人再厉害也无法扭转乾坤，即使周围的人协同性很好而时代潮流不配合也同样无济于事。&lt;/h6&gt;

&lt;p&gt;所以想要赚到大钱，‘天时、地利、人和’一样不能少，这个就是我们俗称的‘运气’。说起来很俗气，‘运气’很神秘，就像神棍一样，没有科学的依据，但确实这个东西真真正正存在我们的周围。&lt;/p&gt;

&lt;p&gt;这个‘运气’，有两种诠释：&lt;/p&gt;

&lt;h6&gt;一种是像稻盛和夫(日本经营之神，创业百分百成功，做什么成什么，企业破产了求他接手，立刻妙手回春)这类的，认为‘运气’是靠自己争取来的，以精神世界为中心，自己积善行德才能积攒足够多的‘运气’，用利他心态来做事，加上不屑努力，最后全社会都会回馈给他以‘运气’，最终靠着这股‘运气’走上成功的道路。&lt;/h6&gt;

&lt;p&gt;另一种是认为‘运气’是随机，就像守株待兔里的农夫，指不定什么时候兔子就自己撞到枪口上了就能有一顿饱肉吃，也像彩票的中奖概率，不知道什么时候就来那么一下，你就什么都有了。&lt;/p&gt;

&lt;p&gt;这两种我更偏向于稻盛和夫的理念，我也一直向他老人家在学习，用利他的心态做事，不屑努力，来感动全宇宙的量子(这个说法是从一本叫做《The Secret》中文叫秘密里看到的，它其实是一部鸡汤成功学的书，它告诉你其实全世界都是量子，你只要拿出你的诚意并且全力拼搏，量子就会被你吸引来帮助你)。&lt;/p&gt;

&lt;p&gt;我们不偏执任何一种，事实上两种都存在，既有自身的因素，也有随机的因素。&lt;/p&gt;

&lt;p&gt;随机的运气也并不是我们表面上看上去那么容易，它很多时候都需要毅力支撑。毅力二字是大多数人成功的秘诀，即使日子再苦再累再无趣，受压迫得再厉害，如果依然能够扛得住，运气就有可能降临到他们身上。&lt;/p&gt;

&lt;p&gt;为什么？因为风险是波动的，当震荡加剧，波幅增大，低谷更低，时间更长时，精神上和肉体上的压力就会增大，无法承受导致崩溃消亡也是正常的现象。大部分人无法承受这种非人的精神压力都选择了退缩，但只要扛过去，通常都是拨云见日，柳暗花明又一村，只是人是脆弱的，99%都选择了退缩，那最后1%中也有一半中途崩溃了，最后剩下的才是苦字熬出头的人，最终运气降临在他们身上，这种看似运气而实非运气的事也很常见。&lt;/p&gt;

&lt;h6&gt;这个世界还是公平的，我们无法把控的‘运气’确实占了成功因素的很大一部分，也只有这样才不是任何人想怎么样就怎么样的么，王思聪有钱有人有才，理论上说没有失败的理由，实际上，他开的公司，创的业，投资标的，不照样该垮的还是垮，”不经历风雨怎能见彩虹，没有人能随随便便成功“。&lt;/h6&gt;

&lt;p&gt;说实在的，我们可以避开赚钱二字不谈，人不一定要赚到足够多的钱才会幸福。&lt;/p&gt;

&lt;p&gt;“没有赚到钱的人生也能幸福”这句话很多人不理解。因为人们把钱看得太重，以至于认为成功就是有钱，有钱才能幸福，把三者划上了等号。&lt;/p&gt;

&lt;p&gt;这个偏执的观念会让人变得很痛苦，人常常会被欲望所控制，越想有钱，越痛苦，越不幸福，是一个恶性循环的开始。&lt;/p&gt;

&lt;h6&gt;我们应该坦然一点才是。​我希望我们能想明白，我们赚钱的目的是什么，如果是养家糊口，那是应该的。如果是追求富足的生活，我觉得该量力而行，别最后钱没赚到人没了情也没了，或者钱有了情没了身体没了，都得不偿失。如果是追求更高的精神境界，我觉得应该有计划的，有进也有退的，以更加稳健的姿态走向目标。&lt;/h6&gt;

&lt;p&gt;我在知乎的问答里看到这么一句话，虽然偏题了但我觉得挺值得深思，他说：”如果一个人到了40几岁，夫妻感情好，每个周还能有性生活，孩子学习成绩好，全家人身体强壮有力，这就是成功“，体会一下。&lt;/p&gt;
</description>
               <pubDate>Sat, 09 Nov 2019 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com//2019/11/09/%E6%80%9D%E8%B7%AF%E6%8E%A2%E8%AE%A831.html</link>
               <guid isPermaLink="true">http://www.luzexi.com//2019/11/09/%E6%80%9D%E8%B7%AF%E6%8E%A2%E8%AE%A831.html</guid>
            </item>
        
            <item>
               <title>思路探讨(三十) 改变自己才能改变孩子</title>
               <description>&lt;p&gt;这4年半的父亲生涯着实让我改变了很多，我从我的女儿身上学到了很多很多东西。&lt;/p&gt;

&lt;p&gt;我知道她是我的镜子，我不经意间的坏习惯都能在她的身上放大很多倍，每次责备她时我都会想到自己的问题，让我心生愧疚。&lt;/p&gt;

&lt;p&gt;===&lt;/p&gt;

&lt;p&gt;我着实明白孩子是张白纸，大部分的行为方式都是从我们日常的行为中学到，她没有这么多的经历和生活经验，所以也无法判断好与坏，只是顺着我们行为方式照着模仿罢了。&lt;/p&gt;

&lt;h6&gt;只是我们也很讨厌我们自己，大部分时候我们自己知道的自己的缺陷和自卑，而通常自己选择了原谅自己，而大部分时候无法原谅孩子有同样的问题。&lt;/h6&gt;

&lt;p&gt;这就像我们生活和工作中那样，总是拿自己做不到的事情来要求别人，我一直记得一句话：对别人是马克思主义，对自己却是自由主义。&lt;/p&gt;

&lt;p&gt;所以我想到了改变自己，我想让女儿知道，并且以自己的行为方式和思维方式让女儿知道，“我们应该怎样做才是正确的，并且做正确的事有很多很多的好处。”&lt;/p&gt;

&lt;p&gt;在正确的道路上行走着实不容易，就像我们以前在学校里上课学习那样，平时的上课学习着实枯燥乏味，如果没有小伙伴能与你一起共同努力共同学习共同生活，我们很难在读书学习这条路上直线的走下去，总是会把注意力跑偏向更加有趣的事物上去。&lt;/p&gt;

&lt;p&gt;因此我知道她要有个伴，这个伴至少应该是个精神上的伙伴，如果还能成为生活中的伙伴那是最好不过的了。(通常我的工作并不允许经常性的陪伴在她身边，但一有时间我就围绕着她)&lt;/p&gt;

&lt;p&gt;我们也像大部分父母那样严格要求女儿去纠正自己的行为习惯，不同的是我们还是觉得我们需要以洞察和理解人性的角度来对待我的女儿，只因为我深刻的认识到其实我们大部分时候，知道和明白她所要做的事情很难突破，很枯燥，很复杂，连我们自己都无法做到，却让孩子去完成。&lt;/p&gt;

&lt;h6&gt;不过无论对女儿有多心疼，多理解，我还是没有放弃对孩子正确的行为习惯和思维方式的教育，只是我想换种方式，我希望这种方式更加彻底，我也明白这种方式的艰难程度。&lt;/h6&gt;

&lt;h6&gt;抱着这种既要女儿纠正行为习惯，要学习，要突破，也同时要理解女儿是我们自己缺点和自卑心理写照的心态，我希望自己走上改变自我再影响她的路线。&lt;/h6&gt;

&lt;p&gt;于是，“改变自己，同时改变女儿，我优秀了女儿也会优秀”，成为了我的教育理念。&lt;/p&gt;

&lt;p&gt;这个教育理念是从我这些年对社会的理解和反思的所得。&lt;/p&gt;

&lt;p&gt;那么我应该怎么改变自己，改变成什么样才是对的。如果我的方向错了，或者偏了，改变的最终效果还是会有问题。&lt;/p&gt;

&lt;p&gt;于是我把这个问题的思考引向了，改变自己到什么样才是对的这个问题上。&lt;/p&gt;

&lt;h6&gt;我首先发现的是安心的心理环境是促成的理智心理的重要因素。&lt;/h6&gt;

&lt;p&gt;理智沉稳的心理状态对学习和生活都是非常有效的帮助。相反，焦躁、恐惧、不安的心态时常会导致效率低下，无法集中注意力，思考的角度也会变得狭窄和阴暗。&lt;/p&gt;

&lt;p&gt;于是我首先让自己时常保持理智，尽量减少情绪的波动，心平气和的与女儿对话，让她感觉到这个氛围是平和的。&lt;/p&gt;

&lt;p&gt;我希望创造一种环境，这种环境中，女儿能很好的思考，包括自己的问题，和别人的问题，环境对她只有促进作用而不是阻碍作用，因此我首先要保证我是理智的，平和的，否则她的思维习惯会跑偏。&lt;/p&gt;

&lt;h6&gt;其次我发现最应该原谅的是别人而不是自己，最应该去帮助别人而不是期待别人的帮助。&lt;/h6&gt;

&lt;p&gt;我们大部分时候都觉得，自己没问题，全是别人的错。这其实是人性的弱点，我们最容易原谅的是自己，最容易责备的是别人，也最容易把希望寄托在别人身上，而自己什么都不做。&lt;/p&gt;

&lt;p&gt;原谅应该更多的体现在对待别人上，只有原谅了别人，事情才会有进展。教育女儿也是一样，我更多的选择理解和原谅女儿的缺点和坏习惯，理解并且明白在困难面前人都是软弱的。&lt;/p&gt;

&lt;p&gt;帮助则更应该体现在对待别人身上，只有通过帮助别人，事情才会有十足的推进。教育女儿也是一样，我更多的去辅助女儿改掉坏习惯，在对她面对的困难的理解之上，逐步纠正她的缺点与习惯，而不是逼迫她。&lt;/p&gt;

&lt;h6&gt;我发现对精神世界改造的重要性&lt;/h6&gt;

&lt;p&gt;面对这个充满焦虑的时代，欲望与恐惧充斥着满世界，我们时常都会不由自主的随波逐流的被世界带着走，被金钱、名誉、权利、地位所吸引，被捆绑，被遏制。&lt;/p&gt;

&lt;p&gt;我反复思考着我们最终人生的意义，我想它肯定不是这些金钱、名誉、权利、地位这些东西，虽然是它们都是我们所渴望的、期盼的，也是避不开的实实在在的‘必需品’。&lt;/p&gt;

&lt;p&gt;但它们毕竟是靠机缘巧合出现的，也时常机缘巧合的消失(眼看他起高楼，眼看他宴宾客，眼看他楼坍塌的事数不甚数)，唯有精神力量才会一直存在下去。&lt;/p&gt;

&lt;h6&gt;精神力量能让我们在面对幸运时更加稳健，在面对低谷时更加冷静沉着，也只有精神力量才能让我们更加持久、幸福、并且优秀的生活下去。&lt;/h6&gt;

&lt;p&gt;于是我希望改造自己成为精神力量的源泉，而不是精神力量的消耗者，锻炼自己拥有更加强大的毅力、耐力、抵抗力，并且将这颗精神力量的种子种在女儿身上，始终鼓励她勇敢的挑战自己，突破自己，让她变得坚强、勇敢、积极乐观。&lt;/p&gt;

&lt;h6&gt;我发现人生中无论大小孩，积累对我们的重要性&lt;/h6&gt;

&lt;p&gt;我发现社会是由‘积累’构成的，无论是财富，名誉，智慧，知识，经验，都是逐日积累而成，而不是一蹴而就的。&lt;/p&gt;

&lt;p&gt;就因为不是一蹴而就的，所以才形成了一种牢固的‘优势’，这种‘优势’不是一日所成(人们总是幻想着能拼几天几星期几个月就能换来‘优势’)，也并不会因一日所垮。‘劣势’或者说坏习惯，也同样不是一蹴而就的，也是通过日复一日，年复一年的积累而成，我们时常担心着潮流会瞬息间转向导致自己无法适应。&lt;/p&gt;

&lt;h6&gt;于是我提出了“每日一小步，每年一大步”的生活和学习理念，我不但要自己每日践行这种自律的理念，也希望女儿心中也能逐步体会到积累的重要性，在我们生活中，每天都积累一些小优势，每年就能积累一个大优势，年复年的坚持下去，最终我和她都将得益于积累，也得以于自律。&lt;/h6&gt;

&lt;h6&gt;对女儿的教育始终源自于我对人性的洞察，我们无法避免的承受着各种各样的缺点和自卑的情节，有时我也原谅自己，但始终未放弃前进，我希望最终我的努力奋进和自我突破的意识，能感动女儿，在她心中种下一颗小小的种子，这颗种子在她潜意识里生根发芽。&lt;/h6&gt;

&lt;h6&gt;女儿的性格是我性格的写照，女儿的习惯是我生活中的点滴所形成的，“改变女儿最有效的方式就是改变自己”这句话始终刻印在我心中，警醒着我不断向更好的自己，更好的家庭，更好的未来前进。&lt;/h6&gt;
</description>
               <pubDate>Mon, 04 Nov 2019 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com//2019/11/04/%E6%80%9D%E8%B7%AF%E6%8E%A2%E8%AE%A830.html</link>
               <guid isPermaLink="true">http://www.luzexi.com//2019/11/04/%E6%80%9D%E8%B7%AF%E6%8E%A2%E8%AE%A830.html</guid>
            </item>
        
            <item>
               <title>《Unity3D高级编程之进阶主程》第五章，资源的加载与释放</title>
               <description>&lt;p&gt;我们在计算机上编程，始终逃不过计算机的体系范围。对于计算机来说不过是进程，线程，CPU，CPU缓存，内存，硬盘，GPU，GPU显存，我们在编程和优化时始终围绕着这个几个关键点在做文章。&lt;/p&gt;

&lt;p&gt;===&lt;/p&gt;

&lt;p&gt;从计算机宏观的角度上来看，计算机本身的内容就这么些，假如我们暂时不去细想具体的逻辑细节，我们可以从大体上明白我们需要做的工作与这些内容有多大的关系。&lt;/p&gt;

&lt;p&gt;我们制作的软件运行在进程上，所以进程是我们的载体，线程可以分担进程的负担，有利于我们更大限度的利用多核CPU，这样就有不只一个CPU为我们工作。&lt;/p&gt;

&lt;p&gt;在PC下CPU的负荷是由多个进程的消耗所组成的但我们只需要关心我们自己进程的消耗，它大部分都是由业务逻辑、算法，内存分配与回收等程序运行所造成的消耗。&lt;/p&gt;

&lt;p&gt;CPU缓存的存在增加了CPU执行命令的命中率，使得CPU执行效率提高。只是CPU只认机器码由1和0组成的命令组合，于是在CPU之上又有了汇编这种语言做中间件，使得我们能够不用去记住0和1的世界，只是这个中间件还需要操作寄存器等直面硬件的事务让我们觉得还是太繁琐。对于庞大的软件系统来说人类无法承受如此庞大复杂度系统下的调试之苦，于是就有了更高级的语言+编译器来让编程变得更加简单，编译器它翻译了我们能容易识别的各种语言包括C++、Java、C#等，它先翻译成中间语言再将中间语言翻译成的二进制码被CPU识别。&lt;/p&gt;

&lt;p&gt;这些高级语言能够让人类更加专注于编写复杂和庞大的软件系统，从而解放了我们直面硬件的痛苦。Unity3D引擎从这层意义上来说也是做了同样的事情，它将大部分对OpenGL/DirectX等图形接口底层的调用都封装好了等我们去用，解放了我们需要学习枯燥复杂的底层的时间，可以将更多的注意力放在对业务逻辑的框架结构和逻辑上。但是在我们制作过程中始终绕不过去的是硬件的工作流程和方式，如果我们想要编写更加优秀的程序，就得学习和理解这些底层原理，也只有这样才能明白我们在编写具体框架逻辑中对计算机是有利还是有弊。&lt;/p&gt;

&lt;p&gt;内存是除了CPU缓存外最快的数据存取地点了，所以要想更快的取得内容就要更多的借助内存，不过也不能无止境的使用内存，比如我们的移动设备，在手机中内存还不是那么廉价或者说容量还不足以可以肆无忌惮的任意使用，即使是PC上内存已经足够大了也要考虑到其他软件进程的内存消耗，不能只顾自己进程的霸占更多内存。&lt;/p&gt;

&lt;p&gt;硬盘在现代已经是很廉价了，硬盘占用的大小已经很少被大家所诟病，不过背后却需要考虑宽带问题。虽然硬盘廉价，但宽带并没有那么廉价，大部分对磁盘的占用都需要从网络上下载下来，这种宽带的占用量其实是紧张的，因此我们经常需要约束对硬盘的占用量，就是为了考虑下载时更多的节省宽带的占用量。&lt;/p&gt;

&lt;p&gt;GPU对CPU的优势是对图形图像的处理比CPU更加强大，它的主要架构和运行模式都是为图形图像而生的，CPU常将大部分图形图像处理都交给GPU去做。从前都是CPU自己处理图形图像，但现代社会中GPU已经不像是以前那么昂贵了，成本已经到了平民化的水平，GPU也已经完全普及在各大设备中。即使是GPU普及的情况下，但GPU的性能好坏也是参差不齐，我们依旧要尽最大的努力去学习和理解GPU的运作原理，以在利用GPU算力时尽可能得发挥其最大优势，以及降低无用的等待与消耗。&lt;/p&gt;

&lt;p&gt;虽然移动设备架构的设计没有将显存加入进去，但显存在PC上却是运用的玲离尽致，显存也确实让GPU在工作效率上升了一个台阶，就像CPU的缓存一样，显存让GPU得到数据和处理数据的效率更高。&lt;/p&gt;

&lt;h6&gt;前面的章节说了这么多关于算法、框架、结构、数学、图形学等，我希望能用更大的角度来观察总结我们所天天需要接触的编程工作。每条语句，每个结构，每个编码都能知道我们现在所要围绕的是哪个节点，是否能通过节点优化来让当前程序的执行更加高效，让程序跑在设备上时更加流畅。&lt;/h6&gt;

&lt;h6&gt;说了这些关于计算机本身的事，寓意是想从宏观的角度看问题，抛开具体的架构、系统逻辑、框架结构等细节来看看我们所面对的工作到底是个怎样的世界。从根本上看我所说这些并不是什么特别具体底层的东西，但是也可以从另一个角度了解我们所面对的编程工作，对我们未来的技术方向会有很大的帮助。&lt;/h6&gt;

&lt;h3&gt;前面讲了很多关于计算机本质的东西，这节我们主要来讲一下关于资源的内容。&lt;/h3&gt;

&lt;h3&gt;资源加载的多种方式&lt;/h3&gt;

&lt;p&gt;虽然资源的格式并不一定要依照引擎来，但如果自己另开辟一种格式来做为自定义资源格式确实耗时耗力，性价比很难适合，虽然也要按项目的需求来，如果是那种资源保密性要求很强的，其实也可以借助Unity3D自身的机制来完成加密工作(下面的章节中会介绍加密)。&lt;/p&gt;

&lt;p&gt;这里我们还是主要来说说以Unity3D自身格式为重点的资源加载方式。&lt;/p&gt;

&lt;p&gt;我们可以把资源加载分为阻塞式和非阻塞式。到底什么是阻塞式什么是非阻塞式呢？&lt;/p&gt;

&lt;p&gt;简单来说，阻塞是当前资源加载完了才能执行下一条语句，非阻塞是开另一个线程(或协程)加载资源，当前的主线程可以继续执行程序，当加载完毕时再通知主线程。&lt;/p&gt;

&lt;p&gt;在Unity3D中阻塞式的加载主要有：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    1.Resource.Load
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Resource.Load是传统的资源加载方式，Unity3D通过Resources这个名字的文件夹来加载资源。&lt;/p&gt;

&lt;p&gt;在移动设备下，Unity3D打包了Resources文件夹的所有资源文件成为1个或几个资源文件(是资源文件合并成1个或几个资源包文件)放入包内，当调用Resource.Load时从这几个资源文件中加载。&lt;/p&gt;

&lt;h6&gt;这个资源包文件会被Unity3D在打包时压缩，保证了包体的大小会适度的减少，压缩的另一面是解压，因此在通过Resource.Load加载时也增加了解压的CPU损耗。这也是很多项目不乐意使用Resources的缘由，解压消耗带给他们不必要的开销，因为CPU资源比硬盘资源珍贵的多。&lt;/h6&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    2.File read + AssetBundle.CreateFromMemory + AssetBundle.Load
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;我们也可以先通过文件操作加载资源文件，再通过AssetBundle.CreateFromMemory的方式把byte数据转换成AssetBundle格式，再通过AssetBundle.Load从AssetBundle中加载某个资源。&lt;/p&gt;

&lt;h6&gt;这种方式看起来费时费力，但是这种方式可以加入我们些许自定义功能。比如能在加载AssetBundle前做加解密操作，加载AssetBundle前自主加载了文件，文件的数据的加解密方式就可以自由的把控，我们可以先用文件操作获得数据后解密，再转换成AssetBundle实例，最后交给资源控制程序处理。&lt;/h6&gt;

&lt;p&gt;不过获得加解密AssetBundle的能力，是需要付出代价的，代价就是内存和GC(内存的分配与销毁)。&lt;/p&gt;

&lt;p&gt;由于用文件操作时完全读入了整个文件的数据，导致当前还不需要的资源也一并读入内存，增大了内存消耗，另外转换成AssetBundle后的byte数据也不再由用处，等待GC的消耗动作，大大增加了内存分配和销毁的CPU负荷。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    3.AssetBundle.CreateFromFile + AssetBundle.Load
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;我们还可以使用通过直接加载文件变成AssetBundle的方式，再通过AssetBundle.Load接口来获得资源。&lt;/p&gt;

&lt;p&gt;这种加载方式最大的好处是按需分配内存。AssetBundle.CreateFromFile并不会把所有资源文件整个加载进内存中，而是先加载数据头，通过数据头中的数据去识别各个资源在文件中的偏移位置，当调用AssetBundle.Load时，根据数据头中对应资源偏移量的记录，找到资源位置，加载数据进入内存，因此我们说它是按需分配内存的。&lt;/p&gt;

&lt;p&gt;在Unity3D中非阻塞式的加载有：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    1.AssetBundle.CreateFromFile + AssetBundle.LoadAsync
    2.WWW + AssetBundle.Load
    3.WWW + AssetBundle.LoadAsync
    4.File Read all + AssetBundle.CreateFromMemory + AssetBundle.Load
    5.File Read all + AssetBundle.CreateFromMemory + AssetBundle.LoadAsync
    6.File Read async + AssetBundle.CreateFromMemory + AssetBundle.Load
    7.File Read async + AssetBundle.CreateFromMemory + AssetBundle.Load
    8.File Read async + AssetBundle.CreateFromMemory + AssetBundle.LoadAsync
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;几种方式主要是由文件读取和AssetBundle异步加载形式组合而成。&lt;/p&gt;

&lt;h6&gt;前2种为主流的异步加载方式。其中第1种用的比较多，因为大多数资源文件都会在游戏开始前进行比对和下载，所以没必要使用WWW的形式从本地读取或从网络下载。&lt;/h6&gt;

&lt;p&gt;其实这里涉及到“为什么要用非阻塞加载”的问题。阻塞式加载这么好用，为什么还要用非阻塞式。&lt;/p&gt;

&lt;p&gt;我们不要为了异步而异步，有人会觉得异步更高级，如果只是为了异步而做异步是没有意义的。大部分情况下我们在使用阻塞式加载资源时，都会遇到一个问题，在某一帧加载的资源很多，加载完毕后需要实例化的资源也很多，从而导致画面在这一帧耗时特别长，画面卡顿现象特别不严重，用运营同学们的话说“对用户来说不友好”。为了能更好更平滑的过度场景，我们需要把要加载和实例化的时间跨度拉长，虽然增加了些许等待时间，却能平滑过渡到最终我们需要的画面。&lt;/p&gt;

&lt;h6&gt;具体怎么做呢。其实不复杂的，可以先获取所有需要加载的资源，放入队列中，每次加载N个(N可以根据实际情况调整)，如果已经加载过的就直接通知逻辑程序实例化，不曾被加载的则调用加载程序并将调用后的加载信息(AssetBundleRequest)放入‘加载中’队列，不开携程而是用Update帧更新去判断‘加载中’队列中是否有完成的，每加载完毕一个资源先从‘加载中’队列里移除，再通知逻辑程序再进行实例化，直到队列中的请求加载完毕为止，继续下一个N个加载请求。当然这里也需要做些判断，例如已经在加载队列里的资源不重复加载等一些避免重复加载的判断。&lt;/h6&gt;

&lt;h3&gt;AssetBundle的引用计数方式卸载&lt;/h3&gt;

&lt;p&gt;Assetbundle在加载后我们需要寻求释放，只有加载没有释放内存只会不断攀升。该怎么释放就成了问题，因为资源使用的地方太多，太庞杂，所以为了能更好的知道什么时候该释放资源，我们需要制定一个规则，这个在遵守这个规则的前提下，我们就知道什么时候资源没有被再使用了，有多少个地方在使用。&lt;/p&gt;

&lt;p&gt;引用计数就是判断这种释放依据的很好的技巧，具体方式为如下：&lt;/p&gt;

&lt;h6&gt;我们对AssetBundle包装一个计数器(是个整数)，当需要某个AssetBundle时先加载所有依赖的AssetBundle，每加载一个AssetBundle就为该AssetBundle的引用计数加1。&lt;/h6&gt;

&lt;p&gt;如果调用的是Prefab，会通过Instantiate进行实例化，这里必须在每次实例化时对该AssetBundle引用计数加1，不过这样在实例化时才做引用计数加1的手法，又消耗了些许我们的注意力而且容易遗漏，我们可以选择一次实例化调用一次加载，这样就节省了人额外的注意力，少一点主意力的消耗，就少一些遗漏。&lt;/p&gt;

&lt;p&gt;如果是Texture贴图这种不需要进行实例化的资源则最好不要被再次被引用，因为被再次引用会导致引用计数的错乱，我们可以选择每次当需要Texture时通过查看AssetBundle是否加载，有则直接取，没有则加载后再取，每次取资源时都对相应的AssetBundle计数加1。&lt;/p&gt;

&lt;h6&gt;当Destroy销毁实例或者不需要用资源时，则统一调用某个自定义的Unload(假设这个接口名字是自定义类AssetBundleMrg.Unload)接口并附上加载时的关键字(为了能更快的找到AssetBundle实例)，从而将对应的AssetBundle的引用计数减1。&lt;/h6&gt;

&lt;p&gt;减少引用计数后，倘若该AssetBundle引用计数为0，则认为可以进行AssetBundle卸载，则立即卸载。&lt;/p&gt;

&lt;p&gt;但是问题又来了，及时的卸载也会有问题，因为每次都卸载后又需要该资源时需要再加载，中间消耗的IO和CPU也很多，我们可以通过增加空置倒计时时间来给卸载AssetBundle一个预留时间。&lt;/p&gt;

&lt;p&gt;当需要卸载时，AssetBundle进入倒计时，比如5秒，5秒内仍然没有任何程序使用这个资源则立即进行卸载，如果5秒内又有程序加载该AssetBundle资源则继续使用引用计数来判断是否需要进入卸载倒计时。&lt;/p&gt;

&lt;p&gt;不过还是有个小问题，如果大量资源在同一时间卸载，就会造成大量资源同一时间进入倒计时，倒计时完毕同时进行卸载，也会带来1帧消耗过大的问题，毕竟资源的卸载时内存的消耗，大量的内存在同一时间销毁会带来大量的CPU消耗。此时我们可以对倒计时进行随机2-5秒的时间内随机一个值，让卸载分散在这个时间段内，让卸载的消耗更加平滑。&lt;/p&gt;

&lt;h3&gt;AssetBundle的打包与颗粒度大小&lt;/h3&gt;

&lt;p&gt;Unity3D对AssetBundle的封装做的很好，当我们在打包AssetBundle时Unity3D会自动去计算AssetBundle与AssetBundle之间的依赖关系，所以我们能很轻松的将资源打的很细(贴图，网格，Shader，Prefab，每个资源分的很开)。&lt;/p&gt;

&lt;p&gt;这使得我们能很轻松得让一个AssetBundle只装一个资源文件并且控制起来也得心应手，只要在加载时读取存有依赖关系的AssetBundle就能得到AssetBundle之间的依赖关系数据(AssetBundleManifest实例数据)，根据这个依赖数据我们就能轻松的加载相关的其他AssetBundle。&lt;/p&gt;

&lt;p&gt;既然AssetBundle颗粒度可以很容易的缩放，那么我们就需要考虑颗粒度的大小到底对项目产生多大的影响。&lt;/p&gt;

&lt;p&gt;我们说说左右两种极端状态下的表现。&lt;/p&gt;

&lt;h6&gt;一种为颗粒度极粗状态，所有资源都打成一个AssetBundle包，所有逻辑程序要的资源都从这个AssetBundle里取。引用计数，在这里已经完全没有了用处，由于只有一个AssetBundle已经完全没有卸载的可能了。这导致了内存只会逐步增大，而绝不会因为不再需要某资源而卸载AssetBundle(当前AssetBundle的卸载机制中没有只销毁某部分资源的功能)。&lt;/h6&gt;

&lt;p&gt;我们来看看整个过程，从一个很大的文件包从网络上下载下来，解压后成为一个AssetBundle文件，然后我们读取它并从中获得资源。从这个过程来看只有一个AssetBundle的极限状态下，文件操作的数量极低，导致读取AssetBundle文件信息没有障碍，解压的IO连续性非常高，导致解压时不需要创建很多文件从IO上会相对比较快些，同时由于只有一个文件内容所以打包的压缩率也是最大的。&lt;/p&gt;

&lt;h6&gt;另一种为颗粒度极细状态，所有贴图、网格、动画、Shader、Prefab都各自打自己的一份AssetBundle(一份AssetBundle只带一个资源)。为了能更有效的控制内存，AssetBundle之间的依赖关系和引用计数在这里用处非常大。通过引用计数和依赖关系，我们能很有效的控制逻辑系统中需要的资源和内存中的资源是一致的。&lt;/h6&gt;

&lt;p&gt;我们来看看整个过程，从网上下载下来所有AssetBundle资源文件，对每个压缩过的资源文件进行解压，当需要某个资源时从AssetBundle读取资源并且读取前先根据依赖关系读取需要的资源，并且对所有加载过的AssetBundle引用计数加1。当卸载时，对当前卸载的AssetBundle引用计数减一，并且对存有需求上依赖关系的其他AssetBundle也减一（由于当前资源卸载后对其他依赖资源不再引用），如果引用计数为0则启动卸载。&lt;/p&gt;

&lt;p&gt;我们从这个过程看来，一个极限细分颗粒度状态下的AssetBundle机制，文件操作数量会很大，IO操作的时间会因为文件增多的增大许多，导致下载时间拉长，下载完毕后解压的总时间也会拉长，打包时由于每个文件单独打包压缩因此压缩比率会降低压缩时间加长。&lt;/p&gt;

&lt;p&gt;上述分析了两种极限状态下的利弊，我们可以根据自己项目的需求来定制AssetBundle打包机制。&lt;/p&gt;
</description>
               <pubDate>Sat, 02 Nov 2019 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com//2019/11/02/Unity3D%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%9B%E9%98%B6%E4%B8%BB%E7%A8%8B-%E8%B5%84%E6%BA%90%E7%9A%84%E5%8A%A0%E8%BD%BD%E4%B8%8E%E9%87%8A%E6%94%BE.html</link>
               <guid isPermaLink="true">http://www.luzexi.com//2019/11/02/Unity3D%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%9B%E9%98%B6%E4%B8%BB%E7%A8%8B-%E8%B5%84%E6%BA%90%E7%9A%84%E5%8A%A0%E8%BD%BD%E4%B8%8E%E9%87%8A%E6%94%BE.html</guid>
            </item>
        
            <item>
               <title>《Unity3D高级编程之进阶主程》第七章，渲染管线与图形学(三) - 渲染原理与知识2</title>
               <description>&lt;p&gt;这节我们将继续补充前面渲染管线中没有讲到的渲染知识和原理。&lt;/p&gt;

&lt;h3&gt;Filter 滤波方式&lt;/h3&gt;

&lt;p&gt;Filter滤波其实在图形引擎中被用到的地方有很多，我们在做项目时却很少察觉到，它的重要性不容忽视。Filter 滤波到底是什么呢？下面我们来讲讲它的来龙去脉。&lt;/p&gt;

&lt;p&gt;===&lt;/p&gt;

&lt;p&gt;一张纹理贴图可以是线性的，正方形的，长方形，甚至三维形式的，当它们被映射到网格表面，再变换到屏幕坐标系之后，纹理上的独立纹素(纹素)几乎不可能直接和屏幕上的最终画面像素直接对应起来。为什么呢？&lt;/p&gt;

&lt;p&gt;因为屏幕上的物体可能是放大后的效果，或者离摄像机很近导致物体需要被放大在屏幕上，这样就导致是屏幕上的一个像素只是对应纹理贴图上一个纹素的一部分（因为被放大了），或者也有可能物体被缩小了，或者离摄像机很远，这时一个像素可能包含很多纹素（因为被缩小了）。因此一个纹素与一个像素通常都是无法一一对应的。&lt;/p&gt;

&lt;p&gt;无论哪种情况我们都无法精确的知道应该使用哪些纹素值，以及如何对它们求平均值或插值。OpenGL就为我们提高了多种Filter 滤波方式，不同的滤波方式在速度和画质上做出了不同的权衡。&lt;/p&gt;

&lt;p&gt;滤波一般分两种，一种是最近采样即Nearest，一种是线性采样即Linear。在Unity3D中Point类型的采样就是最近采样(Nearest Point Sampling)，线性采样在Unity3D中又分为双线性采样(Bilinear)和三线性采样(Trilinear)。&lt;/p&gt;

&lt;p&gt;最近采样，即当纹素与像素大小不一致时，取最接近的纹素进行采样。虽然使用了Mipmap技术，但像素点与纹素仍然没有得到很好的匹配，所以这种方法在纹理需要进行放大或缩小时，结果会变形难看。于是就有了更好的双线性采样算法。&lt;/p&gt;

&lt;p&gt;双线性采样，是取离纹素最近的4个纹素，取得的纹素与中心点的纹素的距离就是参与计算的权重值，把所有采样得到的纹素进行加权平均后得到最终的像素颜色。&lt;/p&gt;

&lt;p&gt;双线性过滤是怎么计算的这4个纹素呢？假设源图像大小为m x n，目标图像为a x b。那么两幅图像的边长比分别为：m/a和n/b。目标图像的第（i,j）个像素点（i行j列）可以通过边长比对应到源图像。其对应坐标应该为（i&lt;em&gt;m/a,j&lt;/em&gt;n/b）。显然这个对应坐标一般来说不是整数，而非整数的坐标是无法在图像中使用。双线性插值通过寻找距离这个对应坐标最近的四个像素点，来计算该点的像素值。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    映射点计算方法:

    srcX=dstX* (srcWidth/dstWidth)+0.5*(srcWidth/dstWidth-1)

    srcY=dstY* (srcWidth/dstWidth)+0.5*(srcWidth/dstWidth-1)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/book/7/g1.png&quot; alt=&quot;双线性过滤&quot;&gt;&lt;/p&gt;

&lt;p&gt;双线性过滤像素之间的过渡更加平滑，但是它只作用于一个MipMap Level,它选取纹素和像素之间大小最接近的那一层MipMap进行采样。当和像素大小匹配的纹素大小在两层Mipmap Level之间时，双线性过滤在有些情况效果就不太好。于是就有了三线性过滤。&lt;/p&gt;

&lt;p&gt;三线性过滤以双线性过滤为基础。对像素大小与纹素大小最接近的两层Mipmap Level分别再进行一次双线性过滤，然后再对两层得到的结果进行线性插值。&lt;/p&gt;

&lt;p&gt;上面的几种线性过滤外，还有各向异性过滤(Anisotropic Filtering)。什么是各向异性和同性呢：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    各向同性，当需要贴图的三维表面平行于屏幕就是各向同性。

    各向异性，当要贴图的三维表面与屏幕有一定角度的倾斜则是各向异性。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;各向异性过滤，除了会把Mipmap因素考虑进去外，还会把纹理与屏幕空间的角度这个因素考虑进去。它会考滤一个像素对应到纹理空间中在u和v方向上与u和v的比例关系，如果u:v不是1:1时，将会按比例在各方向上采样不同数量的点来计算最终的结果。&lt;/p&gt;

&lt;p&gt;各向异性采样的多少取决于Anisotropic Filtering的X值，所以在Unity3D的纹理图片设置上有一个Aniso Level的设置选项，用来设置Anisotropic Filtering的级别。&lt;/p&gt;

&lt;p&gt;采样方式从，最近采样，到双线性过滤，到三线性过滤，再到各向异性过滤，采样次数一级级提高，最近采样1次，双线性采样4次，三线性采样8次，各向异性采样随着等级不同各有不同，效果也是一级级的提高，随着采样次数的提高需要消耗的GPU也会逐级提高(这些都是在OpenGL或DirectX中完成的)，因此我们在设置图片过滤时需要权衡画质与性能。&lt;/p&gt;

&lt;h3&gt;光照阴影是如何生成的&lt;/h3&gt;

&lt;p&gt;前面讲了很多关于Mipmap和纹理采样的知识，对Mipmap和纹理采样的理解对底层画面渲染的理解有很大的帮助。这些所讲的内容也同样具有重大意义，阴影涉及到实际生活中的知识在渲染中是如何模拟的，让原本虚拟的计算机画面更加拟真现实生活。&lt;/p&gt;

&lt;p&gt;为了能让场景和人物看起来更加真实，光影效果是不可或缺的。我们经常能在画面中看到阴影跟随着物体摆动而变动，并且物体被光照遮挡的阴影投射在其他物体上，这样的效果十分动人，那么阴影是如何产生的呢？我们来细致的解析一下，通过解析我们能够更加深刻的理解阴影的生成原理，还可以通过对阴影原理的理解来有针对性的优化阴影对性能的消耗。&lt;/p&gt;

&lt;p&gt;我们可以首先考虑真实生活中阴影的产生流程，当一个光源发射一条光线遇到一个不透明物体时，这条光想不能再继续照亮它背后的物体。因此这个物体背后的物体就会产生阴影，这些阴影区域的产生是因为光线无法到达这些区域。&lt;/p&gt;

&lt;p&gt;在计算机的实时渲染中我们无法用表达出每条光照的射线，我们是如何做到阴影的投射的呢？&lt;/p&gt;

&lt;p&gt;其实可以很简单，假设，我们将摄像机放在光源的位置上，方向与光源照射的方向重合，那些看不到的地方就成了阴影产生的地方。不过，我们不可能真的将摄像机放在那里，但却可以用这种形式的方式，单独渲染一次在摄像机在该位置的图像。只有图像不行，我们需要的是阴影，刚好物体从该位置渲染出来的片元的深度值提供了我们需要的数据，将所有片元的深度值都写入深度缓存中后，我们就可以利用这个深度缓存做阴影的计算了，深度值越大的片元被遮挡的可能性越大，深度值最小的片元不会被遮挡。&lt;/p&gt;

&lt;p&gt;这就是阴影映射纹理(Shadow Map)技术，即在渲染中第一个渲染流程(pass)负责在光源点位置计算得到深度值，输出像素到阴影映射纹理(Shadow Map)。我们实质上得到是一张深度图，它记录了从该光源的位置出发，能看到的场景中距离它最近的表面位置的深度信息。&lt;/p&gt;

&lt;p&gt;只是这张阴影映射纹理对于我们人类来说不够直观，如果想要更好更直观的看到当前摄像机屏幕上的阴影图就更好了。屏幕空间的阴影投影技术(Screenspace Shadow Map)就产生了这种直观的效果，性能和效率也更高，不过它需要显卡支持MRT(Multiple Render Targets)，有些移动平台并不支持这种特性。&lt;/p&gt;

&lt;p&gt;当使用了屏幕空间阴影投射技术(Screenspace Shadow Map)时，Unity3D会让从光源出发的深度图与摄像机产生的深度图做比较，如果摄像机的深度图中记录的点的表面深度大于转化到光源出发生成的深度图的点的深度，那么就说明表面虽然是可见的但却处于该光源的阴影中。通过这样的方式，屏幕空间阴影投射技术(Screenspace Shadow Map)得到了当前摄像机屏幕空间中的阴影区域，即得到了当前摄像机屏幕的阴影图。&lt;/p&gt;

&lt;p&gt;到这里，我们已经得到了阴影映射纹理，不管是传统的阴影图还是屏幕空间阴影图，我们都可以根据这张阴影图来计算出投射到物体的阴影了，那么阴影图有了，应该怎么投射呢？&lt;/p&gt;

&lt;p&gt;主动计算投射到其他物体产生阴影是比较难的，但反过来，根据阴影图主动计算当前渲染物体上的片元是否被阴影是相对比较容易。我们会看到Unity3D在渲染物体上看到有生成阴影和接受阴影两个选项，即Cast Shadows 和 Receive Shadows。&lt;/p&gt;

&lt;p&gt;传统的接受阴影的方式，是将当前顶点的位置变换到光源点的空间下得到它在光源空间中的位置，再根据xy轴分量对阴影映射纹理(Shadow Map)进行采样，从而得到阴影映射纹理中该位置的深度值，如果这个深度值小于该顶点的深度值即z轴分量，那么说明该点位于阴影中，于是在片元颜色输出上加深阴影颜色，反之则没有被阴影遮盖。&lt;/p&gt;

&lt;p&gt;在屏幕空间阴影映射技术中(Screenspace Shadow Map)则可以更加方便一点，因为已经得到了当前摄像机整个屏幕的阴影图，不需要再进行额外的计算，只需要在当前屏幕位置对阴影图进行采样便能知道是否在阴影下，即将当前顶点坐标从模型空间变换到屏幕空间后使用这个坐标对阴影图进行采样即可。相对于传统的阴影渲染来说，屏幕空间阴影映射技术提高了更多的GPU性能效率。&lt;/p&gt;

&lt;p&gt;在Unity3D中使用 LightMode 为 ShadowCaster 的Pass标记为阴影生成管线。当Unity3D在渲染时会首先在当前Shader中找到LightMode为ShadowCaster的Pass，如果没有则会在Fallback指定的Shader中继续寻找，如果没有则无法产生阴影，无论传统的阴影投射还是屏幕空间阴影投射都需要第一步先产生阴影纹理图(Shadow Map)。当找到LightMode为ShadowCaster的Pass后，Unity3D会使用该Pass来制作光源的阴影映射纹理(Shadow Map)。&lt;/p&gt;

&lt;h3&gt;Lightmap烘培原理&lt;/h3&gt;

&lt;p&gt;随着硬件技术的发展，人们对场景的画质效果越来越高，实时光照早已经满足不了人们对画质的需求，想要更加细腻真实光照效果，只能通过离线的烘培技术才能达到理想画质的效果。&lt;/p&gt;

&lt;p&gt;全局光照，简称GI(Global Illumination)，是在真实的大自然中，光从太阳照射到物体和地面再经过无数次的反射和折射，使得地面的任何物体和地面都叠加着直接照射的光和许许多多物体反射过来的间接光(反射光)，导致我们从眼睛里看到画面是光亮又丰富的。&lt;/p&gt;

&lt;p&gt;这种无数次反射和折射形成的高质量画面，才是人们在3D游戏画面中真正想要看到的。但是即使今天硬件技术发展的如此迅速，也无法做到实时的进行全局光照(Realtime Global Illumination)，这样计算量太大，CPU和GPU都无法负担起这个重任。&lt;/p&gt;

&lt;p&gt;离线全局光照就担负起了这个丰富画面光照效果的重任，它不再需要这么多的实时计算的CPU和GPU算力，只要1张或几张光照图(Lightmap)就能将全局光照的效果复原到物体上，不过也仅限于场景静态物体的光照烘培。&lt;/p&gt;

&lt;p&gt;其实烘培这趟水很深，如果要具体深入到工程上的实现，涉及到的算法和图形学知识非常多，这里并不打算深究，而是讲讲我们能相对容易获得的关于Lightmap的原理和知识。根据这个原理，我们在项目的制作和优化中能起到很好的作用。&lt;/p&gt;

&lt;p&gt;什么是烘焙？个人认为从英文‘Bake’翻译过来有点偏差，导致很多工具按钮用‘Bake’表示时，很多人都同样把它理解成了烘培，其实更应该理解为‘制作’。&lt;/p&gt;

&lt;p&gt;烘培简单地说, 就是把物体光照的明暗信息保存到纹理上, 实时绘制时不再需要进行光照计算, 而是采用预先生成的光照纹理(Lightmap)来表示明暗效果。&lt;/p&gt;

&lt;p&gt;我们在渲染3D模型时用到的基本都是顶点，UV，纹理贴图等(这里不多展开)，在顶点上设置UV，形成片元后就成了顶点间的插值UV，用这个UV坐标去纹理贴图上取得颜色值，再填充到帧缓存中最后显示到画面上。&lt;/p&gt;

&lt;p&gt;光照纹理(Lightmap)的显示也是同样道理，用UV坐标来取得光照纹理(Lightmap)上的颜色，最后叠加到片元颜色上输出给缓存。&lt;/p&gt;

&lt;p&gt;这其中的UV有一点讲究。我们在制作模型时的UV数据可以有很多个，其中UV0主要是为了映射贴图纹理而用，在模型制作过程就在模型数据中制作好了，而UV1也就是我们程序中的uv2或俗称的2u，主要是为Lightmap做准备的，还有UV2即程序中的uv3，是为实时全局光照准备的，只有UV3即程序中的uv4开始才是我们程序可以自定义使用的UV数据，其实uv可以有很多个uv5，uv6，不过Unity3D的网格类(Mesh)暂时只提供到uv4的获取接口。&lt;/p&gt;

&lt;p&gt;既然光照纹理(Lightmap)存储的是光照信息，那么它到底存了哪些信息呢？我们先来看下这幅图：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    缺图
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这幅图解释了烘培的简单模型，它分为三个部分，第一部分为光线射到墙壁后反射过来照到模型上，第二部分为光线照射过来时被其他模型挡住，导致当前的模型没有被光线照射到并且有阴影产生，第三部分为光线直接照射到模型上产生的颜色信息。&lt;/p&gt;

&lt;p&gt;这三者之和最终形成了完全的光照颜色。可以用一个简单的公式来说明这三者的结合方式：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    光照颜色 = 间接光照颜色 + 直接光照颜色 * 阴影系数(0到1)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;由于直接光的计算代价比较少，在一些光照并不复杂的场景中不记录直接光信息，而是由Shader自己计算直接光照。因此我们能看到，很多项目并没有记录直接光，而只是记录间接光，即光照纹理中只记录了从其他物体反射过来的光产生颜色的总和，加上另一张阴影纹理记录产生阴影部位的信息。如果你希望记录在光照纹理中主要光的方向，则可以开启Directional Model的Directional来获得，这个文素上主要光的方向信息可以被用在Shader中作为计算的变量。&lt;/p&gt;

&lt;p&gt;现在我们知道了烘培(Bake)会最多产生3种贴图，一种是光照纹理图(可能是间接光照纹理图，也可能是间接光照+直接光照+阴影合并的纹理图，取决于你在Unity3D中Lighting Mode的设置)，一种是阴影纹理图，一种是主要光方向纹理图，以及模型的UV2数据。&lt;/p&gt;

&lt;p&gt;其中UV1(不是UV2，因为uv对应UV0，uv2对应UV1)会被加载到模型网格信息中去，也就是烘培后模型prefab的mesh.uv2的数据会被改写。因此我们在制作和导出模型时要注意，烘培需要用到模型的uv2数据，在导出模型时如果没有导出uv2数据，则无法得到正确的烘培。&lt;/p&gt;

&lt;h6&gt;那么烘培器是如何生成uv和贴图的呢？我们需要理解下UV Chart&lt;/h6&gt;

&lt;p&gt;在烘培时，烘培器会对所有场景中的静态物体上的Mesh网格进行扫描，按块大小和折线角度大小来制作和拆分Mesh上的对应的UV块，这个UV块就是UV Chart。&lt;/p&gt;

&lt;p&gt;UV Chart是静态物件在光照纹理(Lightmap)上某块Mesh的对应的UV区块，一个物体在烘培器预计算后会有很多个UV Chart。因此每个物件的UV Charts是由很多个UV Chart组成，每个UV Chart为一段连续的UV片段。默认情况下，每个Chart都至少是4x4的纹素，无论模型的大小一个Chart都需要16个纹素。UV Chart之间预留了0.5个像素的边缘来防止纹理的溢出。如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/book/7/uvchart.png&quot; alt=&quot;UV Chart0&quot;&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    图0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/book/7/LightingGiUvs-2.png&quot; alt=&quot;UV Chart1&quot;&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    图1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/book/7/LightingGiUvs-4.png&quot; alt=&quot;UV Chart2&quot;&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    图2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/book/7/LightingGiUvs-0.jpg&quot; alt=&quot;UV Chart3&quot;&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    图3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;图中1描述了，当一个场景只有1个正方形物体时，这个正方体网格物体被烘培后，6个面上的UV Chart是如何映射到烘培纹理上的。图2描述了场景中当有多个简单的立方体时，每个物体被扫描后制成UV Chart的情况。图3描述了当烘培场景更加复杂时，扫描后UV Chart被制作的情况，不同规格的模型UV被映射到Lightmap纹理贴图上。&lt;/p&gt;

&lt;p&gt;我们很清晰的能从图中了解到，在烘培时，每个场景中的静态物体都会被扫描网格，并且将计算出来的UV Chart合起来制作成一张或几张(可能场景太大一张不够用)光照纹理贴图。&lt;/p&gt;

&lt;h6&gt;那么什么决定了烘培中扫描网格时形成的UV Chart大小和数量呢？相邻顶点间的最大简化距离和最大夹角值。&lt;/h6&gt;

&lt;p&gt;烘培器为了能更加快速的计算制作出UV Chart，烘培器需要对模型面的顶点扫描进行简化。简化方式为，将相邻顶点间距离小于某个数值的顶点归入一个UV Chart，当这个数值设置相对比较大时，UV Chart生成的速度就会加快。但是只是距离上的简化往往会出现很多问题，我们需要从相邻面的角度上进行约束，即当相邻面间的角度大于某个值时，不能简化成同一个UV Chart。这两个参数在Unity3D中都有设置，点击静态物体在右边的版面上就能看到。如图位置：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/book/7/LightingGiUvs-3.png&quot; alt=&quot;UV Chart1&quot;&gt;&lt;/p&gt;

&lt;p&gt;图中展示了静态物体Mesh Renderer中设置Lightmap UV生成参数，参数包括最大简化顶点距离，最大邻接面角度。&lt;/p&gt;

&lt;p&gt;当设置的最大简化距离和邻接面最大角度数值比较大时，计算生成UV Chart的数量就会比较少，相反如果设置的最大简化距离和最大邻接面角度比较少，则需要计算和生成的UV Chart会比较多，烘培的速度也会比较慢，因为在预计算实时全局光照(GI)时，每个UV Chart上的像素都会计算灯光，预计算的时间跟Chart的数量有很大关系。&lt;/p&gt;

&lt;h6&gt;上述描述了烘培的前置制作中Lightmap纹理分布和场景中物体的UV映射的原理，那么绘制Lightmap纹理贴图时纹理上颜色是怎么生成的呢？&lt;/h6&gt;

&lt;p&gt;我们知道如果不用烘培，在实时渲染中，因为算力的原因我们只能计算直接光对物体的明暗影响，如果想要在实时渲染中计算间接光的影响是非常消耗GPU的算力的，即使有足够强大的显卡支撑使用光线跟踪计算，也只能在带有RTX的显卡计算机上使用。暂时还没有做到普及的程度，因此离线烘培成了我们解决间接光的主要手段。&lt;/p&gt;

&lt;p&gt;在一个场景中如果这些物体只考虑直接光的影响，则会缺乏很多光影细节，导致视觉效果很“平”。而间接光则描述了光子在物体表面之间的反弹，增加了场景中明暗变化以及光线折射的细节，提高了真实感。&lt;/p&gt;

&lt;p&gt;光照纹理贴图的颜色主要是根据光的折射与反射现象来计算的，这里我们需要了解一下Unity3D中采用的Enlighten和Progressive Lightmapper算法解决方案。&lt;/p&gt;

&lt;p&gt;全局照明可以用一个称为渲染方程的复杂方程来描述：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/book/7/LightingGi-1.png&quot; alt=&quot;渲染方程&quot;&gt;&lt;/p&gt;

&lt;p&gt;这个渲染方程定义了光线是如何离开表面上某个点的。但是这个积分方程太复杂以至于无法快速计算出结果，Unity3D中Enlighten采用的近似方法即辐射算法，可以大大提高计算渲染方程式的速度。&lt;/p&gt;

&lt;p&gt;辐射算法假设了场景中存在一组有限的静态元素，以及仅有漫射光传输来简化计算。在计算过程中它把场景拆分成很细很细的面片，分别计算它们接受和发出的光能，逐次迭代直到每个面片的光能数据不再变化(或者到一定的阀值)为止，得到最终的光照图。&lt;/p&gt;

&lt;p&gt;场景拆分后的以及每个面片之间的作用，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/book/7/LightingGi-2.png&quot; alt=&quot;渲染方程&quot;&gt;&lt;/p&gt;

&lt;p&gt;Enlighten将场景切割成很多个面片我们称它们为Cluster(Cluster大小可以通过Unity3D的烘培设置数值大小)，这些Cluster会对其映射的静态物体的纹理中的反射系数进行采样，然后计算Cluster之间的关系，使得光在Cluster之间传递。&lt;/p&gt;

&lt;p&gt;Enlighten将渲染方程简化成了迭代公式即：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/book/7/LightingGi-3.png&quot; alt=&quot;渲染方程&quot;&gt;&lt;/p&gt;

&lt;h6&gt;其中Bi指的是在i点最终的光，Le是i点本身的光，而两个Cluster之间光的反弹系数有Fij来决定，Lj则是J点的光。这也是为什么Enlighten能够支持场景物体不变的情况下允许光源发生变化的原因：因为几何体素化和辐射系数计算代价比较大，需要离线计算，而迭代每个Cluster形成最终结果则计算量相对比较小可以实时进行。&lt;/h6&gt;

&lt;p&gt;Progressive Lightmapper即渐进式光照贴图，是Unity3D 2018版本后才能使用的烘培算法。&lt;/p&gt;

&lt;p&gt;Progressive Lightmapper是一种基于路径追踪（fast path-tracing-based）的光照贴图系统，它能在编辑器中逐步刷新的烘焙光照贴图（baked lightmaps）和光照探针（Light Probes）。&lt;/p&gt;

&lt;p&gt;Progressive Lightmapper主要的优势是能随着时间的推移逐步细化输出画面，及时逐步的看到画面效果，这样能够实现更完善的交互式照明工作流。另外Progressive Lightmapper还提供了一个预估的时间，所以烘焙时间更加可预测。&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《OpenGL编程指南》&lt;/p&gt;

&lt;p&gt;《OpenGL ES 3.0编程指南》&lt;/p&gt;

&lt;p&gt;《Unity移动平台下的烘焙使用及优化》&lt;/p&gt;

&lt;p&gt;《浅析Unity中的Enlighten与混合光照》&lt;/p&gt;

&lt;p&gt;《Progressive CPU Lightmapper》&lt;/p&gt;

&lt;p&gt;《光照贴图Lightmap初探》&lt;/p&gt;

&lt;p&gt;《辐射度算法(radiosity)原理》&lt;/p&gt;
</description>
               <pubDate>Sat, 26 Oct 2019 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com//2019/10/26/Unity3D%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%9B%E9%98%B6%E4%B8%BB%E7%A8%8B-%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF%E4%B8%8E%E5%9B%BE%E5%BD%A2%E5%AD%A67.html</link>
               <guid isPermaLink="true">http://www.luzexi.com//2019/10/26/Unity3D%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%9B%E9%98%B6%E4%B8%BB%E7%A8%8B-%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF%E4%B8%8E%E5%9B%BE%E5%BD%A2%E5%AD%A67.html</guid>
            </item>
        
            <item>
               <title>思路探讨(二十九) 有没有可能是我们理解错了</title>
               <description>&lt;h1&gt;有没有可能是我们理解错了&lt;/h1&gt;

&lt;p&gt;我经常这样问自己，有没有可能是我理解错了。有没有可能完全不是我理解的那么回事。&lt;/p&gt;

&lt;p&gt;===&lt;/p&gt;

&lt;h6&gt;这个世界的真相总是在我们背后，但我们总认为自己的前方所见就是全世界。因此完全推翻自己的认知是有必要的。&lt;/h6&gt;

&lt;p&gt;“有没有可能是我们理解错了”，这个问题是来自于我们的反思，不过看起来似乎像是用好奇心来破解当前面对的困局。&lt;/p&gt;

&lt;h6&gt;当我们遇到困境，遇到疑惑，遇到迷茫时，不妨用好奇的口吻来表达我们渴望突破。&lt;/h6&gt;

&lt;p&gt;其实我们都是井底的那只蛙，我们弹跳力不够很难跳出这口井，就像我们无法用旁观者的角度看自己那样，在井中我们总是认为自己所思所想都是对的，以至于认为世界就是我们所认为的方式在运作。&lt;/p&gt;

&lt;p&gt;映射到实际生活中，比如像我一样的程序员编程技术工作者们，我们很难跳出这个技术视野去看事物。很多像我一样以为只要技术好就能升职加薪赢取白富美走上人生巅峰，这可能是程序员思维中最大的错误理解。因为我们身处在具体的工作细节中，这个具体工作本身就是那口井，我们无法跳出这口井去看外面的世界，就像我们无法用旁观者的角度看清问题的本质一样。&lt;/p&gt;

&lt;h6&gt;面对程序员的职业发展与事业道路，我对自己表达了好奇“有没可能是我理解错了”，我希望透过现象看本质。&lt;/h6&gt;

&lt;p&gt;就此我提出四个点来表达透过现象看到的本质：&lt;/p&gt;

&lt;h3&gt;技能可以用来打工，产品才能用来赚钱。&lt;/h3&gt;

&lt;p&gt;为什么说“只要技术好就能升职加薪赢取白富美走上人生巅峰”是错的呢？&lt;/p&gt;

&lt;p&gt;不是技术没用，而是只有技术还远远不够。口才和心理素质比技术有用的多。&lt;/p&gt;

&lt;p&gt;技术只不过是熟能生巧而已，可以理解为经验和知识在脑中的肌肉记忆。&lt;/p&gt;

&lt;p&gt;而口才是嘴巴和脸部肌肉的肌肉记忆，心理素质则是环境在脑中的肌肉记忆。&lt;/p&gt;

&lt;p&gt;只有这几个肌肉记忆联结起来才会产生实质性的效果。而产品其实就是这几个因素联结起来的结果。&lt;/p&gt;

&lt;p&gt;一个好的产品不只要有好的技术，还要有好的营销，好的运营，好的耐心和好的专注。&lt;/p&gt;

&lt;p&gt;如果只有技术，那就会什么都不是。&lt;/p&gt;

&lt;h3&gt;开源只是种学习的方式，并不能成为崛起财富的途径。&lt;/h3&gt;

&lt;p&gt;很多人都喜欢开源，因为他们弄不清目标，只是觉得开源很酷。&lt;/p&gt;

&lt;p&gt;开源是种精神，这种精神很多种，有的纯粹为了分享，虽然对世界有益，但对个人而言毫无益处。但有的开源就是为了锻炼自己，把自己的行为、希望、作品抛到全世界的平台上去让大家去检验去抨击你，（前提是这种行为是你这个领域一无所有或者投资太多关注太少的时候，如果你已经拥有很多，开源就会变成了一种浪费），那是真正对自己有益的行为。&lt;/p&gt;

&lt;h3&gt;技术驱动的企业必定失败，只有利益和市场才是财富的依靠。&lt;/h3&gt;

&lt;p&gt;世界上没有以技术为导向的公司，所有声称以技术导向的公司都死了，因为这并不符合市场的规律，不符合人类的天性。&lt;/p&gt;

&lt;p&gt;人类的天性是逐利的，技术并不能决定市场的逐利行为，技术不迎合市场一样遭遇淘汰。&lt;/p&gt;

&lt;h3&gt;市场是不道德的，遵循道德跟是否得到市场认可无关，但遵循道德可以让人安心踏实。&lt;/h3&gt;

&lt;p&gt;市场跟道德无关，很多现象看似不道德其实只是人们心里的偏见而已，其实并无他，即使站在道德的制高点也不会让市场回头。&lt;/p&gt;

&lt;p&gt;不过虽然道德跟很多逐利的事物无关，但跟人本身却有很大关系，它能让人安心踏实，人生在世，图的其实就是个安心，道德对人来说就是最好的抚慰剂，让人安心踏实。&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;最后说说我自己。我有好奇的毛病，我想大多数人都和我一样，它时常让我陷入困境，比如我时常有奇思怪想，去体验一把没有体验过的人生旅途，最后发现没有人去体验不是因为他们不敢而是因为这条路体验很差或许还很受伤。不过好奇也同样时常让我豁然开朗，因为体验后自己就经历了比别人更多的遭遇，也有了更多人生体验和感悟。&lt;/p&gt;
</description>
               <pubDate>Sun, 13 Oct 2019 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com//2019/10/13/%E6%80%9D%E8%B7%AF%E6%8E%A2%E8%AE%A829.html</link>
               <guid isPermaLink="true">http://www.luzexi.com//2019/10/13/%E6%80%9D%E8%B7%AF%E6%8E%A2%E8%AE%A829.html</guid>
            </item>
        
            <item>
               <title>《Unity3D高级编程之进阶主程》第七章，渲染管线与图形学(三) - 渲染原理与知识1</title>
               <description>&lt;p&gt;前面的几篇非常详尽的讲述了渲染管线的整个流程以及渲染管线上的每个节点的来龙去脉。这节我们来说说，一些渲染概念和原理，以及上几章中对渲染管线上没有说到的细节，或者在现代GPU中已经被优化的流程。&lt;/p&gt;

&lt;p&gt;===&lt;/p&gt;

&lt;h3&gt;为什么要有渲染顺序&lt;/h3&gt;

&lt;p&gt;前面章节中我们介绍了深度测试这个模块，它用片元的深度值与深度缓存中的值比较得到测试结果，再决定是否要写入深度缓存中，如果判断失败则抛弃片元不再继续下面的流程。这其中涉及到了 ZTest On/Off 状态开关，和，ZWrite On/Off 状态开关，其中ZTest 用于控制是否开启测试，ZWrite 用于控制是否写入深度缓存。&lt;/p&gt;

&lt;p&gt;渲染管线中的深度测试节点最大的好处是帮助我们尽早的发现不需要渲染的片元，并抛弃它们以节省GPU消耗提高效率。&lt;/p&gt;

&lt;p&gt;其实大部分情况下我们都使用 ZTest LEqual 做判断，即离摄像机越近的物体越容易遮挡住离得远的物体。&lt;/p&gt;

&lt;p&gt;从这个角度看渲染机制，如果能先把离屏幕近的物体放前面渲染，那么后面的物体虽然不能完全在CPU层面判定它是否被掩盖而剔除，但能在深度测试的机制下早早的抛弃掉很多片元，会提升不少的GPU效率。&lt;/p&gt;

&lt;p&gt;于是渲染顺序就成了关键，Unity3D引擎对所有不透明物体在渲染前做了排序工作，即离摄像机近的排在前面渲染，离的远的排在后面渲染，这个渲染队列又有了新的排序规则。&lt;/p&gt;

&lt;p&gt;那么半透明物体怎么办呢？因为半透明物体需要Blend混合，ZWrtie开关一般都是关的，因为如果开启来的话半透明部分在深度测试时就变成了完全的遮挡，从而没有了半透的效果。因此它需要在所有不透明物体渲染后再渲染才能真正发挥出它半透明的效果。&lt;/p&gt;

&lt;p&gt;在Unity3D引擎在提交渲染时增加了这么条规则，即对所有半透明物体的渲染都排在了不透明物体的后面，这样就确保了半透明物体能在不透明物体渲染完毕后才开始渲染，以保证半透明物体的渲染效果。&lt;/p&gt;

&lt;p&gt;那么怎么标记物体是不透明还是半透明呢，Unity3D引擎为了解决这个问题，将渲染顺序放在Shader中实现，即 Queue 标签来决定我们的模型将归于哪个渲染队列。&lt;/p&gt;

&lt;p&gt;Unity3D在内部使用了一系列整数索引来表示渲染的次序，且索引越小越表示排在前面被渲染。&lt;/p&gt;

&lt;p&gt;Queue 标签：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    Background，索引号1000

    Geometry，索引号2000

    AlphaTest，索引号2450

    Transparent，索引号3000

    Overlay，索引号4000
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Shader中我们选择任意Queue标签就会指定那个索引类型，Unity3D还有一个规则是2500以下的索引号，当多个物体拥有相同索引号时，排序规则以根据摄像机的距离由近到远顺序渲染，如果是2500索引号以上的包括2500，当多个物体拥有相同索引号时，则排序规则以根据摄像机的距离由远到近顺序渲染(与2500以下的物体相反)。&lt;/p&gt;

&lt;p&gt;为什么要这么排序呢？因为2500以下物体都是不透明物体，渲染在深度测试阶段越早剔除掉越好，所以对摄像机由近及远的渲染方式对早早的剔除不需要渲染的片元有莫大的帮助，提高GPU效率。而2500索引以上的物体，通常都是半透明物体或者置顶的物体(例如UI)，如果依然保持由近到远的渲染规则，半透明物体就无法混合被它覆盖的物体。因此2500索引及以后的物体与2500索引以前的物体，在相同索引号时渲染排序的规则是相反的。&lt;/p&gt;

&lt;p&gt;半透明的排序问题通常是头疼的，为什么呢？因为前面我们说的它是需要由blend混合完成半透明部分的操作，而blend操作必须在前面物体已经绘制好的条件下才能有blend混合后成为半透明或全透明效果。&lt;/p&gt;

&lt;p&gt;Queue在Transparent半透明索引号下，相同索引号是从远到近渲染的，在粗糙颗粒的排序上还是可以解决的，即两个物体模型没有相交部分，前后关系的blend混合是可以依靠模型中点离摄像机的远近做排序的，Unity3D引擎也是这么做的。但是如果两个物体相交，或者本物体中模型有前后叠加关系时则无法再区分片元的前后关系了。&lt;/p&gt;

&lt;p&gt;因此使用Blend混合做半透明物体，通常情况下很难做到前后关系有秩序，特别是当模型物体有交集的时候。而且通常都采用手动排序，例如在Queue上+1，即Tag{ Queue = &amp;quot;Transparent+1&amp;quot; } 的形式，这也是为什么很多特效Shader要有好几个一模一样Shader功能只是Queue不同。&lt;/p&gt;

&lt;p&gt;所有的渲染顺序都是引擎自主排列的，而不是由GPU排序的，GPU只知道渲染、测试、裁切，完全不会去管物体的前后次序，这也是为什么称它叫“流水线”的原因，它就像工厂里的作业流水线一样，每个工人都只是一个节点的螺丝钉，他们很多时候只要记住一个动作就可以“无脑”的重复劳动，GPU里也是一样。&lt;/p&gt;

&lt;h3&gt;Alpha Test&lt;/h3&gt;

&lt;p&gt;上面和前几章讲了好多关于半透明物体的知识，而Alpha Test其实也是属于半透明物体的特征，不过它不是混合，而是裁切。&lt;/p&gt;

&lt;p&gt;我们在制作模型过程中，很多模型的边角都需要极其细微的面片，比如树上的叶子，一堆乱糟糟的草，还有许许多多圆形的洞等，这些如果用网格模型来制作的话会多出很多很多面片，制作时间长，调整起来慢，同屏面数高，这些问题滚滚而来。&lt;/p&gt;

&lt;p&gt;怎么办呢，Alpha Test能很好的解决这些问题，Alpha Test 用纹理图片中的 Alpha 来测试判定该片元是否需要绘制，即当我们展示一些很细节的模型时，用一张图片和两三个面片就能代替巨量的面片制作方式。如果有需要调整的地方，也只是需要调整纹理图片和少量顶点就可以完成工作。&lt;/p&gt;

&lt;p&gt;这种方式被大量用在节省面片渲染数量上，因为它的制作简单，调整容易，被众多开发人员所喜爱。&lt;/p&gt;

&lt;p&gt;其渲染的过程也比较简单，在片元着色器中判断该片元 Alpha 值是否小于了某个阈值，一旦判定小于某个阈值就调用clip或者discard丢弃该片元，该片元流水线停止。&lt;/p&gt;

&lt;p&gt;我们来开如图所示：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    缺图
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;图中这些小草都只是一个个面片，GPU在渲染片元时会先去判定该片元的 Alpha 是否小于某个阀值，如果小于则不渲染该片云，否则继续渲染。&lt;/p&gt;

&lt;p&gt;这种方式的裁剪片元对于只需要不透明和全透明的物体来说很好用，而且 Alpha Test 不需要混合，它完全可以开启 ZTest 的深度测试，和 ZWrite 的深度写入，在渲染遮挡问题上完全没有问题。&lt;/p&gt;

&lt;p&gt;不过它并不是万能的，也存在很多缺陷，我们下面就要讲讲在现代GPU中它的问题。&lt;/p&gt;

&lt;h3&gt;Early-Z GPU硬件优化技术&lt;/h3&gt;

&lt;p&gt;前面说了ZTest 深度测试在片元着色器之后做了片元(即像素带些信息)之间的前后遮挡测试，使得GPU对哪些片元需要绘制又有哪些片元被遮挡而不需要绘制有了依据。&lt;/p&gt;

&lt;p&gt;不过深度测试只是在所有片元都基本成型时才做的测试，使得大部分被遮挡的片元在被剔除时就已经经过一轮的着色器计算，这使得当片元重叠遮挡比较多时导致了大量的GPU算力的浪费。&lt;/p&gt;

&lt;p&gt;这种情况常常发生，特别是在摄像机需要渲染更多物体的时候，遮挡的情况会越来越严重，每个物体生成的片元无论是否被遮挡都会被经过一次差不多是一整个的渲染流程，那么这时的ZTest 深度测试前的渲染计算就几乎全部浪费掉了宝贵的GPU算力。&lt;/p&gt;

&lt;h6&gt;Early-Z 技术就专门为这种情况做了优化，我们可以称它为前置深度测试。由于渲染管线中，ZTest 深度测试其实发生在片元着色器之后，这时候再进行深度测试时，就是对所有渲染对象的像素都计算一遍，几乎没有性能提升，仅仅是为了得出正确的遮挡结果，造成大量的无用计算算力浪费，因为每个像素点上重叠了许许多多次计算。&lt;/h6&gt;

&lt;h6&gt;因此现代GPU中运用了Early-Z的技术，在几何阶段与片元着色器之间（光栅化之后，片元着色器之前）先进行一次ZTest 深度测试，如果深度测试失败，就跳过片元阶段的计算，节省了大量的GPU算力。&lt;/h6&gt;

&lt;p&gt;那么具体它是怎么个流程呢，我们来看看如下图：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    Early-Z--|
    |        |no
    |yes     |
    |    片元着色计算
    |        |
    |        |
    ZTest 深度测试 -- 抛弃
    |
    |
    屏幕像素缓冲
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上图中展示了Early-Z 前置深度测试的流程，当光栅化后的片元先进入Early-Z 前置深度测试阶段，如果片元测试被遮挡，则直接跳过片元着色计算，如果没有被遮挡则继续片元着色的计算，无论是否通过Early-Z 前置深度测试，最终都会汇集到ZTest 深度测试再测试一次，由ZTest来最终觉得是否抛弃该片云，由于前置测试已经测试完毕了片元的前后关系，因此所有跳过片元着色计算的片元都会在ZTest 节点被抛弃，反之则会继续渲染流程最终进入屏幕像素缓冲区。&lt;/p&gt;

&lt;p&gt;Early-Z的实现是GPU硬件自动调用的，它主要是通过两个pass来实现，即第一个是Z-pre-pass，对于所有写入深度数据的物体，先用一个超级简单的pass不写入像素缓存，只写深度缓存，第二个pass关闭深度写入，开启深度测试，用正常渲染流程进行渲染。&lt;/p&gt;

&lt;h6&gt;由于我们在片元着色器中可以自主的抛弃片元，因此问题又出现了。&lt;/h6&gt;

&lt;p&gt;片元在着色器中被主动抛弃后，Early-Z 前置深度测试的结果就会出现问题，因为如果可见片元被抛弃后，被它遮挡的片元就成为了可见片元，导致前置的深度测试结果失效。&lt;/p&gt;

&lt;p&gt;因此GPU在优化算法中，对片元着色器抛弃片元和修改深度值的操作做了检测，如果在片元着色器中存在抛弃片元和改写片元的操作，则Early-Z 将被放弃使用。&lt;/p&gt;

&lt;h6&gt;简单来说，Early-Z 对遮挡处理做了很大的优化，但是如果我们使用了Alpha Test 来渲染物体时要注意，Early-Z 的优化功能将被弃用。同样的在修改深度值时也要引起注意，Early-Z也同样会被关闭。&lt;/h6&gt;

&lt;h3&gt;Mipmap的原理&lt;/h3&gt;

&lt;p&gt;Mipmap是目前应用最为广泛的纹理映射技术之一。Mip来源于拉丁文中的multum in parvo，意思是“在一个小区域里的很多东西”。Mipmap技术与材质贴图技术结合，根据物体距摄像机远近距离的不同，以不同分辨率的纹理贴图，将单一的材质贴图以多重图像的形式表现出来。&lt;/p&gt;

&lt;p&gt;Mipmap功能在3D游戏中非常常见，但很多人还是不太了解Mipmap的来龙去脉，我们在这里详细的讲一讲。&lt;/p&gt;

&lt;p&gt;在我们为物体渲染纹理贴图时，经常会出现物体离摄像机很远的情况，屏幕像素与纹理之间的比率会变得非常低，因此纹理采样的频率也会变得非常低，这样会导致渲染图像上的瑕疵。我们举例来说：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    如果要渲染一面墙，假设这面墙纹理有 1024 x 1024 这样的大小，当摄像机距离墙很近时渲染的图像是没有问题的，因为每个像素都有各自对应的纹理贴图上合理的像素。但是当摄像机向这面墙渐渐远离，直到它在屏幕上变成一个像素点时就出现问题了，因为纹理采样的结果可能会在某个过度点上发生突然的变化导致图像产生瑕疵。

    特别是在屏幕上不断前后运动的物体可能会使得屏幕上渲染产生闪烁的问题。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Mipmap为了降低这个效果的影响，对纹理贴图进行了提前的滤波，并且将滤波后的图像存储为连续的不同分辨率的纹理贴图。OpenGL在开启Mipmap后会自动判断当前应当使用纹理贴图的哪层分辨率贴图，判断的依据是基于物体在屏幕上渲染的像素大小来决定的。&lt;/p&gt;

&lt;p&gt;除了能更好的平滑渲染远近物体像素上的瑕疵和闪烁问题外，Mipmap还能很好的提高采样的效率，由于采用从已经缓存的不同分辨率纹理的采样对象，那些远离摄像机的物体采用了更小分辨率的纹理贴图，使得采样时宽带的使用降低从而获得更高的效率，其实大部分物体都离摄像机较远，这使得Mipmap的采样效率提升在渲染中发挥了重要的作用。&lt;/p&gt;

&lt;p&gt;一般在使用Mipmap的时候，OpenGL会负责计算细节层次并得到Mipmap层级的结果，再将采样结果返回给用户。不过我们也可以自己取代这个计算过程再通过OpenGL纹理获取函数(textureLod)来选取指定的纹理层次。&lt;/p&gt;

&lt;p&gt;那么在OpenGL中到底 Mipmap 是怎么决定采用哪层分辨率的贴图的呢？我们来详细的讲解一下。&lt;/p&gt;

&lt;p&gt;这里有2个概念要复习一下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    1.屏幕上的颜色点叫像素，纹理贴图上的颜色点叫纹素。

    2.屏幕坐标系我们用的是XY坐标系，纹理贴图坐标系用的是UV坐标系。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在片元着色器中，每个片元即屏幕空间XY上的像素都会找到对应的纹理贴图中的纹素来确定像素的颜色。&lt;/p&gt;

&lt;p&gt;这个查找纹素的过程就是一个从XY空间到UV空间的一个映射过程。我们可以通过分别求x和y偏导数来求屏幕单个像素宽度纹理坐标的变化率。&lt;/p&gt;

&lt;p&gt;在屏幕上，某区域上的像素，对应到实际的纹理贴图中可能是一个长方形的区域。&lt;/p&gt;

&lt;p&gt;那么x轴方向上的纹理贴图大小和屏幕上的像素区域大小有一个比例，y轴方向上的也同样有一个比例。&lt;/p&gt;

&lt;p&gt;例如，获取到的纹理贴图上的纹素大小为 64x64，屏幕上的像素区域大小为32x32，那么它们在x轴上的纹素和像素大小比例为 2.0 (即64/32)，y轴上的也同样是 2.0 (即64/32)。又比如，纹理贴图上的纹素大小为 64x32，屏幕上的像素区域大小为 8x16，那么它们在x轴上的纹素和像素大小比例为 8.0(即64/8)，在y轴上的纹素和像素大小比例为2.0(即32/16)。&lt;/p&gt;

&lt;p&gt;这个比例就是纹素的覆盖率，当物体离摄像机很远时，纹素的覆盖率就很大，当物体离摄像机很近时则很小，甚至小于1(当纹素覆盖率小于1时则会调用纹理放大滤波器，反之则用到了Mipmap，如果刚好等于1则使用原纹理)。&lt;/p&gt;

&lt;p&gt;在着色器中我们可以用ddx和ddy求偏导的方式分别求这个两个方向上的覆盖率，然后取较大的覆盖率。&lt;/p&gt;

&lt;p&gt;为什么ddx和ddy偏导函数就能计算覆盖率呢，这里稍微复习一下。我们知道在光栅化的时刻，GPU会在同一时刻并行运行很多片元着色器，但是并不是一个像素一个像素的去执行，而是将其组织成 2x2 为一组的像素块，再去并行执行。而偏导数就正好能计算这一块像素中的变化率。&lt;/p&gt;

&lt;p&gt;我们来看下偏导的真相：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    ddx(p(x,y)) = p(x+1,y) - p(x,y)

    ddy(p(x,y)) = p(x,y+1) - p(x,y)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;x轴上的偏导就是 2x2 像素块中 x轴方向上附近的数值之差。同理，y轴上的偏导就是 2x2 像素块中 y轴方向上附近的数值之差。&lt;/p&gt;

&lt;p&gt;因此MipMap层级的计算可以描述为&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;MipmapLevel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;float2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;textureSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ddx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;textureSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ddy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;textureSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;  
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;求出x轴和y轴方向上的覆盖率后，取最大值d(dot(dx,dx)其实就是dx的平方)，再log2后获得Mipmap层级，这里0.5是技巧，本来应该是d的平方。&lt;/p&gt;

&lt;p&gt;大部分时候OpenGL已经帮我们做了Mipmap层级的计算，也就是说我们在Shader中使用tex2D(tex, uv)获取颜色的时候就相当于在GPU内部展开成了如下面所示：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tex2D&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sampler2D&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lod&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CalcLod&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ddx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ddy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lod&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tex2Dlod&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里的意思是uv所求的导数越大，在屏幕中占用的纹理范围就越大。简单来说就是我们在片元计算中发现uv导数很大时，就说明这个片元离摄像机很远，从这个方面来理解uv的在片元着色器中的求偏导就可以明白，我们只需要通过uv的求偏导就能间接计算出x轴和y轴方向的覆盖率。&lt;/p&gt;

&lt;h6&gt;在OpenGL中Mipmap的计算其实依赖于片元中的uv求偏导值，也就是说，片元所映射的uv范围越大，计算出来的Mipmap层级越高，纹理贴图选取的分辨率越小。&lt;/h6&gt;

&lt;h3&gt;显存的存在&lt;/h3&gt;

&lt;p&gt;显存经常被我们忽视，因为近几年流行的都是手机端的游戏项目，其实它在PC端存在的意义很大。一个显卡除了有图像传给处理单元GPU外，还拥有自己的内存，即显存VRAM(Video Random Access Memory)。&lt;/p&gt;

&lt;p&gt;GPU可以在显存中存储任何数据，例如图像缓存、深度缓存、模板缓存、着色器实例等。&lt;/p&gt;

&lt;p&gt;除了这几个必要的缓存外，显卡中还存放着渲染时需要用到的贴图纹理、顶点缓存等，这些内容都是需要从CPU内存中拷贝过来的，在调用渲染前，应用程序可以调用图形应用接口OpenGL将数据从普通内存中拷贝到显卡内存中，这个过程只存在于PC端和主机端，因为它们都拥有显卡的存在。&lt;/p&gt;

&lt;p&gt;因此PC端在渲染前还有进一步拷贝数据的过程，显存并不多即使现代显存成本变低的情况下仍然捉襟见肘。&lt;/p&gt;

&lt;p&gt;手机端就没有这样的拷贝过程。手机端大都是ARM架构，芯片中嵌入了各种各样的硬件系统，包括SoC(即芯片级系统，包含了完整系统并有嵌入软件的全部内容)、图像处理GPU、音频等。而显存由于种种限制没有被设计加入到ARM中去，因此在手机端中CPU和GPU共用同一个内存控制器，也就是说CPU和GPU是共用内存带宽的，没有独立显存只有普通内存，不过即便这样GPU也有自己的独立内存部分，例如上面的缓存和后面的可写数据的拷贝都需要一份独立的“共享显存”。&lt;/p&gt;

&lt;p&gt;手机端没有独立显存，因此OpenGL ES就设计了映射缓冲区对象，它在不需要拷贝内存的前提下可以通过共享内存来实现数据的提取。如果贴图或顶点数据是只读状态的话完全没有必要为渲染而重新拷贝一份，而是可以选择建立起映射缓冲区对象，直接读取内存来获取数据。不过也有不做建立映射缓冲区对象的时候，当数据、纹理被开启可写状态时则必须重新拷贝一份在GPU独立内存中，因为原数据随时会被CPU更改，而当时可能GPU还在渲染中，如果仍然并行处理同一个数据则会造成显示问题，因此两个并行的脑袋不能共享一份可写的数据。&lt;/p&gt;
</description>
               <pubDate>Sun, 13 Oct 2019 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com//2019/10/13/Unity3D%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%9B%E9%98%B6%E4%B8%BB%E7%A8%8B-%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF%E4%B8%8E%E5%9B%BE%E5%BD%A2%E5%AD%A66.html</link>
               <guid isPermaLink="true">http://www.luzexi.com//2019/10/13/Unity3D%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%9B%E9%98%B6%E4%B8%BB%E7%A8%8B-%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF%E4%B8%8E%E5%9B%BE%E5%BD%A2%E5%AD%A66.html</guid>
            </item>
        
            <item>
               <title>《Unity3D高级编程之进阶主程》第七章，渲染管线与图形学(二) - 渲染管线2</title>
               <description>&lt;p&gt;继上篇讲解了渲染管线的应用阶段、几何阶段和光栅化阶段，这一节我们来讲讲最后的逐片元操作阶段，以及着色器中我们常见的一些概念和原理。&lt;/p&gt;

&lt;h6&gt;逐片元操作(Per-Fragment Operations)是OpenGL的说法，在DirectX称为输出合并阶段(Output-Merger)，其实只是说法不同而已包含的内容都是相同的，包括了，剪切测试(Scissor test)，多重采样的片元操作，模板测试(Stencil Test)、深度测试(Depth Test)、混合(blending)、以及最后的逻辑操作。&lt;/h6&gt;

&lt;p&gt;===&lt;/p&gt;

&lt;p&gt;这几个节点都是以片元为基础的元素操作动作，它们都决定了片元的去留问题。所以逐片元操作阶段是解决片元的可见性问题的一个重要阶段，如果片元在这几个节点上任意一个节点没有通过测试，那么它就会被丢弃并且之后的测试或操作都不会被执行，如果执行全部通过就会进入帧缓存。每个节点实际测试的过程是个比较复杂的过程，而且不同的图形接口实现的细节也不一样，但我们要理解到它们的基本原理和大致的过程相对简单一些。&lt;/p&gt;

&lt;p&gt;所有这些测试和操作其实都可以看做是以开关形式存在，因为他们的操作命令大都包含了On和Off操作指令，在OpenGL里以glEnable()和glDisable()来表示功能是否被开启或关闭。&lt;/p&gt;

&lt;p&gt;第一个可见性测试就是剪切测试(Scissor)，它主要针对的是片元是否在矩形范围内的测试判断，如果片元不在矩形范围内则被丢弃。&lt;/p&gt;

&lt;p&gt;这个范围是一个矩形的区域，我们称它为剪切盒。实际上可以有很多个剪切盒存在，只是默认情况下所有渲染测试都在第一个剪切盒上完成，要访问其他剪切盒就需要几何着色器。&lt;/p&gt;

&lt;p&gt;Unity3D并没有开放这个剪切测试的功能，它的实际应用比较少。&lt;/p&gt;

&lt;p&gt;第二步是多重采样的片元操作。&lt;/p&gt;

&lt;p&gt;普通采样只采一个样本或者说一个像素，而多重采样泽是分散取得多个样本，这些样本可能是附近的几个位置也可能是其他算法。因此在多重采样中，每个片元都有多种颜色，多个深度值和多组纹理坐标，而不是只有一种（具体有多少个取决于子像素的样本数目）。&lt;/p&gt;

&lt;p&gt;如果没有开启多重采样的片元操作，多重采样在计算片元的覆盖比例时，不会考虑alpha值的影响。&lt;/p&gt;

&lt;p&gt;一旦开启多重采样的片元操作，我们就可以用片元的alpha值来影响采样的覆盖率计算。&lt;/p&gt;

&lt;p&gt;Unity3D的没有开放自定义设置多重采样的片元操作功能，但像素本身不是单单只是它本身的颜色和深度，而是由附近的像素一起决定的。具体的多重采样内容将在后面的章节中讲述。&lt;/p&gt;

&lt;p&gt;前两步可能并没有引起我们足够的重视，但后面几步需要我们着重学习。&lt;/p&gt;

&lt;p&gt;第三步模板测试(Stencil Test)，模板测试说的简单点，其实和比大小无异，关键就是怎么比，与谁比，这又能玩出很多花样。&lt;/p&gt;

&lt;p&gt;在模板测试中模板缓存是必要的内存块，因为每个片元在通过测试后都会被写入到模板缓存中。&lt;/p&gt;

&lt;p&gt;开发者需要指定一个引用参考值(Reference value)，这个参考值代表了当前物体所有片元的参考值，这个参考值会与模板缓存(Stencil Buffer)中当前位置片元的模板值进行比较，比较时模板缓存中当前位置片元的参考值是被前面的物体通过测试时写入的一个值，比较两个值后会根据比较的结果做判断是否抛弃片元，判断可以是大于、等于、小于等，一旦判断失败片元将被抛弃反之则继续向下传递，只是判断成功后也可以有相应对模板缓存做其他操作，操作可以有，替换旧的片元，增加一定的参考值，参考值置零等等。&lt;/p&gt;

&lt;p&gt;我们来看看到底有多少种判断，和，多少种对模板缓存的操作。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    Greater 大于模板缓存时判断通过
    GEqual  大于等于模板缓存时判断通过
    Less    小于模板缓存时判断通过
    LEqual  小于等于模板缓存时判断通过
    Equal   等于模板缓存时判断通过
    NotEqual    不等于模板缓存时判断通过
    Always  总是通过
    Never   总是不通过
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上述这些都是对于是否通过测试的判断种类，看上去就像是简单的比大小。在Unity3D的Shader中的完整的模板测试写法如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    Stencil {
        Ref 2 //指定的引用参考值
        Comp Equal //比较操作
        ReadMask 255 //读取模板缓存时的掩码
        WriteMask 255 //写入模板缓存是的掩码
        Pass Keep //通过后对模板缓存的操作
        ZFail IncrSat //如果深度测试失败时对模板缓存的操作
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;模板测试的步骤简单明了，当前值与模板缓冲比较，通过的做一个指定的操作替换或者增加或者减少等，不通过的片元被抛弃。&lt;/p&gt;

&lt;p&gt;上述Unity3D模板命令中 Pass 的操作就是通过测试后的操作种类，它有如下几种方式可选：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    Keep    不做任何改变，保留当前缓存中的参考值
    Zero    当前Buffer中置零
    Replace 将当前的参考值写入缓存中
    IncrSat 增加当前的参考值到缓存中，最大为255
    DecrSat 减少当前的参考值到缓存中，最小为0
    Invert  翻转当前缓存中的值
    IncrWrap    增加当前的参考值到缓存中，如果到最值255时则变为0
    DecrWrap    减少当前的参考值到缓存中，如果到最小为0时则变为255
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;不同的物体有不同的引用值，每个比较操作都可以不一样，包括掩码值、成功后的操作动作，一个简简单单的比大小其实也能玩出这么多花样来。不止如此，除了比较和通过后的操作指令外，深度测试失败时还可以影响模板缓存中的值。我们用一幅图就能理解模板测试的美妙：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    缺图
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;图中三个球一起叠加在一起，却只显示了一个球的，并且在这个球上显示了三个球叠加的部分。因为其他两个球的模板测试并没有通过，但叠加部分则通过了模板测试。&lt;/p&gt;

&lt;h6&gt;如果片元幸运的通过了模板测试，则会来到第四步，深度测试。有没觉得这个片元很像某生理教课书上描述精子通过重重困难终于来到了卵子的的位置那样，课本上总是这么介绍，刚好片元也是如此。&lt;/h6&gt;

&lt;p&gt;深度测试主要目的是将被覆盖的片元丢弃，或者说将需要覆盖的片元绘制在屏幕上，其实这两个操作都是根据物体渲染的前后关系操作的。&lt;/p&gt;

&lt;p&gt;深度测试工作分为两块，一块是比较即ZTest，一块是写入即ZWrite，只有比较并被判定通过的才有写入的资格，我们也可以把写入关了，让物体无法写入，这就会导致它片元深度无法与其他物体比较，这种写法在半透明中很常用，其他时候大部分都是默认开启深度值写入即ZWrite On。&lt;/p&gt;

&lt;p&gt;深度测试是怎么比较的呢？还记得前面介绍的模板测试么，重点就是“比大小”，比完判定通过的就写入缓存，深度测试的方法和模板测试的流程和方法简直就是一个妈生出的俩个孩子。深度测试的 ZTest 对应模板测试的 Comp指令，深度测试的 ZWrite 对应模板测试的 Pass指令，先拿当前片元比较缓存中的值再操作缓存，两者简直一模一样。&lt;/p&gt;

&lt;p&gt;与模板测试不同的是深度测试用的是深度值，而不是固定某个值，写入缓存也不没有那么多花样。&lt;/p&gt;

&lt;p&gt;那么什么是深度值？这个深度值是从哪来的？&lt;/p&gt;

&lt;p&gt;还记得前面顶点着色器中介绍的，顶点在变化坐标空间后z轴被翻转成为了视口前方的轴么。整个锥视体变成了立方体，x、y轴则成为了视口平面上的平面方向轴，原来的z轴转换成了顶点前后关系的深度值。我们再来看看这幅图片：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    缺图
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;是的，正是因为那次坐标系的转换和后面的归一化，使得所有顶点的坐标都在一个立方体的空间内，且这个立方体的大小被限制在了-1到1的大小，x、y成为了屏幕相对参考坐标，而z则成为了前后关系的深度参考值。&lt;/p&gt;

&lt;p&gt;虽然这只是顶点上的坐标，但在后面的步骤中三角面被光栅化，并对每个像素背后形成了片元，每个片元根据三角形顶点信息的插值后z坐标也进入了片元中，这就是我们需要的片元的深度值。&lt;/p&gt;

&lt;p&gt;深度值在片元中成为了片元在深度测试中判断的依据，如果输入片元的深度值即z值可以通过制定的深度测试环节，那么它就可以替换当前深度缓存中已经有的深度值(如果ZWrite 没有被关闭的话)。&lt;/p&gt;

&lt;p&gt;深度测试的判断依据也有很多种，我们来看下它有多少中判断种类:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    ZTest Less | Greater | LEqual | GEqual | Equal | NotEqual | Always
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上述中表达了所有判断种类，从左到右为，小于缓存中的就通过，大于缓存中的就通过，小于等于缓存中的就通过，大于等于缓存中的就通过，等于缓存中的就通过，不等于缓存中的就通过，以及总是通过与缓存无关。其中LEqual 最为常用，即越接近摄像机的越需要覆盖其他面片，越远离摄像机的越容易被覆盖或者说越容易通不过深度测试。&lt;/p&gt;

&lt;h6&gt;我们可以更加白话一点表达深度测试，一般情况下都是用LEqual 作为深度测试判断依据，即哪个片元离摄像机越近就用哪个，其他种类的类型判断类型也可以解释的类似与摄像机距离有关。&lt;/h6&gt;

&lt;p&gt;如果片元很幸运冲破前面这么多种测试终于来到了第五步混合阶段，这一步从测试上来说其实是最后一个阶段。&lt;/p&gt;

&lt;h6&gt;混合阶段实质上并没有丢弃任何片元，但却可以让片元消失不见。&lt;/h6&gt;

&lt;p&gt;如果一个片元通过了上面的测试，那么它就有资格与当前颜色缓冲中的内容进行混合了。最简单的混合方式就是直接覆盖已有的颜色缓冲中的值，实际上这样不算混合，只是覆盖而已，我们需要两个片元的真正混合。&lt;/p&gt;

&lt;p&gt;那么什么叫混合？为什么要混合？&lt;/p&gt;

&lt;p&gt;混合是两个片元的从颜色上和alpha值上相加或相乘的算法过程，通过我们自己指定的数学公式来确定混合后的像素颜色，这个公式不复杂，其实就是颜色和因子的加减乘的基本运算，通过这种运算我们能得到想要的效果。&lt;/p&gt;

&lt;p&gt;由于物体都是一个接一个的被渲染在缓冲中的，当前物体被光栅化成为片元后要写入缓存时，面临着前面渲染的物体已经被铺在缓冲中的情况，如果没有开启混合，当前的片元则会直接覆盖掉当前所在的缓冲中的像素，两个片元并没有做任何关联性的操作，但如果这时开启混合则可以对这两个片元在颜色上做更多的操作，这可能是我们所期望的。&lt;/p&gt;

&lt;p&gt;大多数情况混合与片元的 alpha 值有关，但不是硬性要求一定要与alpha有关，也可以只与颜色有关，只是这种类型比较多而已。&lt;/p&gt;

&lt;p&gt;alpha 是颜色的第四个分量，OpenGL中片元的颜色都会带有 alpha 无论你是否需要它，无论是否你显性地设置了它，alpha默认为1不透明。&lt;/p&gt;

&lt;p&gt;但是 alpha 太抽象，我们无法从肉眼看到它，只能在脑袋中想象它。alpha 代表了片元的透明程度，是颜色的第四个分量，我们可以用它实现各种半透明物体的模拟就像有色玻璃那样。&lt;/p&gt;

&lt;p&gt;说白了，混合就是当前物体的片元与前面渲染过的物体的片元之间的颜色与alpha上的操作，那么混合有哪些操作呢？我们来看下Unity3D中的混合指令：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    Blend SrcFactor DstFactor

    Blend SrcFactor DstFactor, SrcFactorA DstFactorA
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里有两种操作方式，第一种是混合颜色包括alpha，第二种是分开混合即，RGB颜色和RGB颜色混合(alpha不参与)用一种方式，alpha和alpha混合则用另一种方式(颜色不参与)。&lt;/p&gt;

&lt;p&gt;其中 SrcFactor 这个因子(变量)会与刚刚通过测试的物体片元(即当前物体片元)上的颜色相乘。&lt;/p&gt;

&lt;p&gt;DstFactor 这个因子(变量)会与前面已经渲染过的物体的片元(即缓存中的像素)的颜色相乘。&lt;/p&gt;

&lt;p&gt;SrcFactorA 这个因子(变量)会与刚刚通过测试的物体片元(即当前物体片元)上的 alpha 相乘。&lt;/p&gt;

&lt;p&gt;DstFactorA 这个因子(变量)会与已经渲染过的物体(即缓存中的像素)片元上的 alpha相乘。&lt;/p&gt;

&lt;h6&gt;这个过程有两个步骤，第一步是相乘操作，第二步是相乘后的两个结果再相加(还可以选相减等)。我们称为混合方程&lt;/h6&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    即 Src * SrcFactor + Dst * DstFactor

    或 SrcColor * SrcFactor + DstColor * DstFactor, SrcAlpha * SrcFactorA + DstAlpha * DstFactorA
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;通常情况下相乘的结果再相加得到最终的混合片元。但我们可以改变这种方程式，用减号，或者调换位置的减号，最大值函数，最小值函数，来代替源数据与目标数据之间的操作符。即&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    BlendOp Add 加法
    BlendOp Sub 减法
    BlendOp RevSub 置换后相减
    BlendOp Min 最小值
    BlendOp Max 最大值
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上述5种操作符的修改就分别代表了因子相乘后会相加，会相减，会置换后相减，会取得最小值，会取得最大值。拿Sub，Max来举例子：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    当写入BlendOp Sub时，方程式就变成了：

    Src * SrcFactor - Dst * DstFactor

    当写入BlendOp Max时，方程式就变成了：

    Max(Src * SrcFactor, Dst * DstFactor)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;除了操作符可以变化外，SrcFactor、DstFactor、SrcFactorA、DstFactorA 这四个变量的可以选择为：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    One     代表1，就相当于完整的一个数据
    Zero    代表0，就相当于抹去了整个数据
    SrcColor    代表当前刚通过测试的片元上的颜色(即当前物体片元)，相当于乘以当前物体片元的颜色
    SrcAlpha    代表当前刚通过测试的片元上的alpha(即当前物体片元)，相当于乘以当前物体片元的alpha
    DstColor    代表已经在缓存中的颜色，相当于乘以当前缓存颜色
    DstAlpha    代表已经在缓存中的alpha，相当于乘以当前缓存alhpa
    OneMinusSrcColor    代表缓存上的片元做了 1 - SrcColor 的操作，再相乘
    OneMinusSrcAlpha    代表缓存上的片元做了 1 - SrcAlpha 的操作，再相乘
    OneMinusDstColor    代表当前刚通过测试的片元上的颜色做了 1 - DstColor 的操作，再相乘
    OneMinusDstAlpha    代表当前刚通过测试的片元上的颜色做了 1 - DstAlpha 的操作，再相乘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;通过上述举的几个例子，并列出了所有变量的选择，我们可以知道其实Blend混合可以玩出很多花样来。&lt;/p&gt;

&lt;p&gt;这4个变量选择，和操作符的选择决定了混合后的效果，我们来看看其常用的混合方法：&lt;/p&gt;

&lt;h6&gt;1， 透明度混合Blend SrcAlpha OneMinusSrcAlpha，即常用半透明物体的混合方式。&lt;/h6&gt;

&lt;p&gt;这是最常用的半透明混合，首先要保证半透明绘制的顺序比实体的要后面，所以Queue标签是必要的Tags {&amp;quot;Queue&amp;quot; = &amp;quot;Transparent&amp;quot;}。Queue标签告诉着色器此物体是透半透明物体排序。至于渲染排序Queue的前因后果将在后面的文章介绍。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/book/7/shader36.png&quot; alt=&quot;blend&quot;&gt;&lt;/p&gt;

&lt;p&gt;Blend SrcAlpha OneMinusSrcAlpha 我们来解释下，以上图为例，图中油桶是带此Shader的混合目标。&lt;/p&gt;

&lt;p&gt;当绘制油桶时，后面的实体BOX已经绘制好并且放入屏幕里了，所以ScrAlpha与油桶渲染完的图像相乘，部分区域Alpha为0即相乘后为无(颜色)，这时正好另一部分由OneMinusSrcAlpha(也就是1-ScrAlpha)为1即相乘后原色不变，两个颜色相加后就相当于油桶的透明部分叠加后面实体Box的画面，于是就形成了上面的这幅画面。&lt;/p&gt;

&lt;p&gt;反过来也是一样，当ScrAlpha为1时，源图像为不透明状态，则两个颜色在相加前最终变成了，源图像颜色+无颜色=源图像颜色，于是就有了上图中油桶覆盖实体Box的图像部分。&lt;/p&gt;

&lt;h6&gt;2，加白加亮叠加混合 Blend One One，即在原有的颜色上叠加屏幕颜色更加白或亮。&lt;/h6&gt;

&lt;p&gt;&lt;img src=&quot;/assets/book/7/shader37.png&quot; alt=&quot;blend&quot;&gt;&lt;/p&gt;

&lt;p&gt;第一参数One代表本物体的颜色。第二个参数代表缓存上的颜色。两种颜色没有任何改变并相加，导致形成的图像更加亮白。这样我们就看到了一个图像加亮加白的图像。&lt;/p&gt;

&lt;h6&gt;3，保留原图色彩Blend One Zero，即只显示自身的图像色彩不加任何其他效果。&lt;/h6&gt;

&lt;p&gt;&lt;img src=&quot;/assets/book/7/shader38.png&quot; alt=&quot;blend&quot;&gt;&lt;/p&gt;

&lt;p&gt;本物体颜色，加上，零，就是本物体颜色。&lt;/p&gt;

&lt;h6&gt;4，自我叠加（加深）混合Blend SrcColor Zero，即源图像与源图像自我叠加。&lt;/h6&gt;

&lt;p&gt;&lt;img src=&quot;/assets/book/7/shader39.png&quot; alt=&quot;blend&quot;&gt;&lt;/p&gt;

&lt;p&gt;与上面相比，加深了本物体的颜色。先是本物体的颜色与本物体的颜色相乘，加深了颜色，第二个参数为零，使得缓冲中的颜色不被使用。所以形成的图像为颜色加色的图像。&lt;/p&gt;

&lt;h6&gt;5，目标源叠加（正片叠底）混合Blend DstColor  SrcColor，即把目标图像和源图像叠加显示。&lt;/h6&gt;

&lt;p&gt;&lt;img src=&quot;/assets/book/7/shader40.png&quot; alt=&quot;blend&quot;&gt;&lt;/p&gt;

&lt;p&gt;第一个参数，本物体颜色与缓存颜色相乘，颜色叠加。第二个参数，缓存颜色与本问题颜色相乘，颜色叠加。两种颜色相加，加亮加白。这个混合效果就如同两张图像颜色叠加后的效果。&lt;/p&gt;

&lt;h6&gt;6，软叠加混合Blend DstColor  Zero，即把刚测试通过的图像与缓存中的图像叠加。&lt;/h6&gt;

&lt;p&gt;&lt;img src=&quot;/assets/book/7/shader41.png&quot; alt=&quot;blend&quot;&gt;&lt;/p&gt;

&lt;p&gt;与前面的叠加混合效果相似，这个只做一次叠加，并不做颜色相加操作，使得图像看起来在叠加部分并没有那么亮白的突出。因为第二个参数为零，表示后面的屏幕颜色与零相乘即为零。&lt;/p&gt;

&lt;h6&gt;7，差值混合BlendOp Sub，Blend One One，即注重黑白通道的差值。&lt;/h6&gt;

&lt;p&gt;&lt;img src=&quot;/assets/book/7/shader42.png&quot; alt=&quot;blend&quot;&gt;&lt;/p&gt;

&lt;p&gt;在这个混合中使用了混合操作改变，从默认的加法改成了减法，使得两个颜色从加法变为了减法，不再是变白变亮的操作，而是反其道成为了色差的操作。&lt;/p&gt;

&lt;h6&gt;除了对源片元和目标片元，相乘再相加的操作，还可以改变相乘后的加法操作。比如减法，取最大值，取最小值等。&lt;/h6&gt;

&lt;h6&gt;Blend混合很像 Photoshop 中对图层操作，Photoshop中每个图层都可以选择混合模式，混合模式决定了该层与下层图层的混合结果，而我们看到的都是是混合后的图片。&lt;/h6&gt;

&lt;h3&gt;逻辑操作&lt;/h3&gt;

&lt;p&gt;在混合结束后，片元将被写入缓存中去，在写入缓冲中去时，还有一步逻辑操作，这是片元的最后一个操作。&lt;/p&gt;

&lt;p&gt;它作用于当前刚通过测试的片元数据以及当前颜色缓存中的数据，在它们之间进行一次操作，再写入到缓存中覆盖原来的数据。&lt;/p&gt;

&lt;p&gt;由于这个过程的实现代价对于硬件来说是非常低廉的，因此很多系统都允许这种做法。这种逻辑操作的方式很像上面的混合(Blend)，但是更加简单，不再有因子，只是两种颜色之间的数字操作，例如，XOR异或操作，AND与操作，OR或操作等。&lt;/p&gt;

&lt;p&gt;Unity3D中并不能自定义设置逻辑操作，这里不重点讲解。&lt;/p&gt;

&lt;h6&gt;双缓冲机制&lt;/h6&gt;

&lt;p&gt;片元最后都会以像素颜色的形式写入缓冲中，但是如果只有一个缓冲，那么我们会时常见到绘制的中间状态即图形的形成过程，这对画面呈现效果很不友好，所以GPU通常采用双缓冲机制，即前置缓存用于呈现画面，而后置缓存则继续由GPU继续工作。&lt;/p&gt;

&lt;p&gt;当整个画面绘制完成时，后置缓冲与前置缓冲进行调换，这时后置缓存可以成为了前置缓冲并呈现在屏幕上，而原来的前置缓存则成为后置缓冲交由GPU作为缓冲内存继续绘制下一帧，由此我们可以保证看到的图像是连续的最终状态。&lt;/p&gt;

&lt;h6&gt;整个渲染管线已经全部呈现在这里了，我们来总结一下。&lt;/h6&gt;

&lt;p&gt;整个渲染管线从大体上分，应用阶段，几何阶段，光栅化阶段。渲染数据从应用阶段生成开始。&lt;/p&gt;

&lt;p&gt;数据在应用阶段被记录、筛选(或者也可以叫裁剪)、合并，这个筛选和合并有些运用了算法来达到裁剪的目的，有些放大了颗粒度用少量的消耗来加速筛选(裁剪)，有些利用了GPU工作原理合并了渲染数据提高了GPU工作效率。&lt;/p&gt;

&lt;p&gt;几何阶段着重于处理顶点的数据，顶点着色器是其中最为重要的一个着色器，它不但需要计算顶点在空间上的转换，还要为下一个阶段光栅化阶段做准备。&lt;/p&gt;

&lt;p&gt;在顶点着色器中，计算和记录了片元着色器计算颜色需要的数据，这些数据都会被放入顶点(图元)数据内，这些数据在下一个阶段会被做插值后放入片元中。&lt;/p&gt;

&lt;p&gt;光栅化阶段主要任务是将三角形面转化为实实在在的像素，并且根据顶点上的数据做插值得到片元信息，一个片元就相当于一个像素附带了很多插值过的顶点信息。&lt;/p&gt;

&lt;p&gt;片元着色器在光栅化阶段起了重要的作用，它为我们提供了自定义计算片元颜色的可编程节点，不但如此，我们还可以根据自己的喜好抛弃某些片元。&lt;/p&gt;

&lt;p&gt;除了片元着色器外，片元在片元着色器后还需要经过好几道测试才能最终呈现在画面上，包括判断片元前后顺序的深度测试，可以自定义条件的模板测试，以及常用来做半透明的像素混合，片元只有经过这几道关卡才最终被写入缓存中。&lt;/p&gt;

&lt;h6&gt;我们讲解了很多，但还是有很多很多细节被忽略，我们会在后面的章节中详细为大家解剖，这些细节可能在各个图形编程接口(OpenGL和DirectX)的实现中不尽相同，但大体上都是运用了同一种原理和概念。&lt;/h6&gt;

&lt;p&gt;Unity3D为我们封装了很多东西，使得我们能很快的上手去运用，但也屏蔽了很多原理上的知识，使得我们在面对底层原理时感到迷茫。本书虽然不是致力于Shader的教学，但也将尽最大的努力使读者们从根本上理解GPU的工作原理，从而在面对工作上的困难时能一眼看透问题的本质，从根本上解决麻烦并优化效率。&lt;/p&gt;
</description>
               <pubDate>Sat, 28 Sep 2019 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com//2019/09/28/Unity3D%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%9B%E9%98%B6%E4%B8%BB%E7%A8%8B-%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF%E4%B8%8E%E5%9B%BE%E5%BD%A2%E5%AD%A65.html</link>
               <guid isPermaLink="true">http://www.luzexi.com//2019/09/28/Unity3D%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%9B%E9%98%B6%E4%B8%BB%E7%A8%8B-%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF%E4%B8%8E%E5%9B%BE%E5%BD%A2%E5%AD%A65.html</guid>
            </item>
        
            <item>
               <title>杭州景点体验概览</title>
               <description>&lt;p&gt;1.西湖--西湖音乐喷泉--三潭印月--断桥残雪--苏堤--白堤--西湖游船--曲院风荷--六和塔--花港观鱼--梅家坞--云栖竹径--龙井路与满觉陇路--孤山公园--虎跑公园--杨公堤&lt;/p&gt;

&lt;p&gt;===&lt;/p&gt;

&lt;p&gt;2.灵隐寺（飞来峰）景区----北高峰索道&lt;/p&gt;

&lt;p&gt;3.宋城景区--宋城千古情演出&lt;/p&gt;

&lt;p&gt;4.杭州动物园&lt;/p&gt;

&lt;p&gt;5.吴山广场，河坊街&lt;/p&gt;

&lt;p&gt;6.雷峰塔&lt;/p&gt;

&lt;p&gt;7.杭州长乔极地海洋公园 -- 好，贵，大&lt;/p&gt;

&lt;p&gt;8.杭州野生动物世界 -- 良好，停车难，略贵，不大&lt;/p&gt;

&lt;p&gt;9.西溪国家湿地公园 -- 差，管理无章法，太大以至于找不到重点&lt;/p&gt;

&lt;p&gt;10.九溪&lt;/p&gt;

&lt;p&gt;11.南宋御街&lt;/p&gt;

&lt;p&gt;12.杭州乐园&lt;/p&gt;

&lt;p&gt;13.太子湾公园&lt;/p&gt;

&lt;p&gt;14.千岛湖中心湖区--千岛湖景区--千岛湖森林氧吧--千岛湖东南湖区景区--千岛湖游船&lt;/p&gt;

&lt;p&gt;16.大明山景区&lt;/p&gt;

&lt;p&gt;17.杭州烂苹果乐园 -- 游乐园&lt;/p&gt;

&lt;p&gt;18.杭州海底世界&lt;/p&gt;

&lt;p&gt;19.浙西大峡谷&lt;/p&gt;

&lt;p&gt;20.钱塘江观赏堤坝&lt;/p&gt;

&lt;p&gt;21.浙江省科技馆--西湖文化广场&lt;/p&gt;

&lt;p&gt;22.杭州浪浪浪水公园&lt;/p&gt;

&lt;p&gt;23.杭州Hello Kitty乐园&lt;/p&gt;

&lt;p&gt;24.桐庐县雅鲁激流探险漂流----临安市龙井峡漂流----淳安县九龙溪漂流----桐庐县虎啸峡激流探险漂流----余杭区双溪漂流景区&lt;/p&gt;

&lt;p&gt;25.桐庐县瑶琳仙境，垂云通天河景区&lt;/p&gt;

&lt;p&gt;26.杭州DO都城，亚洲最大的少年儿童体验类教育场馆&lt;/p&gt;

&lt;p&gt;27.桐庐县大奇山国家森林公园&lt;/p&gt;

&lt;p&gt;28.临安太湖源&lt;/p&gt;

&lt;p&gt;29.良渚，彻天彻地童玩中心，让孩子训练协调能力，培养冒险精神&lt;/p&gt;

&lt;p&gt;30.江干区江和美海洋公园&lt;/p&gt;

&lt;p&gt;31.临安大明山景区&lt;/p&gt;

&lt;p&gt;32.慈溪杭州湾国家湿地公园&lt;/p&gt;

&lt;p&gt;33.胡雪岩故居&lt;/p&gt;

&lt;p&gt;34.京杭大运河，余杭塘栖&lt;/p&gt;

&lt;p&gt;35.杭州国际博览中心，萧山区&lt;/p&gt;

&lt;p&gt;36.多乐岛蹦床公园杭州馆，江干区&lt;/p&gt;

&lt;p&gt;37.桐庐县大奇山疯狂森林主题乐园，冒险探险&lt;/p&gt;

&lt;p&gt;38.城西银泰，娱乐场--滑冰--玩具店 -- 逛买逛买&lt;/p&gt;

&lt;p&gt;39.浙江大学紫金港校区 -- 好风景好环境&lt;/p&gt;

&lt;p&gt;40.塘西古镇  -- 逛吃逛吃，小&lt;/p&gt;

&lt;p&gt;41.杭州北高峰 -- 交通不方便&lt;/p&gt;

&lt;p&gt;42.良储遗址 -- 大，美，便宜，自带食物，能游览大半天&lt;/p&gt;

&lt;p&gt;43.井山湖农耕文化公园(塘子堰，中小学生实践基地) -- 免费，向日葵基地，大片草地，搭帐篷，风景美，自带食物&lt;/p&gt;
</description>
               <pubDate>Sat, 21 Sep 2019 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com//2019/09/21/%E6%9D%AD%E5%B7%9E%E6%99%AF%E7%82%B9%E4%BD%93%E9%AA%8C%E6%A6%82%E8%A7%88.html</link>
               <guid isPermaLink="true">http://www.luzexi.com//2019/09/21/%E6%9D%AD%E5%B7%9E%E6%99%AF%E7%82%B9%E4%BD%93%E9%AA%8C%E6%A6%82%E8%A7%88.html</guid>
            </item>
        
            <item>
               <title>《Unity3D高级编程之进阶主程》第七章，渲染管线与图形学(二) - 渲染管线1</title>
               <description>&lt;p&gt;计算机的世界里其实是很纯粹的，没有什么高深的技术，无非就是进程、线程、内存、硬盘、CPU。&lt;/p&gt;

&lt;p&gt;在现代社会的实际编程中，很多时候引擎或者框架帮我们屏蔽了底层上的操作使得程序员只需要将所有精力放在上层应用就可以了，因此数学和算法很多时候成了重点，这是符合社会进步规律的，我们需要站在巨人的肩膀上才能走得比巨人更快更远。&lt;/p&gt;

&lt;p&gt;===&lt;/p&gt;

&lt;p&gt;Unity3D就是帮助我们快速建立程序结构的好引擎，有了Unity3D我们才能在较低门槛的情况下，创造出自己的想法和创意，让’我‘里面有的内在才能快速和有效的得到放大。&lt;/p&gt;

&lt;p&gt;除了进程、线程、内存、硬盘、CPU这些通常我们程序员在编程时都要接触的因素外，对于我们前端程序员来说又多了一个GPU的技术范畴，因此我们需要学习和考虑的问题比其他程序员会更加多一些也更加高阶一些，Unity3D虽然封装了所有引擎需要的GPU接口功能但我们还是必须要了解渲染管线是如何处理的，最终是如何将渲染数据渲染要屏幕上的等等这些底层的知识和原理。&lt;/p&gt;

&lt;h3&gt;OpenGL、DirectX究竟是什么&lt;/h3&gt;

&lt;p&gt;OpenGL 和 DirectX 其实是一回事，它们都是图形渲染的应用程序编程接口，它们都是一种可以对图形硬件设备特性进行访问的软件库。它们的区别只是接口名字不一样，并且，分别由不同的两个开发群体开发出来的两套程序。&lt;/p&gt;

&lt;p&gt;为什么会是两个不同群体开发出来的两套差不多功能的软件，并且还同时运行在现有的世界中呢？&lt;/p&gt;

&lt;p&gt;OpenGL是由SGI(Silicon Graphics 美国硅图公司)开发的，而DirectX是由微软开发的，由于市场竞争的关系两家公司做了同样的事，最后导致现在的局面。从现在的局面看，我们可以想象的到，在当初还没有形成统一的硬件渲染接口时，各家公司的编程方式有多混乱，情况有多复杂，对标准统一接口的标准竞争有多激烈。在这种严峻的情况下才使得两家公司为了各自的利益，一直在不断维护和升级着各自的驱动接口直到今天。&lt;/p&gt;

&lt;p&gt;幸运的是 Unity3D 已经帮我们封装好了 OpenGL 和 DirectX 的接口，我们无需关心到底是调用 OpenGL 还是 DirectX。我们这里会以OpenGL为例来讲解Unity3D与OpenGL的关系，暂时免去DirectX的麻烦。&lt;/p&gt;

&lt;h6&gt;OpenGL究竟处在哪个位置&lt;/h6&gt;

&lt;p&gt;Unity3D通过调用 OpenGL 来渲染图像，OpenGL 定义各种标准接口就是为了让像 Unity3D 这样的应用程序在面对不同类型的显卡硬件时可以不必慌张，也就是说由于 OpenGL 的存在，Unity3D完全不需要去关心硬件到底是哪个厂家生产的，它的驱动是什么。其实与其说OpenGL在标准接口中适配了硬件厂商的驱动程序，不如说硬件厂商的驱动程序适配了OpenGL，事实上确实是这样。&lt;/p&gt;

&lt;p&gt;当Unity3D在渲染调用时去设置OpenGL的渲染状态，OpenGL就会去检查显卡驱动程序里是否有该功能，如果有就会调用，如果是那些比较特殊的渲染接口，有些硬件驱动是没有的则不调用。&lt;/p&gt;

&lt;p&gt;如果把GPU硬件看做是最底层的那个模块的话，显卡驱动就是在硬件之上的模块，它是用来将指令翻译成机器语言并调用硬件的那个程序。&lt;/p&gt;

&lt;p&gt;显然OpenGL是在驱动程序之上的应用程序，我们可以把它看做是适配不同驱动程序的中间件。如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/book/7/render-pipeline1.png&quot; alt=&quot;opengl&quot;&gt;&lt;/p&gt;

&lt;p&gt;上图中很清晰的表达OpenGL所处的位置，应用程序(如Unity3D)向OpenGL发送渲染指令，告诉OpenGL我的某个模型数据需要渲染或者说某个状态要设置，OpenGL发送指令给显卡驱动程序，显卡驱动程序将指令翻译为机器码后，将指令机器码发送到GPU，GPU先从显存中获得需要的数据再根据指令做处理。&lt;/p&gt;

&lt;p&gt;我们看到这个过程中显卡驱动程序只是做了传递指令消息的工作，指令从OpenGL那里发起到GPU接受到指令，显卡驱动只是起到了翻译的作用。因此我们在平常的讨论中，常常将显卡驱动程序的工作忽略掉，而用 OpenGL 与 GPU 的互动代替之。甚至有时会将OpenGL也忽略掉用GPU代替，或把GPU忽略掉用OpenGL代替，因为GPU的工作是机械式的它俩的工作完全可以看做一个整体。&lt;/p&gt;

&lt;p&gt;当然这里GPU不只会处理一次，OpenGL会通过显卡驱动发送很多次指令给GPU，让它处理一连串的操作，每次指令都有可能不一样，经过一系列的处理过程后，最终形成了一张屏幕大小的图像存放在缓存中，这时GPU才向屏幕输出最终画面。&lt;/p&gt;

&lt;p&gt;下面我们就来详细介绍一下渲染管线。&lt;/p&gt;

&lt;h3&gt;究竟渲染管线是什么？&lt;/h3&gt;

&lt;p&gt;上面所说的 OpenGL 通过驱动程序向 GPU 发送很多个指令，其实为了渲染很多个模型每一帧都会发送很多个指令，这一系列指令加起来，才形成一整个渲染过程，拥有完整的一个画面。&lt;/p&gt;

&lt;p&gt;渲染管线就是指令中完成一个绘制命令(drawcall)的流水线。这条流水线中有很多个环节，每个环节都自己干自己的事，就像工厂里的流水作业一样，每个节点的工人都会拧属于自己的螺丝，完全不会去管前面节点发生了什么事情，不过在现代GPU中也会做些流程上的优化，比如调整节点的顺序，但节点还是自顾自的工作，这部分会在后面的文章中提到。&lt;/p&gt;

&lt;p&gt;从严肃的理论描述来说渲染管线：是一系列数据处理的过程，这个过程最终的目的是将应用程序的数据转换到最终输出的缓存上最后输出到屏幕。&lt;/p&gt;

&lt;p&gt;我们说的再白话一点。渲染管线从接受到渲染命令后开始，分几个阶段处理了这些数据，这几个阶段分别是应用阶段，几何阶段，光栅化阶段，经过这几个阶段处理最终输出到屏幕上。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    缺图片
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;图中每个阶段都有各自细分的流程，我们来一一讲述下。&lt;/p&gt;

&lt;h6&gt;应用阶段&lt;/h6&gt;

&lt;p&gt;应用阶段其实就是我们执行Unity3D引擎和代码的过程，在逻辑代码过程中，我们实例化了很多个模型或者UI（UGUI的UI也是网格，跟渲染场景中的3d模型从根本上是没有区别的），这些模型有贴图，有材质球，有网格，对于引擎来说，这个阶段在代码执行完毕后它知道了哪些模型需要被渲染，有哪些光源存在，摄像头的位置大小，于是就知道该如何通知GPU去渲染，总的来说这个阶段是准备渲染数据的阶段，为调用渲染准备。&lt;/p&gt;

&lt;p&gt;引擎除了知道有哪些东西(数据)需要被提交到GPU渲染外，在提交前还会对这些数据做很多优化工作，从而提高渲染性能。&lt;/p&gt;

&lt;p&gt;优化工作有很多种，从具体业务逻辑上做优化的方案，前面的章节中我们也讲到了很多很多关于在逻辑端上优化的工作，现在我们来重点说一下引擎的‘剔除’优化部分。&lt;/p&gt;

&lt;p&gt;Unity3D引擎会对不需要渲染的物体进行剔除，原本这是在GPU中做的事搬到了CPU上做。为什么要搬到CPU上做呢？因为在引擎端掌握的是第一手数据信息，如果从粗颗粒上下手做剔除工作，CPU会更快更方便，如果放到GPU去剔除，则更可能是三角形级别的裁剪，会浪费很多计算同时降低了功效。&lt;/p&gt;

&lt;p&gt;引擎在粗颗粒上是怎么剔除的呢，引擎当然不会像GPU那样去计算每个面是否可展示，因为这个操作对GPU来说更快，而是去计算更粗的颗粒，即整个模型的包围盒是否需要被剔除。&lt;/p&gt;

&lt;h6&gt;引擎会计算一个模型的包围盒，这个包围盒就是Unity3D的Mesh.bounds变量，这个包围盒为AABB包围盒，即一个顶点与最大最小长宽高，我们可以理解为包围盒是个立方体有8个顶点，这8个顶点决定了这个模型是否会被剔除，即只要有一个顶点在摄像机可视范围内(锥视体内或正交范围)，就不会被剔除，否则将被剔除。&lt;/h6&gt;

&lt;p&gt;引擎通过这种快速的判断包围盒与锥视体的关系来剔除不需要渲染的物体，以达到对粗颗粒的渲染优化。&lt;/p&gt;

&lt;p&gt;除此之外，对粗颗粒的剔除判断还有 occlusion culling 即遮挡剔除，也是属于应用阶段的优化剔除，它其实也是属于业务逻辑层的优化方案并不是所有项目都会使用，而通常只在第一人称视角的游戏上使用这种剔除方式，即被遮挡的物体不进入渲染队列。&lt;/p&gt;

&lt;p&gt;除了得到和优化需要渲染的数据外，应用阶段的最后时刻就是向GPU提交需要渲染的数据，即拷贝数据到显存中、设置渲染状态、渲染调用(Draw call)。&lt;/p&gt;

&lt;p&gt;在PC端中显存是最接近GPU的内存设备，将数据拷贝到显存中会加速GPU的工作效率，但在移动端里并没有显存，安卓和IOS的架构决定了它们只能用内存来为GPU提供服务，因此在手机端中没有拷贝数据到显存的这个说法，使用的都是同一个内存地址，除非我们需要读写这块内存内容才将它们另外复制一份。&lt;/p&gt;

&lt;h6&gt;那么什么是渲染状态？很多人都很困惑，其实就是一连串的开关或方法以及方法的地址指向。&lt;/h6&gt;

&lt;p&gt;比如：要不要开启混合，使用哪张纹理，使用哪个顶点着色器，使用哪个片元着色器，剔除背面还是剔除前面亦或都不剔除，使用哪些光源等等。&lt;/p&gt;

&lt;p&gt;通俗的来说，设置渲染状态，就是设置并决定接下来的网格如何渲染，有了渲染的具体方法，至于具体的渲染工作则是由GPU来执行。&lt;/p&gt;

&lt;p&gt;有了渲染的具体方法，就要调用渲染的具体对象，这就是渲染调用即 Draw call 做的工作。实际上 Draw call 就是一个命令，它的发起方是CPU，接收方是GPU，这个命令仅仅指向了一连串的图元（即点,线,面，我们可以理解为网格被拆分后的状态），并不会包含其他任何材质信息。&lt;/p&gt;

&lt;p&gt;每个 Draw call 前面都伴随着一个渲染状态的设置，因此整个渲染命令队列中都是一对对出现的，并且都是由CPU向GPU提交。&lt;/p&gt;

&lt;h6&gt;那么为什么要有这个渲染命令队列呢？&lt;/h6&gt;

&lt;p&gt;因为CPU和GPU相当于是两个大脑，它们是分离的，如果没有很好的协调机制，它们无法正常梳理自己的工作。一个命令缓冲队列就是用来协调CPU与GPU的，CPU只管向命令缓冲队列中推数据，GPU只管取数据并且处理数据，取一个处理一个，其他时间的都自顾自的忙自己的事。这个命令缓冲队列成了CPU与GPU的关系纽带。&lt;/p&gt;

&lt;p&gt;这条关系纽带(命令缓冲队列)很好的连接了CPU与GPU，但也成了它们之间交互的瓶颈，即我们通常所说的 Draw call 太多时GPU的工作效率比较差。其根本原因就是 CPU 发送了很多渲染命令后，只是空转的等待GPU完成这些渲染操作。&lt;/p&gt;

&lt;h6&gt;几何阶段&lt;/h6&gt;

&lt;p&gt;CPU准备好数据后，向GPU发送了渲染状态的设置命令和渲染调用命令后，接下来的工作就完全属于GPU了。&lt;/p&gt;

&lt;p&gt;接下来进入的是几何阶段的工作。几何阶段最终的工作目标是将需要绘制的图元转化到屏幕空间中，所以它决定了哪些图元要绘制，怎么绘制。&lt;/p&gt;

&lt;p&gt;图元即点、线、面。我们可以理解为网格的拆分状态，是着色器中的基础数据，在几何阶段作用最大。&lt;/p&gt;

&lt;h6&gt;几何阶段会经过几个节点，按顺序排列为，顶点着色器，曲面细分着色器，细分计算着色器，几何着色器，图元装配，裁减和剪切。如下图所示：&lt;/h6&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    缺图
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;图中几何阶段分拆成了，顶点着色器、曲面细分着色器、细分计算着色器、几何着色器、图元装配、裁剪和剪切，6个节点。&lt;/p&gt;

&lt;p&gt;顶点着色器会对每个顶点进行逐一的计算，OpenGL会调用一个顶点处理函数来处理顶点数据。&lt;/p&gt;

&lt;p&gt;这个顶点处理函数就是我们可编程的部分，它可以很简单，只是数据复制并传递到下一个节点，也可以很复杂，例如变换矩阵的方式来得到顶点在屏幕上的位置，或者通过光照计算来判断顶点的颜色，或者记录和计算其他下一个阶段需要的信息。具体我们将在后面的章节中详细讲解。&lt;/p&gt;

&lt;p&gt;曲面细分着色器，细分计算着色器，几何着色器，都是可选的着色器。细分着色器包括曲面细分着色器和细分计算着色器会使用面片来描述一个物体的形状，并且增加面片数量使得模型外观更加平顺。几何着色器则允许增加和创建新的图元，这是唯一一个能自定义增加新图元的着色器。&lt;/p&gt;

&lt;p&gt;前面几个着色器节点处理的都是顶点数据，到了图元装配节点，它将这些顶点与相关的几何图元之间组织起来为下一步的裁剪和剪切工作做准备。&lt;/p&gt;

&lt;h6&gt;经历过前面几个阶段的变换，特别是在顶点着色器中的顶点空间转换，从模型空间到世界空间再到视口空间再到投影空间，Unity3D的Shader中常见的UNITY_MVP就是这个坐标空间转换的矩阵，再经过硬件上透视除法后得到了归一化的设备坐标，这使得到裁剪和剪切节点时，这个归一化的设备坐标使得裁剪会更加容易，不仅如此还对后面的深度缓冲和测试有很大的帮助。&lt;/h6&gt;

&lt;p&gt;归一化后的设备坐标(Normalized Device Coordinates, NDC)可以看做是一个矩形内的坐标体系，这个坐标体系是一个立方体的坐标体系，所有在这个坐标体系内的顶点的坐标都不会超过1到-1之间，无论x、y、z。&lt;/p&gt;

&lt;p&gt;为了能更好的理解经过空间转换后的顶点在后面几个阶段上应用的数据，有必要在这里来理解一下空间坐标系转换前后的样子，如下图：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    缺图1

    缺图2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上述图1中我们看到原本在视锥体上的物体，在经过空间矩阵转换后，视口从锥体变为了立方体，而原本在视锥体中的物体则从长方体变成了锥体，这是空间坐标系转化后的结果。&lt;/p&gt;

&lt;h6&gt;其中需要特别注意的是原本在视锥体坐标系上向前方向(forward)的X坐标轴变为了Z轴方向，整个立方体平面由x、y组成二维坐标体系。&lt;/h6&gt;

&lt;h6&gt;相当于，x、y坐标成为了可以映射到屏幕上的相对坐标，z坐标则被用来作为离屏幕有多远的数值参考，这是因为归一化后的NDC坐标系与原本视锥体坐标系相比其Z轴方向发生了翻转。&lt;/h6&gt;

&lt;p&gt;归一化坐标让坐标范围固定在1到-1之间，使得后续对图元数据的处理变得更加简单。不过归一化坐标范围在OpenGL和DirectX上有所不同，在OpenGL上x、y、z坐标范围在[-1,1]之间，而在DirectX上则是[0,1]之间，但这并不影响最终在屏幕上的表达，只是规则不同而已。最终他们都会进行简单的线性变换映射到屏幕的平面矩形范围内。虽然在屏幕映射时，OpenGL和DirectX两者的差异有出现了，OpenGL以左下角为(0,0)点，而DirectX则以左上角为(0,0)点，显然是两个商家因为竞争而故意造成的，还好主流的图形编程接口并不多，不管怎样差异已经存在了我们只能小心留意。&lt;/p&gt;

&lt;p&gt;说了这么多就是为了更好的理解几何阶段最后一步裁剪和剪切。我们将顶点转化到了归一化的坐标空间后，裁剪就容易多了，再通过图元装配，又有了线段和三角形数据，剪切就可以开始了。&lt;/p&gt;

&lt;p&gt;一个图元和可视范围关系，要么完全在范围内，要么完全在范围外，要么就是部分在里面部分在外面。完全在范围内的图元继续向下传递，不做任何操作，完全在范围外的图元则被剔除掉不再进入到后面的阶段，部分在视野内的图元则需要进一步剪切处理，把在范围外的部分剔除掉并在边界处生成新的顶点来连接没有被剔除的顶点。如下图：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    缺图
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;图中一个完整的三角形两个顶点在范围内，一个顶点在范围外，剪切后在边界上增加了两个顶点，这是比较复杂的情况，另一个中比较简单的情况时一个顶点在范围里，两个顶点在范围外，剪切后形成新的两个顶点与范围内的顶点结合后替换了原来的三角形。&lt;/p&gt;

&lt;h6&gt;我们来分析下那种复杂的情况，因为经过裁剪后三角形由3个顶点变成了4个顶点，成为了4边形，所以需要对这个四边形进行切割。切割的方法其实很简单，选一个新增的顶点与原本的两个顶点替换原来的三角形，另一个新增的顶点与前一个新增的顶点再加上一个旧顶点(这个旧顶点一定是剪切后新增的这个顶点的线段里的)形成新的三角形。&lt;/h6&gt;

&lt;p&gt;不仅如此，裁剪不仅仅是视口的裁剪，还有会有背面裁剪(Back-Face Culling)，即剔除面朝视口反方向的面片，将在后面的Shader编写中详细讲述。&lt;/p&gt;

&lt;p&gt;至此所有几何阶段的操作都结束了，总体来说几何阶段处理的是顶点，以及计算和准备下一个阶段需要用到的数据。&lt;/p&gt;

&lt;h6&gt;光栅化阶段&lt;/h6&gt;

&lt;p&gt;光栅化阶段分为三个节点，光栅化、片元着色器、逐片元操作。&lt;/p&gt;

&lt;p&gt;其中光栅化可以分成，三角形设置、三角形遍历两个节点。&lt;/p&gt;

&lt;p&gt;三角形设置即Triangle Setup，由于前面阶段都是空间意义上的顶点和三角形，到了光栅化阶段我们更加需要的屏幕上的像素，于是三角形设置可以认为是将所有三角形都铺在屏幕坐标平面上，这样就知道了每个三角形片面在屏幕上的范围，它用三角形边界的形式表达了这个覆盖面。&lt;/p&gt;

&lt;p&gt;知道覆盖面还不够，因为屏幕中展示的画面都是以像素为单位计算的，所以一个三角形覆盖哪些像素需要依靠扫描变换(Scan Conversion)得到，这个像素扫描阶段就是三角形遍历(Triangle Traversal)。如下图：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    缺图
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;图中，在三角形遍历节点中像素依据三角形三条边计算得到像素覆盖范围，即哪些像素被认为是这个三角形内的覆盖范围，再通过三个顶点中信息的插值得到每个像素的信息，信息包括坐标，深度，颜色，法线，纹理坐标等都是顶点上的信息经过插值得到。&lt;/p&gt;

&lt;h6&gt;经过光栅化的节点，我们得到了三角形内每个像素上的信息，我们称它们为片元，每个片元包含了诸多信息。这个片元将被传递到下一个阶段即片元着色器。&lt;/h6&gt;

&lt;p&gt;片元着色器(Fragment Shader)就如字面意思那样，是处理片元的地方，它是可编程的阶段，我们在这里可以编写很多我们喜欢操作来改变片元的颜色，或者也可以丢弃该片元(discard 或者 clip)。&lt;/p&gt;

&lt;p&gt;每个片元就相当于一个像素，只是比起像素，片元装载了很多的信息，这些信息都是通过前面三角形遍历时对三个顶点中的信息插值得到的。&lt;/p&gt;

&lt;p&gt;经过片元着色器的处理，也就是我们编写的片元着色程序的处理后，最终输出的也是片元，我们通常都在片元着色器中计算改变片元的颜色，最终得到一个我们想要的输出到屏幕的片元。&lt;/p&gt;

&lt;h6&gt;这里有一个重点，每次片元着色器处理片元的只是单个片元，也就是单个一个像素，对于片元着色器来说它并不知道相邻的片元是什么样，因此每个片元在处理时无法得到邻近的片元的信息。&lt;/h6&gt;

&lt;p&gt;得不到邻近的片元信息不代表我们就不可以受到邻近的片元影响，虽然每次片元着色器传入的和处理的都是单个片元，但GPU在跑片元着色器时并不是只跑一个片元着色器，而是将其组织成2x2的一组片元块同时跑4个片元着色器。如下图：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&lt;span&gt;&lt;/span&gt;    缺图
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上图中，描绘了4个片元组成的片元组，以及偏导数函数对它们的计算过程。我们可以通过ddx和ddy这两个偏导数函数来求得邻近片元的差值。偏导数函数可以用于片元着色器中的任何变量。对于向量和矩阵类型的变量，该函数会计算变量的每一个元素的偏导数。&lt;/p&gt;

&lt;p&gt;偏导数函数是纹理Mipmaps实现的基础，我们将在后面的章节中详细讲解。&lt;/p&gt;

&lt;p&gt;除了计算片元的颜色，我们还可以在片元着色器中丢弃某些片元(discard 或者 clip)，我们常说的Alpha Test就是一个应用丢弃片元来实现的效果，我们将在后面的章节中详细讲解 Alpha Test的原理与利弊。&lt;/p&gt;

&lt;h6&gt;片元着色器和顶点着色器是我们在着色器编程时最重要的两个节点，如果我们想要更通俗简单的理解顶点着色器和片元着色器的区别的话，可以认为：顶点着色器(包括细分着色器和几何着色器)决定了一个三角形应该放在屏幕的什么位置，而片元着色器则用这个三角形包括它的顶点和线段来决定三角形范围内的像素拥有什么样的颜色。&lt;/h6&gt;

&lt;p&gt;片元着色器输出片元后，进入了逐片元操作阶段，也是渲染管线的最后一步。&lt;/p&gt;

&lt;h6&gt;下一节继续讲解剩余的逐片元操作阶段。&lt;/h6&gt;
</description>
               <pubDate>Sat, 21 Sep 2019 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com//2019/09/21/Unity3D%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%9B%E9%98%B6%E4%B8%BB%E7%A8%8B-%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF%E4%B8%8E%E5%9B%BE%E5%BD%A2%E5%AD%A64.html</link>
               <guid isPermaLink="true">http://www.luzexi.com//2019/09/21/Unity3D%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%9B%E9%98%B6%E4%B8%BB%E7%A8%8B-%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF%E4%B8%8E%E5%9B%BE%E5%BD%A2%E5%AD%A64.html</guid>
            </item>
        
    </channel>
</rss>