<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title></title>
        <description>技术，哲学，金融</description>
        <link>http://www.luzexi.com</link>
        <atom:link href="http://www.luzexi.com/assets/feed.xml" rel="self" type="application/rss+xml" />
        
            <item>
               <title>Perfetto内存工具分析</title>
               <description>&lt;p&gt;用Markdown在贴图方面不是很方便，于是用印象笔记写了篇文章，尝试一下新的方式。&lt;/p&gt;

&lt;p&gt;我越来越觉得图对理解的重要性，所以想把更多文字转为以图文结合的方式表达，这样会更加清晰一些，也更易于理解。&lt;/p&gt;

&lt;p&gt;后面会更多的尝试用这样方式来写文章，即，用印象笔记写完后，导出html放在博客上。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/static-page/Perfetto/Index/Perfetto内存工具分析.html&quot;&gt;点击查看原文&lt;/a&gt;&lt;/p&gt;

</description>
               <pubDate>Wed, 20 Jan 2021 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2021/01/20/Perfetto%E5%86%85%E5%AD%98%E5%B7%A5%E5%85%B7%E5%88%86%E6%9E%90</link>
               <guid isPermaLink="true">http://www.luzexi.com/2021/01/20/Perfetto%E5%86%85%E5%AD%98%E5%B7%A5%E5%85%B7%E5%88%86%E6%9E%90</guid>
            </item>
        
            <item>
               <title>读书笔记(十八) 《C++性能优化指南》三</title>
               <description>&lt;p&gt;此篇主要介绍热点代码、I/O、以及并行部分的优化，我们会从原理出发来，再根据原理讲优化，这样即学习了原理，又知道了优化的来龙去脉。&lt;/p&gt;

&lt;h2 id=&quot;热点代码&quot;&gt;热点代码&lt;/h2&gt;

&lt;p&gt;这里作者带我们聊一聊关于代码细节的优化，虽然语句的细节优化并不能带来非常明显的提升，但是也是非常有必要的优化步骤，尤其在那些追求极致高性能或精小的组件中，代码细节的优化决定了组件与组件之间的差异。&lt;/p&gt;

&lt;p&gt;语句细节的优化，其实质是对CPU指令的优化，可以认为是从执行指令流中移除指令的过程。下面先来阐述一下细节优化的原理。&lt;/p&gt;

&lt;h3 id=&quot;语句的细节优化其实质是执行指令数量的优化指令跳转次数的优化向栈中保存临时寄存器次数的优化以及内存分配次数的优化&quot;&gt;语句的细节优化，其实质是执行指令数量的优化，指令跳转次数的优化，向栈中保存临时寄存器次数的优化，以及内存分配次数的优化。&lt;/h3&gt;

&lt;p&gt;执行指令数量减少了可以减少CPU在执行程序时的耗时我们很好理解，指令跳转则是因为指令也是被放在内存中的数据，因此它也会被高速缓存cache，长距离跳转会让高速缓存失效，静态函数调用和非成员函数调用通常都是长距离指令跳转的典型案例。&lt;/p&gt;

&lt;p&gt;函数调用开销不可忽视，即使一个空函数，在调用时也会有性能开销（编译器可能会帮我们优化掉空函数），有时为了极致的优化，我们应该最大限度的减少调用函数的频率，特别是频率最高的top3。&lt;/p&gt;

&lt;p&gt;因为在函数被调用时会保存当前函数的数据，包括参数、局部变量、当前指令地址、临时寄存器和标记寄存器等，每次调用一个函数会做如下处理：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;	1.当调用函数时，先保存当前函数的临时变量、参数、临时寄存器、标记寄存器。
	
	2.将这些每个要保存的数据都复制到栈中。
	
	3.当前执行的地址复制到栈中。

	4.将指令指针寄存器IP指向要执行的函数体的第一句

	5.执行函数体中的指令

	6.将函数调用结果保存到寄存器

	7.从栈中推出要返回的地址，并复制给指令寄存器IP

	8.推出栈中的临时寄存器、参数、局部变量、标记寄存器都重新还原回去

	9.继续执行剩下的指令直到遇到下一个函数。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果遇到成员函数是虚函数的，还得先从虚表中偏移并取出函数地址再调用，这里又多了2次计算，即先取出虚表地址、再根据虚表地址偏移获得真正的函数地址、最后再才能跳转过去。如果是多重继承、或者是多重继承的继承类中的虚函数成员，则需要再加一次地址偏移计算。&lt;/p&gt;

&lt;p&gt;inline内联是减少函数调用的最佳方式，内联函数并不像一般函数那样会保存数据并且跳转指令，因为编译器会就地展开内联函数中的指令，因此没有推栈入栈保存数据到栈和跳转指令到函数再返回的步骤，取而代之的是就地直接执行指令。&lt;/p&gt;

&lt;p&gt;这样看来减少函数调用(或让函数内联)的同时也减少了入栈、出栈、复制数据的指令数量，也减少了指令跳转的丢失高速缓存的概率。&lt;/p&gt;

&lt;p&gt;不必要的内存分配也是在代码细节中常犯的错误，尤其指向堆内存分配，当函数中需要某个容器或者类实例时，常会临时向堆内存申请一次以用来计算。&lt;/p&gt;

&lt;p&gt;我们来看看以上这说的7个细节的具体例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
for(int i = 0 ; i&amp;lt;strlen(str) ; i++)
	...

//改为

for(int i = 0, n = strlen(str) ; i&amp;lt;n ; i++)
	...

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1.将重复计算提到前面，但这里不一定有优化，因为编译器可能会识别这类循环并将实时计算移出去，不过不能保证编译器一定会这么干，所以我们最好做人为的优化，保证不重复计算。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
void function()
{
	list = new list();
	for(int i = 0 ; i&amp;lt;n ; i++)
	{
		list.Add(xx);
	}

	return;
}

//改为

public static list = new list(); //改为全局变量

void function()
{
	list.Clear();
	for(int i = 0 ; i&amp;lt;n ; i++)
	{
		list.Add(xx);
	}

	return;
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.函数中临时的堆内存分配，改为全局的共用内存，只要分配一次，每次使用前先清理就能节省开销。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
int k = 0;
for(int i = 0 ; i&amp;lt;100 ; i++)
{
	int j = sin(100) + cos(50);
	k = j*i;
}

//改为

int k = 0;
int j = sin(100) + cos(5);
for(int i = 0 ; i&amp;lt;100 ; i++)
{
	k = j*i;
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.移除循环中不变的计算，减少不必要的指令，可能会被编译器优化掉。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;for(int i = 0 ; i&amp;lt;10 ; i++)
{
	int b = Add(3,5);
	...
}

//改为

int b = 0
for(int i = 0 ; i&amp;lt;10 ; i++)
{
	b = 3 + 5;
	...
}

//或者将Add函数内联

inline int Add(a,b)
{
	...
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4.用内联或者手动内联的方式，减少循环中的函数调用开销。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
string str = &quot;a&quot;;

str = &quot;&amp;lt;p&amp;gt;&quot; + str + &quot;&amp;lt;/p&amp;gt;&quot;;

//改为

str = string.format(&quot;&amp;lt;p&amp;gt;{0}&amp;lt;/p&amp;gt;&quot;,str);

//或者

str = StringCacheMgr.instance.Format(&quot;&amp;lt;p&amp;gt;{0}&amp;lt;/p&amp;gt;&quot;,str);

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5.减少字符串内存分配次数，将原来要分配两次的字符串，改为只要分配1次。或者使用自制的字符串内存管理方式管理分配和操作字符串(前面的内存优化那一节我们讲过这种方式)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
for(int i = 0 ; i&amp;lt;1000 ; i++)
{
	test();
}

//改为

test();

void test()
{
	for(int i = 0 ; i&amp;lt;1000 ;i++)
	{
		...
	}
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;6.将1000次调用函数的开销改为1次，节省函数调用的开销。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
if(x == a)
{
	...
}
else if(xx == a)
{
	...
}
else if(xxx == a)
{
	...
}
else ...

//改为

switch(a)
{
	case x:
		break;
	case xx:
		break;
	case xxx:
		break;
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;7.通常switch都会被编译器优化为索引的方式去跳转，因此用switch比if效率高的多，也不用我们自己对数据排序。&lt;/p&gt;

&lt;p&gt;最后说下异常try catch的开销，在早期C++的try catch机制会在栈帧上包含一个异常上下文，这些上下文会随着异常抛出或者作用范围结束而销毁，增加性能开销。现在则不同了，上下文开销都没有了，只是会在开始try时多几个指令更改中断程序的指向，退出时再改回来，但是即使这样，我们也不能有太多try catch，因为try catch太多仍然会多出很多额外的指令消耗。&lt;/p&gt;

&lt;h3 id=&quot;我们做个小结我们说语句的细节优化实质是减少执行指令数量减少指令跳转次数减少函数调用以及减少内存分配次数我们用代码细节来解释有哪些细节是可以遵从我们的原理来优化的这些细节的优化在性能要求比较高的组件上会比较有用好的代码细节是业务逻辑优化的前提业务逻辑上当我们更多运用的是调整实现方式调整数据结构的方式调整业务逻辑策略的方式时这些细节的优化则成了底层的支柱&quot;&gt;我们做个小结，我们说语句的细节优化，实质是减少执行指令数量，减少指令跳转次数，减少函数调用，以及减少内存分配次数。我们用代码细节来解释有哪些细节是可以遵从我们的原理来优化的，这些细节的优化，在性能要求比较高的组件上会比较有用，好的代码细节是业务逻辑优化的前提。业务逻辑上，当我们更多运用的是调整实现方式，调整数据结构的方式，调整业务逻辑策略的方式时，这些细节的优化则成了底层的支柱。&lt;/h3&gt;

&lt;h2 id=&quot;io-文件操作&quot;&gt;I/O 文件操作&lt;/h2&gt;

&lt;h3 id=&quot;io操作的优化空间相对比较小是因为它主要的工作大部分由操作系统完成因此我们先介绍下操作系统中io的读写原理再从原理出发优化io操作效率包括降低读写次数减少读取时间和优化体验俩个方面&quot;&gt;I/O操作的优化空间相对比较小，是因为它主要的工作大部分由操作系统完成。因此我们先介绍下操作系统中I/O的读写原理，再从原理出发优化I/O操作效率，包括降低读写次数减少读取时间和优化体验俩个方面。&lt;/h3&gt;

&lt;p&gt;操作系统中为了分割操作内容让调用更安全，分为‘用户态’和‘内核态’，当用户态需要内核态工作时我们称为‘系统调用’，我们平常写的程序只要不涉及系统调用的都是用户态完成的，一旦涉及到需要操作系统工作的部分，就要先切到内核态完成工作，结束后再切回用户态继续执行后面的程序，这个切换的过程是比较费时费力的，I/O调用就是其中一种需要切换内核态的系统调用。&lt;/p&gt;

&lt;p&gt;操作系统可以支持多种底层不同的文件系统（比如NTFS, FAT, ext3, ext4），为了给内核和用户进程提供统一的文件系统视图，Linux在用户进程和底层文件系统之间加入了一个抽象层，即虚拟文件系统(Virtual File System, VFS)，进程所有的文件操作都通过VFS，由VFS来适配各种底层不同的文件系统，完成实际的文件操作。&lt;/p&gt;

&lt;h3 id=&quot;这里我们来了解下虚拟文件系统构成和主要模块&quot;&gt;这里我们来了解下虚拟文件系统构成和主要模块：&lt;/h3&gt;

&lt;h3 id=&quot;超级块super_block&quot;&gt;超级块（super_block）&lt;/h3&gt;

&lt;p&gt;用于保存一个文件系统的所有元数据，相当于这个文件系统的信息库，为其他的模块提供信息。&lt;/p&gt;

&lt;p&gt;因此一个超级块可代表一个文件系统，文件系统的任意元数据修改都要通过超级块修改，超级块对象是常驻内存并被缓存起来的。&lt;/p&gt;

&lt;h3 id=&quot;目录项模块&quot;&gt;目录项模块&lt;/h3&gt;

&lt;p&gt;是管理路径的目录项，比如一个路径 /home/foo/hello.txt，那么目录项有home, foo, hello.txt三个。&lt;/p&gt;

&lt;p&gt;每个目录项的块，存储的是这个目录下的所有的文件的inode号和文件名等信息。其内部是树形结构，操作系统检索一个文件是从根目录开始，按层次解析路径中的所有目录，直到定位到具体文件。&lt;/p&gt;

&lt;h3 id=&quot;inode模块&quot;&gt;inode模块&lt;/h3&gt;

&lt;p&gt;管理的是一个具体的文件，是文件的唯一标识，一个文件对应一个inode。&lt;/p&gt;

&lt;p&gt;通过inode可以方便的找到文件在磁盘扇区的位置，同时inode模块可链接到address_space模块，方便查找自身文件数据是否已经被缓存在内存中。&lt;/p&gt;

&lt;h3 id=&quot;打开文件列表模块&quot;&gt;打开文件列表模块&lt;/h3&gt;

&lt;p&gt;包含所有内核已经打开的文件，已经打开的文件对象由open系统调用在内核中创建，也叫文件句柄。&lt;/p&gt;

&lt;p&gt;打开文件列表模块中包含一个列表，列表表项是一个结构体struct file，结构体中的信息存储了打开的一个文件的各种状态参数。&lt;/p&gt;

&lt;h3 id=&quot;file_operations模块&quot;&gt;file_operations模块&lt;/h3&gt;

&lt;p&gt;模块中维护一个数据结构，是一系列函数指针的集合，其中包含所有可以使用的系统调用函数，例如open、read、write、mmap等。&lt;/p&gt;

&lt;p&gt;每个打开文件（打开文件列表模块的一个表项）都可以连接到file_operations模块，从而对任何已打开的文件，通过系统调用函数，实现各种操作。&lt;/p&gt;

&lt;h3 id=&quot;address_space模块&quot;&gt;address_space模块&lt;/h3&gt;

&lt;p&gt;记录了文件在页缓存中已经缓存了的物理页信息，是页缓存和外部设备中文件系统的桥梁。如果将文件系统可以理解成数据源，内存中的页缓存是已经读取的内容，那么address_space可以说是内存系统和文件系统的中间层。&lt;/p&gt;

&lt;h3 id=&quot;所有文件信息保存在超级块中通过目录项模块找到文件所在位置所有被打开的文件放在文件列表模块中file_operations模块负责操作文件每个文件都有唯一标识inode磁盘数据与内存缓存通过address_space联接与映射&quot;&gt;所有文件信息保存在超级块中，通过目录项模块找到文件所在位置，所有被打开的文件放在文件列表模块中，file_operations模块负责操作文件，每个文件都有唯一标识inode，磁盘数据与内存缓存通过address_space联接与映射。&lt;/h3&gt;

&lt;h3 id=&quot;下面我们来看看读写入文件时的基本流程&quot;&gt;下面我们来看看读写入文件时的基本流程：&lt;/h3&gt;

&lt;h3 id=&quot;读文件&quot;&gt;读文件&lt;/h3&gt;

&lt;p&gt;1、进程调用库函数向内核发起读文件请求；&lt;/p&gt;

&lt;p&gt;2、内核通过检查进程的文件描述符定位到虚拟文件系统的已打开文件列表表项；&lt;/p&gt;

&lt;p&gt;3、调用该文件可用的系统调用函数read()&lt;/p&gt;

&lt;p&gt;read()函数通过文件表项链接到目录项模块，根据传入的文件路径，在目录项模块中检索，找到该文件的inode；&lt;/p&gt;

&lt;p&gt;4、在inode中，通过文件内容偏移量计算出要读取的页；&lt;/p&gt;

&lt;p&gt;5、通过inode找到文件对应的address_space；&lt;/p&gt;

&lt;p&gt;6、在address_space中访问该文件的页缓存树，查找对应的页缓存结点：&lt;/p&gt;

&lt;p&gt;（1）如果页缓存命中，那么直接返回文件内容；&lt;/p&gt;

&lt;p&gt;（2）如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过inode找到文件该页的磁盘地址，读取相应的页填充该缓存页；重新进行第6步查找页缓存；&lt;/p&gt;

&lt;p&gt;7、文件内容读取成功。&lt;/p&gt;

&lt;h3 id=&quot;写文件&quot;&gt;写文件&lt;/h3&gt;

&lt;p&gt;前5步和读文件一致，在address_space中查询对应页的页缓存是否存在：&lt;/p&gt;

&lt;p&gt;6、如果页缓存命中，直接把文件内容修改更新在页缓存的页中。写文件就结束了。这时候文件修改位于页缓存，并没有写回到磁盘文件中去。&lt;/p&gt;

&lt;p&gt;7、如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过inode找到文件该页的磁盘地址，读取相应的页填充该缓存页。此时缓存页命中，进行第6步。&lt;/p&gt;

&lt;p&gt;8、一个页缓存中的页如果被修改，那么会被标记成脏页。脏页需要写回到磁盘中的文件块。有两种方式可以把脏页写回磁盘：&lt;/p&gt;

&lt;p&gt;（1）手动调用sync()或者fsync()系统调用把脏页写回&lt;/p&gt;

&lt;p&gt;（2）pdflush进程会定时把脏页写回到磁盘&lt;/p&gt;

&lt;p&gt;同时注意，脏页不能被置换出内存，如果脏页正在被写回，那么会被设置写回标记，这时候该页就被上锁，其他写请求被阻塞直到锁释放。&lt;/p&gt;

&lt;h3 id=&quot;页缓存实际上就是一个基数树结构它将一个文件的内容组织起来存放在struct-page结构中文件越大树形结构越庞大每一页都记录着文件内容的页信息和缓存信息&quot;&gt;页缓存实际上就是一个基数树结构，它将一个文件的内容组织起来存放在struct page结构中，文件越大树形结构越庞大，每一页都记录着文件内容的页信息和缓存信息。&lt;/h3&gt;

&lt;p&gt;另外内核使用task_struct来表示单个进程的描述符，其中包含维护一个进程的所有信息。task_struct结构体中维护了一个 files的指针（和“已打开文件列表”上的表项是不同的指针）来指向结构体files_struct，files_struct中包含文件描述符表和打开的文件对象信息，这使得系统能够：&lt;/p&gt;

&lt;p&gt;1、多个进程可以同时指向一个打开文件对象（文件列表表项）。&lt;/p&gt;

&lt;p&gt;2、一个进程可以多次打开一个文件，生成不同的文件描述符，每个文件描述符指向不同的文件列表表项。但是由于是同一个文件，inode唯一，所以这些文件列表表项都指向同一个inode。&lt;/p&gt;

&lt;h3 id=&quot;我们知道了文件的读写原理再来看看我们在平时编写文件操作时的优化思路&quot;&gt;我们知道了文件的读写原理再来看看我们在平时编写文件操作时的优化思路。&lt;/h3&gt;

&lt;p&gt;1.减少读写次数，减少读写时间。&lt;/p&gt;

&lt;p&gt;由于每次读取文件内容都会从用户态转到内核态，完成后再切回来，这种切换的消耗是比较重的，因此我们应该尽量减少读写次数。&lt;/p&gt;

&lt;p&gt;在读取一个文件时，尽量将需要的内容一次性读取完毕，甚至可以预先读取未来的内容，以避免多次读取。在写文件时也是同样，尽量一次性写入硬盘，避免多次写入。例如下面代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
while(getline(file,line))
{
	doSomeThing(line);
}

//改为

lines = getlines(file);

for(int i = 0 ,n = len(lines) ; i&amp;lt; n ; ++i)
{
	doSomeThing(lines[i]);
}

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;一次性读取所有行再对每行做处理&quot;&gt;一次性读取所有行，再对每行做处理。&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
void write_lines(std::ostream&amp;amp; file std::string const&amp;amp; lines[])
{
	for(int i = 0,n = len(lines) ; i&amp;lt;n ; ++i)
	{
		file &amp;lt;&amp;lt; lines[i]
		file-&amp;gt;flush();
	}
}

//改为

void write_lines(std::ostream&amp;amp; file std::string const&amp;amp; lines[])
{
	for(int i = 0,n = len(lines) ; i&amp;lt;n ; ++i)
	{
		file &amp;lt;&amp;lt; lines[i];
	}
	file-&amp;gt;flush();
}

//或用内存池的方式改为

void write_lines(std::ostream&amp;amp; file std::string const&amp;amp; lines[])
{
	int str_size = 0;
	for(int i = 0,n = len(lines) ; i&amp;lt;n ; ++i)
	{
		str_size += len(lines[i] + 1)*sizeof(char);
	}
	
	byte[] data = MemoryPool.instance.AllocMemory(str_size);

	CombineStringData(lines, data); //将lines中的数据都拷贝到data中

	file-&amp;gt;write(data);
	file-&amp;gt;flush();

	MemoryPool.instance.Free(data);
}

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;每次写入文件时系统并不会立即写入文件而是存放在页缓存如果我们每次刷新则会每次都同步到硬盘写入硬盘速度比较内存慢很多会消耗比较长时间所以要减少刷新调用次数&quot;&gt;每次写入文件时系统并不会立即写入文件，而是存放在页缓存，如果我们每次刷新，则会每次都同步到硬盘，写入硬盘速度比较内存慢很多，会消耗比较长时间，所以要减少刷新调用次数。&lt;/h3&gt;

&lt;h3 id=&quot;只是减少刷新次数但依然减少不了内核态切换的次数于是我们用内存池的方式减少内存分配的时间将内存分配的耗时降低将原本要调用很多次系统调用的次数降低为了一次从而减少了内核态切换的次数&quot;&gt;只是减少刷新次数，但依然减少不了内核态切换的次数。于是我们用内存池的方式减少内存分配的时间，将内存分配的耗时降低，将原本要调用很多次系统调用的次数降低为了一次，从而减少了内核态切换的次数。&lt;/h3&gt;

&lt;p&gt;2.优化体验&lt;/p&gt;

&lt;p&gt;用阻塞读取的方式，由于线程要等待磁盘设备的工作，对于整个程序的效率来说是比较低的，因为硬盘设备读写的速度比较慢，主线程要等待硬盘设备工作完毕后才进行后面的工作。因此为了能让程序的整体效率提升，我们可以用异步读取的方式来优化整体的程序时间，即在读取或写入文件的同时，其他程序工作同步进行。&lt;/p&gt;

&lt;p&gt;最常见的是游戏的开机画面，加载画面，切换场景画面，甚至有些游戏中边加载边进行的部分，都是可以通过并行来优化体验的。&lt;/p&gt;

&lt;h3 id=&quot;文件读写并发通常都是开启线程后的读写操作与阻塞内容一样只是更多的利用可利用的cpu时间而不让线程空闲等待硬盘原理是我们尽力能让计算机中的所有设备资源都满负荷运转并很好的协作而不是相互牵制&quot;&gt;文件读写并发通常都是开启线程后的读写操作，与阻塞内容一样，只是更多的利用可利用的CPU时间而不让线程空闲等待硬盘，原理是我们尽力能让计算机中的所有设备资源都满负荷运转并很好的协作，而不是相互牵制。&lt;/h3&gt;

&lt;p&gt;下面我们就来讲讲并发的优化内容。&lt;/p&gt;

&lt;h2 id=&quot;并发&quot;&gt;并发&lt;/h2&gt;

&lt;p&gt;并发的方案有很多特别是在业务层上有很多技巧，这里只是选取与语言相关部分。我们将从原理出发讲一讲，线程同步中的技巧、原子性、以及无锁容器的原理。&lt;/p&gt;

&lt;p&gt;由于设备资源并不总是运行，因为我们的程序并没有使用到这些资源，或者说有时没有同一时间同时让它们一起运转，这使得资源的闲置造成了浪费，如果能在当某个程序在执行指令时，另一个设备在满负荷运作，这样就相当于提高了运行效率。&lt;/p&gt;

&lt;h3 id=&quot;并发的挑战是找到足够多的独立任务来充分地使用所有可用的计算机资源让资源都能满负荷的执行提高整体运行效率其中cpu资源是最稀缺也是使用最频繁的资源如果能让多核中所有cpu都满负荷工作不考虑降频问题程序的效率就能提高很多即使不满负荷也能提其他cpu分担不少工作让降频的概率减少到最低&quot;&gt;并发的挑战是找到足够多的独立任务来充分地使用所有可用的计算机资源，让资源都能满负荷的执行，提高整体运行效率。其中CPU资源是最稀缺，也是使用最频繁的资源，如果能让多核中所有CPU都满负荷工作(不考虑降频问题)程序的效率就能提高很多，即使不满负荷，也能提其他CPU分担不少工作，让降频的概率减少到最低。&lt;/h3&gt;

&lt;p&gt;首先我们来梳理下操作系统中的进程、线程、时间片的概念。&lt;/p&gt;

&lt;p&gt;线程是实际工作的单元，进程只是一个容器用来管理线程。严格来说Linux内核其实不区分进程和线程，内核把执行单元叫做任务(Task)。操作系统实际上调度的是进程，进程通过fork()来创建同样的另一个进程。每个进程有一个PID，同一组进程中最先启动的那个还有一个TGID，严格来说前者应该叫线程ID，后者应该叫进程ID，其实它们都是Linux的Task。&lt;/p&gt;

&lt;p&gt;多线程能同时做好几件事情以提高效率，但实际问题是，CPU的数量（核心数）是有限的，而且并不多。如果你的CPU有8个核，并且整个操作系统中有8个线程的话，不考虑中断等因素，每个线程理论上能一直执行下去。然而多于8个线程以后，操作系统就必须进行调度，也就是分配时间片。具体的分配方案，或者说调度算法有很多种。如果一个进程创建了很多线程的话，最多也只有8个能够处于执行的状态(这里说的是物理线程，有别于逻辑线程)，其余的线程必须等待调度。线程被调度的时候需要进行上下文切换，这个操作是一种额外的开销。当线程数量过多的时候，上下文切换产生的额外开销会对系统的效率造成负面影响。&lt;/p&gt;

&lt;p&gt;线程的调度算法和进程一样通常有优先级之分，优先级高的线程可以比优先级低的线程多抢占些CPU时间片。甚至不同的线程可以通过系统调用将线程绑定在某个CPU核上。因此我们也可以通过将线程绑某个cpu核的方式来强制执行线程调度，从而优化并行开销。&lt;/p&gt;

&lt;h3 id=&quot;线程同步&quot;&gt;线程同步&lt;/h3&gt;

&lt;p&gt;通常我们在多个线程交叉执行时最关心的是同步问题。解决这个问题我们可以用，减少锁的占用时间、减少锁的颗粒度、无锁容器三个方式。前两者更好理解些，也用的比较多，最后一个需要阐明下原理。&lt;/p&gt;

&lt;p&gt;通常我们使用锁和互斥量来解决线程间的同步问题，但这会带来潜在问题，就是由于锁的原因导致线程间的等待时间变长，实际执行的效率可能并没有因此而增加。&lt;/p&gt;

&lt;p&gt;因此锁的范围必须被压缩到最小，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
void doFunction(item)
{
	lock(obj)
	{
		doSomeThing1();

		list.push(item); //must lock

		doSomeThing2();
	}
}

//改为

void doFunction(item)
{
	doSomeThing1();

	lock(obj)
	{
		list.push(item); //must lock
	}

	doSomeThing2();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;尽可能的缩小锁的范围减少锁等待时间&quot;&gt;尽可能的缩小锁的范围，减少锁等待时间。&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
void doFunction1()
{
	lock(obj)
	{
		...
	}
}

void doFunction2()
{
	lock(obj)
	{
		...
	}
}

//改为

void doFunction1()
{
	lock(obj1)
	{
		...
	}
}

void doFunction2()
{
	lock(obj2)
	{
		...
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;减少锁的颗粒度让各自的锁只负责自己一小部分的内容这里也涉及到细粒度锁算法它通常基于轻量级原子性原语由于并不是基于系统提供的同步原语所以性能开销很小但在高并发的情况下细粒度锁算法就会成为程序的瓶颈&quot;&gt;减少锁的颗粒度，让各自的锁只负责自己一小部分的内容。这里也涉及到细粒度锁(算法)，它通常基于轻量级原子性原语，由于并不是基于系统提供的同步原语所以性能开销很小，但在高并发的情况下，细粒度锁(算法)就会成为程序的瓶颈。&lt;/h3&gt;

&lt;p&gt;由于指定锁某些局部的计算范围或者函数，锁的时间太长并不划算，所以我们通常在两个线程间的协作上使用消息队列(或者其他容器)让线程更大程度的并行，但这依然需要对容器加锁，以使得操作不冲突。&lt;/p&gt;

&lt;p&gt;为了能让容器冲突时间更小，当只有两个线程操作容器时，我们通常会采用些技巧。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;例如双队列，设置两个队列，其中一个用于处理消息，另一个用于接收消息，当处理消息时，两个队列的头指针交换一下再处理，这样就能让接收的队列继续接收，处理的队列独自处理，这种方式的缩短了锁的占用时间，锁的时间缩短到了变量交换时间。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;以及循环队列的方式，用头尾循环的方式做队列，一个线程只对尾部操作，另一个线程只对头部操作，发送数据的线程向尾部推入数据，接收数据的线程从头部取出数据，循环操作队列，只有当队列满时才需要停一停等待数据
处理，其他时候，两者永远都不需要相互等待。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;无锁容器&quot;&gt;无锁容器&lt;/h3&gt;

&lt;p&gt;无锁容器的复杂度有点高，它适用于高并发场景，这里不便深入，其原理是原子操作。虽然我们不深入无锁容器的具体写法，但我们用问答的方式来解释下原子操作。&lt;/p&gt;

&lt;h3 id=&quot;什么是原子性&quot;&gt;什么是原子性？&lt;/h3&gt;

&lt;p&gt;如果一个更新操作不会计算到一半的时候被另外一个线程看到，就叫原子性。&lt;/p&gt;

&lt;p&gt;原子操作可认为是一个不可分的操作；要么发生，要么没发生，我们看不到任何执行的中间过程，不存在部分结果(partial effects)。可以想象的到，原子操作要保证要么全部发生，要么全部没发生，这样原子操作绝对不是一个廉价的消耗低的指令，相反，原子操作是一个较为昂贵的指令。&lt;/p&gt;

&lt;h3 id=&quot;非原子操作为什么会更新到一半被另一个线程看到&quot;&gt;非原子操作，为什么会更新到一半被另一个线程看到？&lt;/h3&gt;

&lt;p&gt;即使一个简单的整型变量的赋值操作，也有可能更新到一半被另一个线程看到，这是为什么呢？原因就是高速缓存中的旧数据。&lt;/p&gt;

&lt;p&gt;由于每个cpu除了共享一个内存设备外还有各自的高速缓存，一个cpu更新了内存中的内容后，其实并没有通知其他cpu中的缓存去掉该内容，这导致其他cpu中的高速缓存存储的仍然是旧的数据。当这些CPU读取这个变量时会从缓存中取得旧数据，直到缓存中的这个数据被丢弃或更新。&lt;/p&gt;

&lt;h3 id=&quot;原子操作做了什么使得更新不被其他线程看到&quot;&gt;原子操作，做了什么使得更新不被其他线程看到？&lt;/h3&gt;

&lt;p&gt;CPU的高速缓存间有一个MESI协议(cache一致性协议，4个关键词 Modifed Exclusive Shared Invalid 拼凑起来的缩写)，通过这个消息协议，CPU可以查看其他CPU高速缓存中的数据状态，就像不同设备间通信那样。&lt;/p&gt;

&lt;p&gt;当执行原子操作 store 即写入数据时，先查看当前cpu高速缓存中有没有数据，如果没有，则通知其他cpu中的高速缓存该数据切为无效状态，等待所有cpu都将该数据切为无效状态后，此cpu才开始发起写入内存和高速缓存的操作，并标记该值为修改状态。如果有，则更新高速缓存中的值，并通知其他cpu中的高速缓存该值已经不合法，最后此cpu并没有将该值写入内存，而是在高速缓存中标记该值被修改，以便下次再利用，或者等到丢弃时再写入内存。&lt;/p&gt;

&lt;p&gt;当执行原子操作 load 即读取数据时，先查看当前cpu高速缓存中有没有该数据，如果没有(或者是无效的)，则从先从查看其他cpu中查看该数据，如果有则获取，没有则从内存中获取。如果当前cpu高速缓存中有该数据，则直接使用该数据(必须不是无效的)。&lt;/p&gt;

&lt;h3 id=&quot;其他并行优化&quot;&gt;其他并行优化&lt;/h3&gt;

&lt;p&gt;1.分割资源，减少线程间的争夺。&lt;/p&gt;

&lt;p&gt;分割或者复制一块内存出来，让某个线程专门使用，这样就不会与其他线程冲突，计算结束时再考虑合并的事。&lt;/p&gt;

&lt;p&gt;此方法在Unity引擎的 Job System中有使用到，即给Job System一块独立的内存来处理自己的事物，与其他线程不冲突。&lt;/p&gt;

&lt;p&gt;2.散列容器，减少锁的范围，和前面介绍的细粒度锁(算法）稍微有点不一样，这种容器是散列的，冲突更少但使用范围很小。&lt;/p&gt;

&lt;p&gt;3.SIMD指令虽然不是并行，但由于它可以同时处理4个数据的运算，也算是勉强算并行处理了。&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/huxiao-tee/p/4657851.html&quot;&gt;《从内核文件系统看文件读写过程》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/64723752&quot;&gt;《Linux系统中 进程 、线程 、时间片的关系》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.jiqizhixin.com/articles/2019-01-22-12&quot;&gt;《说说无锁(Lock-Free)编程那些事》&lt;/a&gt;&lt;/p&gt;
</description>
               <pubDate>Sun, 27 Dec 2020 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2020/12/27/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B018</link>
               <guid isPermaLink="true">http://www.luzexi.com/2020/12/27/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B018</guid>
            </item>
        
            <item>
               <title>给女儿的信(七)</title>
               <description>&lt;p&gt;Hi 陆秀恩&lt;/p&gt;

&lt;p&gt;圣诞快乐，今年的圣诞爸爸在很远的深圳，爸爸好想跟你一起过圣诞，爸爸一直很想念你，也一直很关注你。&lt;/p&gt;

&lt;p&gt;我知道你与同学相处的越来越融洽了，在学校里的表现很积极很开朗，大家都喜欢跟你交朋友，因为你懂得关心朋友。&lt;/p&gt;

&lt;p&gt;你的画画和跳舞越来越棒了，对自己喜欢的事很专注。我跟秀恩一样也很专注呢。我还听妈妈说你越来越自律了，这是个不错的开始喔。&lt;/p&gt;

&lt;p&gt;爸爸一直在学习如何学习，想把学习的技巧再多研究一下，让自己更懂得如何高效学习，以前爸爸学习总是很低效，注意力很难集中，浪费了很多时间，现在我想改变一下自己。&lt;/p&gt;

&lt;p&gt;这是一条漫长的路，爸爸每天都在坚持，坚持每天看点书，每天运动一下，每天学习一下，这样一天天积累下来，1年就会有大的不同，3、5年就有翻天覆地的变化。我想成为一个知识渊博的人，可能成不了科学家，但可以成为一个有价值的人，一个自律、智慧、有爱的人。&lt;/p&gt;

&lt;p&gt;爸爸很想念你，祝你圣诞快乐，加油陆秀恩 ：）&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Hi 陆安妮&lt;/p&gt;

&lt;p&gt;圣诞快乐，爸爸很想念你。&lt;/p&gt;

&lt;p&gt;我常听妈妈说你也很想念爸爸，爸爸心里暖暖的很高兴。&lt;/p&gt;

&lt;p&gt;在幼儿园里的日子还好么，和朋友们相处的还融洽么，爸爸很想过来每天都陪着你，但爸爸有点忙，需要在深圳工作几年。&lt;/p&gt;

&lt;p&gt;爸爸知道最近你跟姐姐一起开始学习写字和数学，爸爸知道你很努力，跟爸爸一起加油喔。你会慢慢的找到自己学习的节奏的，安妮。你很棒哎，要坚持住喔。爸爸也在深圳努力呢，每天都有学习和健身，爸爸跟你一起做身体壮壮的、学习棒棒的好孩子，比心。&lt;/p&gt;

&lt;p&gt;爸爸拿着你送给我的画，每天都放在床头看一下，一看到这幅画爸爸就想到你，下次记得再送爸爸一副画哦。最近去台上表演时心里紧张吗，爸爸看了你跳舞的视频，很不错哎，我们再接再厉，一起加油。&lt;/p&gt;

&lt;p&gt;爸爸、妈妈、小姨妈、安妮、秀恩都一起加油，加~油~！&lt;/p&gt;

&lt;p&gt;圣诞快乐安妮，想念你的爸爸 ：）&lt;/p&gt;

</description>
               <pubDate>Fri, 25 Dec 2020 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2020/12/25/%E7%BB%99%E5%A5%B3%E5%84%BF%E7%9A%84%E4%BF%A17</link>
               <guid isPermaLink="true">http://www.luzexi.com/2020/12/25/%E7%BB%99%E5%A5%B3%E5%84%BF%E7%9A%84%E4%BF%A17</guid>
            </item>
        
            <item>
               <title>读书笔记(十七) 《C++性能优化指南》二</title>
               <description>&lt;h3 id=&quot;字符串问题&quot;&gt;字符串问题&lt;/h3&gt;

&lt;p&gt;这里作者讲的有点啰嗦，没有围绕着重点去讲，所以这里我吸收下他的知识点并总结下自己的知识点和经验。&lt;/p&gt;

&lt;p&gt;把字符串问题单独拎出来说是因为字符串问题比较大，也比较隐性，常常容易引起性能问题。字符串在概念上很简单，它就是一个字符数组，但是想要实现高效的字符串却非常不容易。&lt;/p&gt;

&lt;p&gt;首先字符串内存是动态分配的，其次是字符串常常被用来当成一个值来使用，这导致字符串操作常常带来大量不必要的内存分配和内存复制。&lt;/p&gt;

&lt;p&gt;字符串问题的重点在内存分配问题和字符串查找。字符串操作带来的内存频繁的分配和浪费导致程序性能效率大大降低，操作包括，字符串拼接、字符串拆分、字符串大小写切换等，每次操作字符串都会新分配一个字符串内存或者字符串内存集，而查找字符串，即使使用算法通常也会逐字比较，效率比价差，特别是在一个集合中查找某个字符串对应的值时，需要完整的比较两者字符串是否完全一致。&lt;/p&gt;

&lt;p&gt;改善内存分配效率，我们可以使用预分配和内存池机制。字符串内存预分配可以有2种，一种预先分配很多个长度不同的字符串缓存起来，使用时给出去，例如分别预分配1-50长度的字符串各100个，当逻辑需要时再给出去，用完了再收回来。另一种是先分配多个长一点的字符串，例如分配100个100长度的字符串，让字符串能够在拼接时不用再分配内存，由于本身字符串长度足够长，所以可以直接在当前字符数组中改写内容。&lt;/p&gt;

&lt;p&gt;除了预分配，我们也可以将已经分配的字符串加入到字符串缓冲池中去，来管理这些预先分配好的字符串，需要时给予，不用时回收，不够时再分配一批，这样就能重复利用已经分配的字符串内存，将分配内存的工作集中起来消耗在某个点上。&lt;/p&gt;

&lt;p&gt;我们常会去比较和查找字符串，查找字符串中的字符串有很多算法，但比较两个字符串是否相同如果仍然使用查找算法去做就是一种浪费，那么我们应该怎样去做两个字符串的比较呢，最好用哈希的方式，把字符串计算出一个哈希值，用这个哈希值来比较是否相等就快很多了。例如我们常常在业务逻辑中判断两个字符串是否相等，每次比较都会浪费掉很多计算量，用哈希的方式就会快很多，因为比较的是两个整数，在每次更新字符串时只需要重新计算一次哈希值就可以，由于通常字符串更新的并不频繁，所以计算哈希的消耗远比每次遍历两个字符串所带来的消耗要小的多。但哈希计算不一定能够获得一个唯一值，所以它只能被用来判断是否不同，即当哈希值不同时，两个字符串一定不同，而两个哈希值相同时有可能不同，此时再比较两者是否真的相同。虽然无法直接比较相同的字符串，但仍然大大减少了不同的两个字符串的比较的计算。&lt;/p&gt;

&lt;h3 id=&quot;算法&quot;&gt;算法&lt;/h3&gt;

&lt;p&gt;算法是性能优化中的精髓，多数平庸的优化方法对性能改善都是线性的，但算法不同，如果说一个高效的算法替换了一个低效的算法性能可能呈现指数级的增长。&lt;/p&gt;

&lt;p&gt;算法时间开销一般有O(1)，O(log2(N))，O(N)，O(Nlog2(N))，O(N^2)，O(N^3)，O(2^N)，从高效到低效的排列，大多数算法如果能到log2(N)已经是非常优秀了，再进一步到O(1)则通常要付出巨大的内存代价。&lt;/p&gt;

&lt;p&gt;作者对二分查找、哈希、散列查找算法特别中意，于是讲了散列算法是怎样的和关键点是什么。我们在用在用查找算法时log2(N)的算法已经是非常不错的查找效率了，所以二分查找是效率比较高的，但它仍然是建立在有序队列的基础上，需要先排序再查找，排序比查找更能耗时，而且后续的元素加入需要插入到有序队列中。而散列算法则不同，排序和查找会更快，前提是数据特性能够散列，或者说散列的冲突不会那么高，于是他告诉我们哈希算法对于散列的重要性。&lt;/p&gt;

&lt;p&gt;这里作者讲的查找和排序内容比较浅，我融入了一些自己的经验。&lt;/p&gt;

&lt;p&gt;算法通常是根据数据特效来定制的，所以对数据独有的特性分析是重点。就我的理解，算法并一定要局限于当前的结构，可以重新创建一个全新的结构方式，这样在用算法去优化程序的时候思路会更开阔。例如我们在全地图寻找某个人的时候并不一定要在查找函数上优化算法，而可以重新制造一个方格结构体把世界分割成不同的方块，找人时只要收集四周方块内的人就可以更快的找到。&lt;/p&gt;

&lt;p&gt;算法也可以是局部的，因为数据多少和数据的特性可以由不同算法处理，所以我们在处理一大堆数据时可以拆分成不同的数据集进行处理，这些数据集的大小和特性也有所不同，针对性的处理会得到更有效的算法效率，例如快速排序算法，可以由不同的算法组成，由于它的中间值决定了快排速度，所以中间值我们可以用三个值取中间数的算法来找到更加稳定的中间值，当数段被分割成多个区间并且单个区间小于等于8个数时，插入排序其实比快排会更加快一些，因此我们在快排中间当数据量小于8时选择用插入排序算法。&lt;/p&gt;

&lt;p&gt;作者列举了一些常用的算法优化思路和套路。&lt;/p&gt;

&lt;p&gt;套路有：预计算、延迟计算、批量处理、缓存、特化、提高处理量、提示、优化执行路径、散列法、双重检查。&lt;/p&gt;

&lt;h3 id=&quot;预计算&quot;&gt;预计算&lt;/h3&gt;

&lt;p&gt;提前计算好一些可以离线完成计算量存储在文件中，这样可以省去了实时计算的开销。&lt;/p&gt;

&lt;h3 id=&quot;延迟计算&quot;&gt;延迟计算&lt;/h3&gt;

&lt;p&gt;先让所有中间过程改变完成后再对最后的结果计算，这样就省去了每次都需要计算全路径的消耗，例如引擎中通常有节点相互的挂载，每次赋值节点position时都会去计算重新计算子节点的位置，这时就要思考如何让计算延后，每次子节点的真实位置只要在帧结束时计算一遍就可以了，不用每次改变position时都去全路径计算一遍所有子节点。&lt;/p&gt;

&lt;h3 id=&quot;批量处理&quot;&gt;批量处理&lt;/h3&gt;

&lt;p&gt;某些具有相同性质的数据不要一个个处理，因为一起同一类型的数据处理起来会有更优的方法，例如堆排序如果一个个插入的元素的话性能开销是O(Nlog2(N))，而一次性构建一个堆的话只需要O(N)。&lt;/p&gt;

&lt;h3 id=&quot;缓存&quot;&gt;缓存&lt;/h3&gt;

&lt;p&gt;不要每次都计算，然后拿着结果去比较，计算完后缓存起来，一直用缓存的值，直到需要更改时再计算一遍。&lt;/p&gt;

&lt;h3 id=&quot;特化&quot;&gt;特化&lt;/h3&gt;

&lt;p&gt;一堆数据处理时它们都会消耗一些计算量，如果某个数据是特别的，不需要计算或者计算量可以很小，则另外开辟一个通道给它，让它少消耗一些。&lt;/p&gt;

&lt;h3 id=&quot;提高处理量&quot;&gt;提高处理量&lt;/h3&gt;

&lt;p&gt;一次处理多个数据而不是一个个处理，例如写日志不要每次都写，每隔一段时间写一次，类似这样的操作，先把准备的数据集中起来，集中起来的数据可能会有更多相似的特性可以用来优化。&lt;/p&gt;

&lt;h3 id=&quot;提示&quot;&gt;提示&lt;/h3&gt;

&lt;p&gt;当处理数据的时候，给予一个提示，这样我们就能知道该如何更好更快的处理，例如在插入一个数据到队列里去时，告诉插入函数，这个数是个比较大的值或者是一个比较小的值，这样我们在做插入时就有了更多优化提示。&lt;/p&gt;

&lt;h3 id=&quot;优化执行路径&quot;&gt;优化执行路径&lt;/h3&gt;

&lt;p&gt;程序语句里有很多个if…else，如果95%的语句都进某个if，那么最好把它提前到语句前，这样就不用执行其他的if里的计算了。&lt;/p&gt;

&lt;h3 id=&quot;散列法&quot;&gt;散列法&lt;/h3&gt;

&lt;p&gt;哈希值比较法，数据结构和字符串在比较时比较费时，用哈希值比较则比较方便，为它们计算一个哈希值，当两个哈希值不同时，它们一定不同，如果哈希值相同则再比较是否真的相同。&lt;/p&gt;

&lt;h3 id=&quot;双重检查&quot;&gt;双重检查&lt;/h3&gt;

&lt;p&gt;数据其实有很多个特征可供我们使用来优化我们的算法，比如长度，如果两个数组长度不一样，那么它们两个的内容肯定是不一样的。类似这样的特征还有数据结构的某个字段或者某几个字段可以决定算法的计算路径，我们只要判断这几个字段就能排除很多计算量。&lt;/p&gt;

&lt;h3 id=&quot;套路只是方法论&quot;&gt;套路只是方法论&lt;/h3&gt;

&lt;p&gt;很多时候技巧谁都知道，实际运用时却能难灵活自如，如果你不常用它们，它们就不回成为你思考的一部分。&lt;/p&gt;

&lt;h3 id=&quot;容器&quot;&gt;容器&lt;/h3&gt;

&lt;p&gt;作者对容器类数据结构性能做了一些介绍，从本质和测试标准两个方面做了讲解。&lt;/p&gt;

&lt;p&gt;不管C++标准库和Boost中的容纳器，还是其他语言的标准容器，它们都是非常通用且性价比不错的容器。但是如果你想让容器的性能发挥到最佳状态，就得自己去改造它。为什么要改造呢？因为首先标准容器内存的分配方式对具体的业务逻辑并不友好，我们可以把跟业务强相关的内存分配方式和内存池的技巧用在容器上以提高内存分配效率，其次容器中数据结构的插入、删除、查找的算法跟业务匹配上并不是最佳的，所以我们要根据我们的实际情况来改造这些算法以提高性能效率。&lt;/p&gt;

&lt;p&gt;容器包括，序列容器和关联容器，序列容器有string，vector，deque，list，forward_list，大都是以数组或链表形式存在的容器，而关联容器则以map和set为代表，用来建立key和value之间联系的容器，包括map、multimap、set、multiset等。&lt;/p&gt;

&lt;p&gt;我们在构造完自己的容器后，需要跟标准容器进行比较，只有这样才能知道我们改造的与业务强相关的容器是否比标准容器更加高效。&lt;/p&gt;

&lt;p&gt;容器性能测试标准就是为了判断容器的在各方面的性能是否更优秀，测试内容需要包含向一个没有内容的容器中以及向一个有数万条记录的容器中插入，删除，查找十万个不同的元素所需要消耗的纳秒数，比较拥有相同功能的容器在执行同一功能的操作时所消耗的时间。我们在测试时用到的数据也会遇到问题，十万个元素也并不能代表数据的典型性，所以很多时候我们需要离线Random随机1000组不同的数据以覆盖所有测试范围。&lt;/p&gt;

&lt;p&gt;由于我们自己不可能对所有容器进行重构，所以第三方容器库也是我们需要关注的地方，包括Boost、EASTL等都是我们需要参考的对象。&lt;/p&gt;

&lt;h2 id=&quot;内存分配&quot;&gt;内存分配&lt;/h2&gt;

&lt;p&gt;提升内存分配效率是提升程序性能非常有效的手段，其实质就是减少内存分配次数，减少内存分配次数就意味着减少内存分配带来的消耗，因此关键的关键还是如何减少内存分配次数，注意，是次数，不是大小，也不是释放。&lt;/p&gt;

&lt;p&gt;讲内存分配之前，我们先来了解下内存分配接口以及内存分配的底层原理。&lt;/p&gt;

&lt;p&gt;C++中内存管理函数有new，delete，malloc，free，其中new，delete运算符可以被类重载为 new()，new&lt;a href=&quot;&quot;&gt;&lt;/a&gt;，delete()，delete&lt;a href=&quot;&quot;&gt;&lt;/a&gt;，他们与class强相关，而malloc()和free()则是经典的C函数库中的内存管理函数，它们分配和释放的是无类型内存块，当无类型内存块被创建出来后，可以被强制指定为是某个变量、数据结构或者类实例。&lt;/p&gt;

&lt;p&gt;从概念上来说，分配内存的函数会从内存中寻找一块可以使用的内存来满足请求，但事实上并没有这么简单。作者没有详细介绍内存分配和释放的底层原理，但我觉得这部分的底层原理是值得挖掘和说明的，作为一个频繁与内存打交道的程序员来说，知道内存是如何分配和释放的是非常有必要的。&lt;/p&gt;

&lt;p&gt;我们的程序被加载到内存后分为几个内存段，包括指令段，数据段，bss段，栈段，堆段，指令段放具体指令，数据段放常量数据，bss段放静态和全局变量，栈段放调用栈、临时寄存器和临时变量，以上几个段都是固定的，不会有扩容一说，只有堆段是可扩容的。new和malloc分配的内存就在这个堆段中。&lt;/p&gt;

&lt;p&gt;堆段会事先分配一段内存，当malloc请求分配的内存时，如果剩余空的内存足够，则分配返回一段足够大小的内存，如果不足则再申请内存。&lt;/p&gt;

&lt;p&gt;堆段在向系统申请内存时类似于提高内存块大小，分配新内存这个操作需要系统将用户态切换到内核态再切回来，因此性能损耗是比较大的。其实malloc分配了内存，也并不代表实际物理内存中申请了某块内存，因为进程所面对的虚拟内存地址空间，只有按页映射到物理内存地址，才能真正使用。而且分配了新的内存，物理内存上实际没有此内存空间，只有当我们memset实际使用它时系统发现了物理内存缺页情况时才真正分配实际物理内存空间。&lt;/p&gt;

&lt;p&gt;从这个角度看，内存分配在操作系统底层上会稍显复杂。那么申请内存在系统底层到底是如何操作的呢？我们来深究一下。&lt;/p&gt;

&lt;p&gt;在Linux中进程由进程控制块(PCB)描述，用一个task_struct 数据结构表示，这个数据结构记录了所有进程信息，包括进程状态、进程调度信息、标示符、进程通信相关信息、进程连接信息、时间和定时器、文件系统信息、虚拟内存信息等. 和malloc密切相关的就是虚拟内存信息，定义为struct mm_struct描述了进程的地址空间。&lt;/p&gt;

&lt;p&gt;mm_struct结构对整个用户空间（进程空间）的描述如下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c&quot;&gt;///include/linux/sched.h 

struct mm_struct {
  struct vm_area_struct * mmap;  /* 指向虚拟区间（VMA）链表 */
  rb_root_t mm_rb;         /*指向red_black树*/
  struct vm_area_struct * mmap_cache;     /* 指向最近找到的虚拟区间*/
  pgd_t * pgd;             /*指向进程的页目录*/
  atomic_t mm_users;                   /* 用户空间中的有多少用户*/                                     
  atomic_t mm_count;               /* 对&quot;struct mm_struct&quot;有多少引用*/                                     
  int map_count;                        /* 虚拟区间的个数*/
  struct rw_semaphore mmap_sem;
  spinlock_t page_table_lock;        /* 保护任务页表和 mm-&amp;gt;rss */       
  struct list_head mmlist;            /*所有活动（active）mm的链表 */
  unsigned long start_code, end_code, start_data, end_data; /* 代码段、数据段 起始地址和结束地址 */
  unsigned long start_brk, brk, start_stack; /* 栈区 的起始地址，堆区 起始地址和结束地址 */
  unsigned long arg_start, arg_end, env_start, env_end; /*命令行参数 和 环境变量的 起始地址和结束地址*/
  unsigned long rss, total_vm, locked_vm;
  unsigned long def_flags;
  unsigned long cpu_vm_mask;
  unsigned long swap_address;

  unsigned dumpable:1;
  /* Architecture-specific MM context */
  mm_context_t context;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中start_brk和brk分别是堆的起始和终止地址，我们使用malloc动态分配的内存就在这之间。系统分配堆空间时，进程通过malloc()库函数在堆上进行空间动态分配，堆空间如果不够用，malloc就进行系统调用增大brk的值。malloc只知道start_brk 和brk之间连续可用的内存空间它可用任意分配，如果不够用了就向系统申请增大brk。&lt;/p&gt;

&lt;p&gt;我们看到实际堆内存在虚拟空间中是可以不断向上扩张的，虽然实际物理内存中不是这样，但至少在虚拟空间中我们可以认为堆内存是一段连续的内存空间地址。&lt;/p&gt;

&lt;p&gt;由于我们分配的内存空间都在虚拟空间当中，我们看到的都是虚拟的地址，实际物理内存分配并不是我们想象的那样连续，也有可能在分配时由于物理内存不足我们拿到的空间是从硬盘空间上的一段数据交换到内存上来的。所以很多时候即使我们分配了连续的空间，在物理内存上也并不是连续的，只能说连续的概率比较大而已。&lt;/p&gt;

&lt;p&gt;其实还有很多分配内存在操作系统层面的原理，这里暂时不深究下去。&lt;/p&gt;

&lt;p&gt;作者指出提高内存分配效率的方法有两种，一种是减少不必要的内存复制的情况，另一种是用固定大小内存分配器解决减少内存分配次数。&lt;/p&gt;

&lt;p&gt;其中内存复制现象常会存在于对象初始化、赋值运算、函数参数、函数返回、插入一个元素到标准容器中，这几种情况是我们需要特别注意的，常常会由于失误编码而导致内存复制的情况，特别是针对一些常用的结构体和非指针类型的实例传递。&lt;/p&gt;

&lt;p&gt;固定大小内存管理器，意思是分配的内存块大小是固定的，这块内存可以是某个类或数据结构相匹配的一个固定大小，也可以是按某固定大小的内存块，这块内存能容纳某个范围内的一个类或数据结构的实例，这个内存管理器专门管理这个类或数据结构的所有内存的，或者专门管理某个固定大小内存块的管理类，这样在分配某一类大小实例时可以专门使用这样的内存管理器(有冗余不可避免)。&lt;/p&gt;

&lt;p&gt;在固定大小内存管理器中，会预加载一段内存以便给足够数量的类和数据结构使用，并且在回收时存储在管理器中以便重复利用，这样既减少了内存分配次数，也减少了内存碎片。&lt;/p&gt;

&lt;p&gt;这样一来，内存块的管理，可以分为，专门为某个类设计的内存管理类，和专门为某个大小范围内设计的内存管理类，我们可以称它们为通用的内存块管理类。&lt;/p&gt;

&lt;p&gt;在实际编程中，我们在写一个固定大小的内存分配管理器时，如果某个类使用数量比较固定和分配释放率比较频繁的话，可以专门为这个类做一个分配器是性价比比较高的。我们通常也会写一个比较通用的内存管理器，用大小不同的内存块来进行区分，例如我们可以为64byte，128byte，256byte，512byte，1k，2k，这几档大小分别预分配几十个内存块存储在通用内存分配管理器中，当程序请求内存时，将请求大小四舍五入后变为2的下一个幂，这样就能获得一个最快适配的内存管理器，当然在使用完毕释放时也同样只是回到这个内存管理器中存储起来以便重复利用，就像内存池和对象池那样。&lt;/p&gt;

&lt;h2 id=&quot;热点代码&quot;&gt;热点代码&lt;/h2&gt;

&lt;p&gt;这周依然没有写完，下周继续最后一部分的总结。&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《malloc和free的实现原理解析》https://jacktang816.github.io/post/mallocandfree/&lt;/p&gt;

</description>
               <pubDate>Sun, 13 Dec 2020 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2020/12/13/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B017</link>
               <guid isPermaLink="true">http://www.luzexi.com/2020/12/13/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B017</guid>
            </item>
        
            <item>
               <title>读书笔记(十六) 《C++性能优化指南》一</title>
               <description>&lt;p&gt;这本书给我的感受是，有技巧有细节也有许多不足，作者介绍了大部分程序上性能优化的方案和思路，也从原理上讲了性能问题的根本原理，但没能做得通俗易懂、深入浅出，书本有几处地方在故弄玄虚以及凑字数，也许是我的功力不足没能理解，这部分无法理解的杂乱无章的内容，可以留到以后再慢慢回顾。&lt;/p&gt;

&lt;p&gt;整本书其实并不是针对C++写的，而是面向程序执行而效率写的，其他语言也一样通用。我结合我的经历和经验写下我的理解，以及我从书中学到的知识，或许过几年回头看会是另一番情景，但现在我需要把它们拎出来总结一下。&lt;/p&gt;

&lt;p&gt;作者是一个有30多年编程经历的人，对编程依然保持的狂热兴趣，注意，他从未去过微软、谷歌等知名公司，这本书就是在这样的一个前提下写下的。&lt;/p&gt;

&lt;p&gt;作者认为我们在优化程序的时候，很多时候都是靠‘猜测’而不是实际的去测试，这是一个比较大的问题。实际上我们并不知道某段程序是否有性能问题，因为有可能编译器已经将它优化了，或者某段程序在我们优化后是否真的有性能提升，因为很多时候我们只是肉眼去代码或是用脑袋去猜，不知道性能问题出在哪里就花费很多时间去优化这是不行的。而且我们也不能因为优化程序性能而破坏了程序的稳定性，如果从中制造出Bug导致产品崩溃那是非常得不偿失的。&lt;/p&gt;

&lt;p&gt;另外他提出了一个比较重要的理念，即大部分性能问题在代码层面上的分布都是‘90/10规则’，也就是说，90%的性能问题出在10%的代码上。因此为了我们在做性能优化时提高效率，应该重点去找出这影响90%性能问题的那10%的代码，它们就是性能问题的重点。不过这10%的代码并不是集中在某处，而是分散在各个模块中，需要我们去找出来，因此按照我的经验和他的理念来理解性能优化的90/10规则，是说我们需要改动的代码远比整体代码要少的多，而我们必须精准的找出这部分少数代码并优化它。&lt;/p&gt;

&lt;p&gt;原书内容比较繁杂，我又重新归类，我把它归类为，计算机执行原理、性能测试、字符串问题、算法、内存分配、热点代码、IO、并发，这八个方面。下面就让我们来讲讲我从书本中学到的对性能优化的理解。&lt;/p&gt;

&lt;h2 id=&quot;计算机执行原理&quot;&gt;计算机执行原理&lt;/h2&gt;

&lt;p&gt;代码从被编译到成为可执行文件也就是机器码，这个过程就是一个从本文字符串翻译成机器码的过程，当我们执行它们的时候，它可机器码被放入了内存，内存中也有分块，包括数据段、栈段、指令段。&lt;/p&gt;

&lt;p&gt;CPU在执行指令时是从内存中将指令送入CPU的，而执行指令的速度通常比读取内存的快很多，因此读取指令也成为了瓶颈的一种。CPU在读取指令时也并不会一行一行的读取，因为这样效率太差，取而代之的是它会把一大块内容读取到高速缓存从而加快执行速度，指令会顺序执行直到结束或有跳转。&lt;/p&gt;

&lt;p&gt;而内存芯片也有自己的工作原理，它相当于另一个CPU，它只有在顺序访问时才能在一个周期内完成，而访问一个非连续的位置则会花费更多周期。&lt;/p&gt;

&lt;p&gt;这里就涉及到了内存在访问时的形式，每次访问内存都是以某个大小为单位，例如x86机器，每次访问内存时都是以4个字节为单位访问，一个int整数为4个字节需要一次访问，但如果这个int整数内存没有对齐，那么可能就需要访问两次才能获得这个值，因为构成这个内存的物理结构可能是垮了两个物理内存字。&lt;/p&gt;

&lt;p&gt;不过请注意，现代编译器都会默认对对象和数据结构做内存对齐操作，除非我们告诉编译器某个数据结构不做内存对齐。对齐时编译器也会优化内存结构让高速缓存命中率提高，关于class的内存布局我们在《深度探索C++对象模型》总结中有详细的讲解。&lt;/p&gt;

&lt;p&gt;作者没有细说关于不对齐时内存访问的来龙去脉，不过我们来举个例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c&quot;&gt;[-][-][x][x][x][x][-][-]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例如上面这个非对齐的内存空间，‘x’表示某个int变量占用的4个字节，‘-’表示其他，当CPU读取这个int整数时，其实是先读取&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c&quot;&gt;[-][-][x][x]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再读取&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[x][x][-][-]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;拼接完成后为&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[x][x][x][x]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后交给寄存器。实际上访问非内存对齐并没有我们想象的那么简单，一个内存实际上有很多个内存芯片共同组成。为了提高访问的带宽，通常会将存储地址分开放在不同的芯片上，例如上面位置0，1，2，3，这4个byte分别存放在芯片1，芯片2，芯片3，芯片4中，当需要它们时，可以一次性全部读取，即如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c&quot;&gt;偏移量/芯片存储空间
   x1 x2 x3 x4
0 [-][x][x][x]
1 [x][-][-][-]
2 [-][-][-][-]
3 [-][-][-][-]
4 [-][-][-][-]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;图中x为要读取的数据，每一列为一个芯片负责的空间，每一行为一个偏移量。这就是说，内存实际上并不是完全以连续byte形式组织的，而是以偏移(offset)量给出具体地址。当我们读取[0][1][2][3]这4个byte数据时可以一次性读取，但如果从1开始读取1，2，3，4时就要多一次偏移(offset)的操作，即先让4个芯片读取偏移量为0时的数据，再让它们读取偏移量为1的数据。&lt;/p&gt;

&lt;p&gt;为了改善内存速度，高速缓存被大量运用，即我们说的L1、L2、L3、L4四级高速缓存，它们每一层的速度大约是下一层的10倍左右。当执行单位需要的内容不在高速缓存中时，需要从内存中加载数据到高速缓存中，并同时将一部分内容舍弃以换取足够的空间，通常会选择放弃的数据都是最近被使用频率比较低的数据。在读取一个不在高速缓存中的数据时通常会将临近的数据也被缓存起来，从访问概率上来说做了加速了数据访问，即概率上来说临近的数据访问概率比较高的特点。&lt;/p&gt;

&lt;p&gt;这意味着频繁被访问的数据和频繁被访问的周围附近的数据都会因为高速缓存而加速。不仅仅是变量数据，机器指令也是数据的一种，超远的if和goto跳转以及远地址function函数调用同样会让高速缓存失效，其原理是执行指令地址从一处跳到另一处导致执行指令不连续。&lt;/p&gt;

&lt;p&gt;内存的访问也会有不够的时候，这时虚拟内存带来了很大的便利，但也给性能带来了很大影响。在虚拟内存机制中，当内存不够时需要借用磁盘空间来扩充，这让内存制造出拥有充足物理空间的假象，将使用频率小的内存数据作为文件存放在磁盘上，当使用时再读区进内存同时更换部分内存到硬盘上，我们常称它们为内存swap操作。由于swap操作很费时，因此检测swap次数也常被纳入性能监控中。&lt;/p&gt;

&lt;p&gt;通常我们一个操作系统中有多个程序需要同时内存访问，而内存总线就只有一个，内存芯片必须一个个去完成CPU分配给它的任务，有时甚至是经常不连续的内存访问，由此看来，内存的读写负担是相当重的。如果未来有更多的处理器内核增加，而内存接口和读取速度没有增加的话，那么其实这些内核对性能的改善效果也是趋于递减的，因为虽然有多个CPU来处理指令，但内存并没有被加速。&lt;/p&gt;

&lt;p&gt;接着我们来看看线程和进程如何影响执行效率，由于操作系统会执行一个线程很短时间然后将上下文切换到其他线程或进程。导致在切换时会浪费掉很多时间，操作系统需要暂停当前的线程并且保存处理器中的寄存器到内存，然后为即将被执行的线程加载之前保存过的寄存器。如果新的线程的数据不在高速缓存中，那么还需要从内存中加载数据到高速缓存，因此上下文切换的代价比我们想象的高。&lt;/p&gt;

&lt;h3 id=&quot;这里做个小结以上讲的都是些计算机执行原理我们需要明白的原理才能真正明白优化背后的逻辑首先内存效率没有我们想象那么快非对齐内存会多一次开销编译器通常都有做内存对齐指令远距离跳转和内存远距离访问都会让高速缓存命中丢失频繁访问的数据和附近的数据会比较快虚拟内存扩充了内存但swap时性能开销很大多个进程和线程争夺内存使用权是性能瓶颈之一太多线程和进程上下文切换代价较大会导致执行效率降低&quot;&gt;这里做个小结，以上讲的都是些计算机执行原理，我们需要明白的原理才能真正明白优化背后的逻辑。首先内存效率没有我们想象那么快，非对齐内存会多一次开销(编译器通常都有做内存对齐)，指令远距离跳转和内存远距离访问都会让高速缓存命中丢失，频繁访问的数据和附近的数据会比较快，虚拟内存扩充了内存但swap时性能开销很大，多个进程和线程争夺内存使用权是性能瓶颈之一，太多线程和进程上下文切换代价较大，会导致执行效率降低。&lt;/h3&gt;

&lt;h2 id=&quot;性能测试&quot;&gt;性能测试&lt;/h2&gt;

&lt;p&gt;性能测试对于性能优化来说是关键的关键，就像作者提到的那样，我们不能靠猜来判断哪些代码需要优化，或者代码执行效率提升了多少不能由某个人说了算。&lt;/p&gt;

&lt;p&gt;那些具有最让人折服的优化技巧的开发人员都会系统地完成如下步骤：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
1.测试出哪些地方是可优化的，做出预测并记录预测。

2.保留优化的代码记录

3.用测试工具进行测量优化前后的数据对比

4.保留实验结果并做详细的笔记。

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上列的四项步骤是性能优化过程中必须不断实践的技能，现实中多数开发人员都想当然的去优化代码，而不是按照上面的方式有条不紊的进行优化，这是优化过程中最糟糕的一点，即不知道自己该从哪里开始优化，优化结束时不知道是否真的优化了优化了多少，有可能更加糟糕，过了段时间甚至记不起来优化了什么。&lt;/p&gt;

&lt;p&gt;除了实际的去测量和记录，我们在性能测试时要注意哪些关键点呢？作者给出了自己的经验。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1.测量程序的启动时间，执行时间，退出时间。

通常人们总是忘了启动和退出时间，这导致部分测量范围不够或者测量不准确。

2.测量的数据和环境必须是可重复的。

只有两个数据和环境是可重复的，才有可能让两次测量在同一个标准中进行。

3.测量必须有一个标准和一致的范围。

如果前后两次测量的环境、测量内容、测试的持续时间不一致，则测量出来的数据是无效的，这种情况下的任何优化数据都是可笑的。

4.测量数据通常都是波动的，没有不波动的测量数据。

因此我们需要通过反复测量多次给出平均值的方式来确定最后的数据。

5.其他进程会影响测量结果。

关闭其他会导致影响的进程，或者提高测量进程为最高级别。

6.测量工具很重要

测量工具包括类似Stopwatch方式的打点，抓取堆栈调用时间，内存分配，内存快照等方式。

7.分析代码和测量运行时间是帮助找出可优化代码的两种有效途径。

只分析代码是行不通的，只测量运行时间也不可行。要分析代码与测量相互迭代，分析后测量，测量后分析，以此方式不断找出可优化的代码。

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;开发人员需要向同事和领导展示他们在性能优化中取得的进展，我们需要精准的测量和详细的记录，如果凭直觉进行优化，也不发表结果，或者发表了结果也会遭到质疑，这是因为他们分不清你到底是在用高度专业的直觉进行优化还是只是在碰运气。&lt;/p&gt;

&lt;h2 id=&quot;字符串问题&quot;&gt;字符串问题&lt;/h2&gt;

&lt;p&gt;这把字符串问题单独拎出来说是因为字符串问题比较大，也比较隐性，常常容易引起性能问题。字符串在概念上很简单，它就是一个字符数组，但是想要实现高效的字符串却非常不容易。&lt;/p&gt;

&lt;h3 id=&quot;这周太忙暂时写到这里下周继续&quot;&gt;这周太忙，暂时写到这里，下周继续…&lt;/h3&gt;

</description>
               <pubDate>Sun, 06 Dec 2020 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2020/12/06/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B016</link>
               <guid isPermaLink="true">http://www.luzexi.com/2020/12/06/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B016</guid>
            </item>
        
            <item>
               <title>给女儿的信(六)</title>
               <description>&lt;p&gt;Hi Sharon and Anne，爸爸好想你们，爸爸喜欢你们。爸爸还在深圳呢，要再过大概1个月才能回来呢。&lt;/p&gt;

&lt;p&gt;爸爸最近在给自己安排任务，以前爸爸常常等公司给我安排任务，这样会有个问题，爸爸总是会忙于公司的事，没有空去做自己想做的事情了。爸爸觉得这样不行，爸爸必须做些自己想做的事情，但又不能将公司的事情落下，于是爸爸就想到自己给自己安排任务，每天晚上都写下爸爸明天要做的事情，把公司的事和自己的事都兼顾起来，每天都做完他们，当然爸爸在指定任务的时候都是指定一天里能做完的，做不完的后面分成一天天的小任务去做。就像老师给你们安排作业一样，这些都是别人要你们做的，有些被动，做被动的事情的时候其实没有灵魂，不如反过来，每天晚上写下明天自己要做的事情，第二天的时候去做自己写下的列表上的事情，这样会更快乐哦。&lt;/p&gt;

&lt;p&gt;加油Sharon，加油Anne！&lt;/p&gt;

</description>
               <pubDate>Wed, 02 Dec 2020 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2020/12/02/%E7%BB%99%E5%A5%B3%E5%84%BF%E7%9A%84%E4%BF%A16</link>
               <guid isPermaLink="true">http://www.luzexi.com/2020/12/02/%E7%BB%99%E5%A5%B3%E5%84%BF%E7%9A%84%E4%BF%A16</guid>
            </item>
        
            <item>
               <title>向内看自己(十) 反思自己的行为带给人的感觉</title>
               <description>&lt;p&gt;最近发现自己的行为和话语给别人的感觉很不好，这源于我自身的性格问题。&lt;/p&gt;

&lt;p&gt;我有很多性格问题，导致生活中、工作中在与人交往过程中就会遇到障碍或瓶颈。&lt;/p&gt;

&lt;p&gt;我很想弄清楚我到底出了什么问题，但一直没弄明白，于是我想好好剖析一下自己。&lt;/p&gt;

&lt;p&gt;也因为最近在学习冥想，这个看起来有点玄乎的词语，是我最近研究的内容，我会专门写一篇文章来详细说明我对它的理解与感受。&lt;/p&gt;

&lt;p&gt;我发现冥想最大的益处就是让我忽略杂念专注于当前所做的事，在专注过程中不断发现当前事物中以前没有被我发现的细节，这些细节很多时候都是关键中的关键。&lt;/p&gt;

&lt;p&gt;当然最重要的也是最大的问题是我自己本身，于是我边练习冥想技巧边来发现自己的问题。&lt;/p&gt;

&lt;p&gt;自身问题一，我常常会去要求别人却没有用心体会对方的感受，慢慢会引起别人的反感。&lt;/p&gt;

&lt;p&gt;自身问题二，我常常会以炫耀的口吻讲述自己的经历和想法，让对方感觉不愉快。&lt;/p&gt;

&lt;p&gt;自身问题三，我常常会想妥协而装做一副顺从的样子，让别人有了更多负担，也让事情进展有些尴尬。&lt;/p&gt;

&lt;p&gt;自身问题四，我常常心急如焚想立刻搞定某事而选择比较激进的做法，让人会觉得我不靠谱，或者不尊重他们。&lt;/p&gt;

&lt;p&gt;自身问题五，与人交流成为我了的负担，我宁愿自己辛苦点去搞定也不愿意或者说恐惧与人打交道。&lt;/p&gt;

&lt;p&gt;即使我知道这些问题的存在，我仍然不知道该如何去改进，因为我没有找到解决问题的方向。&lt;/p&gt;

&lt;p&gt;就像上学时一直喜欢玩耍没有好好学习一样，我知道好好学习的重要性，但就是坐不下来安静学习。&lt;/p&gt;

&lt;p&gt;我觉得是因为我没有get到某个点。这和我现在所面临的问题有点相似，明知道有问题，明知道该如何如何去做，但就是做不到。&lt;/p&gt;

&lt;p&gt;很多时候我们都是撞的很痛了才下定决心去改，但这时通常已经很迟了，我不想每次都等到我痛到骨子里了才去改。&lt;/p&gt;

&lt;p&gt;于是我问自己，我需要get什么点？&lt;/p&gt;

&lt;h4 id=&quot;我回忆了下长大成人后喜欢上了自律和学习的过程我为什么会有转变我是怎么转变过来的&quot;&gt;我回忆了下，长大成人后喜欢上了自律和学习的过程，我为什么会有转变，我是怎么转变过来的。&lt;/h4&gt;

&lt;h4 id=&quot;我依稀记得长大成人后逐渐喜欢上学习的起点是因为我第一次获得学习上的成就感开始的可能这个成就感是非常微不足道的一点点但足以敲开了我对此感兴趣的大门随着我不断深入研究慢慢的我被一次次的成就感所激励着不断前进许多正向的反馈在我的生活中不断冒出中间也有些许负向的反馈但由于相对正向反馈来说量少我还能克服它们&quot;&gt;我依稀记得，长大成人后，逐渐喜欢上学习的起点，是因为我第一次获得学习上的成就感开始的，可能这个成就感是非常微不足道的一点点，但足以敲开了我对此感兴趣的大门。随着我不断深入研究，慢慢的我被一次次的成就感所激励着不断前进，许多正向的反馈在我的生活中不断冒出，中间也有些许负向的反馈，但由于相对正向反馈来说量少我还能克服它们。&lt;/h4&gt;

&lt;h4 id=&quot;这个过程中最重要的是第一次正向反馈当我感觉到自己的努力有了回报我就更感兴趣去深入研究它们如果在开始的时候一次次又一次的正向反馈不断袭来我就能感觉到我自己找对了方法就像找到了金钥匙那样不断向这个方向前进直到遇到更大的瓶颈当遇到更大的瓶颈时我则需要更换思路和方法如果没有找对思路和方法则会继续原地踏步常常会因为原地踏步时间太久而感到沮丧和气馁因此而懈怠并且开始退步&quot;&gt;这个过程中最重要的是第一次正向反馈，当我感觉到自己的努力有了回报，我就更感兴趣去深入研究它们。如果在开始的时候，一次次又一次的正向反馈不断袭来，我就能感觉到我自己找对了方法，就像找到了金钥匙那样，不断向这个方向前进，直到遇到更大的瓶颈。当遇到更大的瓶颈时，我则需要更换思路和方法，如果没有找对思路和方法，则会继续原地踏步，常常会因为原地踏步时间太久而感到沮丧和气馁，因此而懈怠并且开始退步。&lt;/h4&gt;

&lt;h4 id=&quot;想到这里我想着能不能根据这个途径先去找些改善的行动项做起来从而获得正向反馈再根据这个正向反馈来一步步改善我的行为&quot;&gt;想到这里，我想着能不能根据这个途径，先去找些改善的行动项做起来，从而获得正向反馈，再根据这个正向反馈来一步步改善我的行为。&lt;/h4&gt;

&lt;h4 id=&quot;这当然是很难的起步的时候更是艰难特别是第一次的正向反馈可能需要一段比较长时间的积累我需要保持耐心维持改善行为好一阵&quot;&gt;这当然是很难的，起步的时候更是艰难，特别是第一次的正向反馈可能需要一段比较长时间的积累，我需要保持耐心维持改善行为好一阵。&lt;/h4&gt;

&lt;h4 id=&quot;路漫漫其修远兮吾将上下而求索&quot;&gt;路漫漫其修远兮，吾将上下而求索。&lt;/h4&gt;

&lt;h3 id=&quot;希望大家一起加油同我一样来改善自己&quot;&gt;希望大家一起加油同我一样来改善自己​&lt;/h3&gt;

</description>
               <pubDate>Sat, 21 Nov 2020 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2020/11/21/%E5%90%91%E5%86%85%E7%9C%8B%E8%87%AA%E5%B7%B110</link>
               <guid isPermaLink="true">http://www.luzexi.com/2020/11/21/%E5%90%91%E5%86%85%E7%9C%8B%E8%87%AA%E5%B7%B110</guid>
            </item>
        
            <item>
               <title>读书笔记(十四) 《深度探索C++对象模型》</title>
               <description>&lt;p&gt;看此书的起因是自己想更加深刻的了解底层，最底层的莫不过于汇编了，但只有汇编还不够，因为它需要上层工具语言编译器的支持，编译器怎么去编译程序的，决定了汇编的执行方向，理论上说汇编只是执行编译器编译后的程序内容，因此我认为编译器是关键所在。&lt;/p&gt;

&lt;p&gt;我们大多数人自认为自己已经把面向对象语言已经烂熟于心了，其实台面下的机制，如编译器合成的默认构造函数、对象内存布局等都不是很了解。我也是一样，我对编译器一块知识一直不是清晰，所以想通过这本书来了解我们平时编程时的底层的工作原理是什么。&lt;/p&gt;

&lt;p&gt;作者说第一句话就打动了我，让我认真看完了全书，他说“我的经验告诉我，如果一个程序员了解底层实现模型，他就能够写出效率较高的代码，自信心也比较高。一个人不应该用猜的方式，或者等待某位大师的宣判，才确定何时提供一个copy constructor 而何时不需要。这类问题的解答应该来自于我们自身对对象模型的了解。“&lt;/p&gt;

&lt;p&gt;不管我们是在使用C#、Java、C++，它们都是面相对象的编程语言，因此底层的原理都会有些相似性，特别是内存布局上。我也是抱着这种用C++内存布局去理解其他语言的心态去学习和研究这部分内容的。&lt;/p&gt;

&lt;h2 id=&quot;对象的内存布局&quot;&gt;对象的内存布局&lt;/h2&gt;

&lt;p&gt;一个普通的class，有成员变量、成员函数，静态变量，静态函数，关于它们我们可以话一张图，拿一个简单的Point来举例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;	class Point

	成员变量 float x

	成员函数 int PointCount()

	静态变量 static int sMaxCount

	静态函数 static int GetMaxCount()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;假如我们实例化一个Point，即 Point * pt = new Point，Point的内存中为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;	float x
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;没错，内存中只有一个浮点数变量的空间大小，那么其他的包括成员函数、静态变量、静态函数都不在Point实例内存中，它们在哪呢？&lt;/p&gt;

&lt;h4 id=&quot;它们被编译器编写在了代码段和数据段中可以被所有point实例共享的内存使用&quot;&gt;它们被编译器编写在了代码段和数据段中，可以被所有Point实例共享的内存使用。&lt;/h4&gt;

&lt;p&gt;我们知道一个可执行程序的内存分布，分为数据段、代码段、栈段，这三个基本都是静态不会被改变的空间段，其他还有中断表、堆内存空间等。&lt;/p&gt;

&lt;p&gt;class的成员函数、静态函数无论是否public还是private修饰，都会被放入代码段中，静态变量则被放入数据段中无论是否public还是private(放入数据段中的内容，每次取值都会做远距离寻址，相对近距离寻址会费一些，因为隔断了内存连续操作)，而成员变量例如Point中的x，无论它是public还是private都会被放入动态内存分配的内存块中。&lt;/p&gt;

&lt;p&gt;实际上计算机内存中、以及机器码中没有public和private之分，我们可以任意的取得任何内存中的内容没有限制，限制我们程序访问的，只是语言和编译器的语法检查器这两者为我们提供的语言方法和规则检查。&lt;/p&gt;

&lt;h4 id=&quot;当class有继承和多态后则有所不同&quot;&gt;当class有继承和多态后则有所不同&lt;/h4&gt;

&lt;p&gt;当class有了继承后，通常都会有多态出现，即虚函数。让我们来举个例子说明：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;class Point
{
public:
	float x;
	virtual int PointCount();
}

class Point2D : public Point
{
public:
	float y;
	virtual int PointCount();
	virtual void PrintPoint();
}

Point pt = new Point2D();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;加上继承和多态后，内存布局就有所变化，由于基类和子类都有虚函数，子类重载了函数后，我们在内存中就需要有一张表来存放所有虚函数，以便正确调用。&lt;/p&gt;

&lt;p&gt;如上Point和Point2D的关系，可以将一个Point2D实例内存看作如下结构：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;	- virtual table 虚表地址 --------&amp;gt;   Point2D的虚表空间
										- PointCount()地址
										- PrintPoint()地址
	- x
	- y
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;和普通class不同的是，当我们有了多态后，我们的一个实例内存中除了数据外，还多了一个变量指向这个类的虚表空间，这个虚表空间已经被编译器编写在了数据段中，是一个静态的并且专门为Point2D制定的空间，这个空间中存放着指向类中所有虚函数地址，空间不会随着多个实例化而增多因为它只有一个，但每个Point2D实例的虚表指针指向着它（Point实例也是类似的内存布局）。&lt;/p&gt;

&lt;p&gt;（这里不得不讲一下struct和class的区别，其实它在不同语言中的语义和用途不太一样，在C++中可能大部分struct都是用来兼容c或当纯数据的内存结构的，很多class有的功能struct也同样能实现，但在其他语言则不同，比如在C#中的用途就是期望struct能更多的做些内存连续优化，因为它是复制类型数据结构，每次赋值和传递参数都会复制一份内存，除非使用引用关键字。）&lt;/p&gt;

&lt;p&gt;此时如果是Point实例则是&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;	- virtual table 虚表地址 --------&amp;gt;   Point的虚表空间
										- PointCount()地址
	- x
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;与Point2D相比，少了一个y变量，以及虚表空间中少了一个函数地址。&lt;/p&gt;

&lt;p&gt;(编译器编译中很多时候都会将许多我们看来是动态的访问变为静态，例如子类的强制转换(其实内存上没有做任何操作，只是通知编译器后面的操作是基于某个类开始的，使得编译器在编译时偏移地址较前面有所不同)、前面Point中的静态函数（程序在执行时就会直接跳到代码段的GetMaxCount这个函数的地址上而不会通过实例内存去找）、Templete会在编译期就将代码和指令生成完毕，以及一些编译器对代码的优化会直接将某个公式计算好以数字的形式呈现在机器码里，还有很多排错机制，其实编译器帮我们干了很多本该我们需要检查和手动指定的工作。)&lt;/p&gt;

&lt;p&gt;多重继承的内存布局更为复杂些，会带有好几个虚表地址在内存中，效率也更差，因为每一层的虚表都会间接性降低把处理搬到寄存器执行的优化，我们也不鼓励多重继承的写法，因此这里不做详细讲解。&lt;/p&gt;

&lt;h4 id=&quot;实例化后的类大小真的只有变量大小的总和加一个虚标指针吗还有内存对齐的规则&quot;&gt;实例化后的类大小真的只有变量大小的总和，加一个虚标指针吗？还有内存对齐的规则。&lt;/h4&gt;

&lt;p&gt;在32位计算机上，由于寄存器是32位、总线有32条、一次取内容为32位，因此每次取值时都会取得一个4字节的内存内容，编译器也会遵循32位字节对齐的方式去编译。&lt;/p&gt;

&lt;p&gt;例如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;class A
{
	int a; //4字节
	bool b; //1字节
	float c; //4字节
	double d; //8字节
	char e; //1字节
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;	[a 4字节]
	[b 1字节][填充3字节]
	[c 4字节]
	[d 8字节]
	[e 1字节][填充3字节]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;32位计算机中，此对象的内存空间为 4 +（1+3） + 4 + 8 + (1+3) = 24个字节。&lt;/p&gt;

&lt;p&gt;而在64位计算机中，以64位内存对齐的规则时：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;	[a 4字节][b 1字节][填充3字节]
	[c 4字节][填充4字节]
	[d 8字节]
	[e 1字节][填充7字节]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;此对象实例的内存占用空间为 (4+1+3) + (4+4) + 8 + (1+7) = 32字节，在取a、b变量时可以一次取得，节省一次内存调度。&lt;/p&gt;

&lt;h4 id=&quot;对象在内存上对齐的越紧凑能节省的内存调度次数就会越少程序运行的性能也会因此提高&quot;&gt;对象在内存上对齐的越紧凑，能节省的内存调度次数就会越少，程序运行的性能也会因此提高。&lt;/h4&gt;

&lt;h2 id=&quot;inline-内联&quot;&gt;inline 内联&lt;/h2&gt;

&lt;p&gt;除了对齐内存，inline也能让编译器优化函数，让函数执行更快。那么它是怎么优化的呢？&lt;/p&gt;

&lt;p&gt;一般而言，处理一个inline函数有两个阶段：&lt;/p&gt;

&lt;p&gt;1.分析函数，以决定函数是否具备inline能力。&lt;/p&gt;

&lt;p&gt;如果函数因其复杂度，或因其建构问题，被判断不可成为inline，它会被转为一个static函数，并在“被编译模块”内产生对应的函数定义。&lt;/p&gt;

&lt;p&gt;2.真正的inline函数在调用时展开操作，省去函数调用导致的推栈和入栈寄存器的操作，也一并优化了函数中的计算内容(更少的内存存取次数和更快更少的计算次数)。&lt;/p&gt;

&lt;p&gt;这也导致我们通常给予inline后并不清楚编译器是否真正将其视为inline去优化，只有我们进入汇编中才能看到是否真的实现了inline。&lt;/p&gt;

&lt;h3 id=&quot;inline具体会优化哪些方面呢我们来举几个例子&quot;&gt;inline具体会优化哪些方面呢？我们来举几个例子&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;minval = min(val1, val2); //1
minval = min(1024, 2048); //2
minval = min(foo(), bar() +1); //3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果min是一个inline内联函数：&lt;/p&gt;

&lt;p&gt;第一行会被改为 minval = val1 &amp;lt; val2 ? val1 : val2; 省去了函数调用。&lt;/p&gt;

&lt;p&gt;第二行会被改为 minval = 1024; 编译器直接离线计算好结果用常数代替函数调用。&lt;/p&gt;

&lt;p&gt;第三行会被改为&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;int t1 = foo();
int t2 = bar() + 1;
minval = t1 &amp;lt; t2 ? t1 : t2;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;增加了临时性的变量，从而替代内联的函数调用。inline函数中的局部变量加上inline自己增加的局部变量，在展开后可能会导致大量临时性的变量产生。&lt;/p&gt;

&lt;p&gt;inline函数对于封装提供了一种必要的支持，可以有效存取装于class中的nonpublic数据。它同时也是C程序中大量使用#define宏处理的一个安全代替品，但如果inline函数被调用太多次的话，会产生大量的扩展代码，使得程序集本身的大小暴涨。&lt;/p&gt;

&lt;h2 id=&quot;template-模板&quot;&gt;Template 模板&lt;/h2&gt;

&lt;p&gt;C++ 中的Template 模板，在许多语言里也称为泛型。自从1991年加入到cfront 3.0之后深深改变了C++编程习惯。它被使用在编译期做些评估和生成代码的工作，也因而带来了重大的效率提升，同时也成为了程序员一个噩梦以及最挫败的主题。&lt;/p&gt;

&lt;h4 id=&quot;那么当我们声明了一个-template-class或者-template-function时究竟会发生什么呢&quot;&gt;那么当我们声明了一个 template class、或者 template function时究竟会发生什么呢？&lt;/h4&gt;

&lt;p&gt;其实什么都不会发生，如果我们不使用它的话，编译器就会忽略它什么都不干。有也只有当我们使用定义的template做事时，编译器才开始工作，我说的使用是指在我们在代码中使用了前面声明的 template class 或者 template function，而不光是定义。&lt;/p&gt;

&lt;p&gt;如果我们使用了一个指针，指向特定的实例，像这样：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;template&amp;lt;class T&amp;gt;
class Point
{
public:
	void Print();
private:
	T x,y,z;
}

Point&amp;lt;float&amp;gt; * ptr = 0;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编译器依然什么都不回做，因为一个指向class object的指针本身并不是一个class object，编译器不需要知道与该class有关的任何成员数据或对象布局数据，它只是一个指针，至于指向什么并不重要。&lt;/p&gt;

&lt;p&gt;然而如果带template的class被实例化时，则编译器才真正开始为template产生代码，例如我们定义了一个实体而非指针：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;Point&amp;lt;float&amp;gt; origin;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;此时origin会被实例化，编译器也检查到了这种情况，则会启动template代码生成器为Point&lt;float&gt;生成一个类，如下面代码生成格式：&lt;/float&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;class Point_float
{
private:
	float x,y,z;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然而在编译器生成template代码类时，也并不会将所有template定义的类中的代码都生成出来，编译器只会在代码中生成被使用的函数或者可能使用的函数。例如上述中的Point_float就没有生成Print函数，因为我们并没有使用它。&lt;/p&gt;

&lt;h4 id=&quot;这样做的主要原因是为空间和时间上的效率考虑如果我们的template-class中有100个函数使用中的类型有10个我们只使用了其中5个函数那么原本会生成是100--10--1000个函数现在编译器只会生成-5--10--50-个函数其余的950个函数代码讲会被忽略这大大节省了空间提升了编译效率&quot;&gt;这样做的主要原因是，为空间和时间上的效率考虑，如果我们的template class中有100个函数，使用中的类型有10个，我们只使用了其中5个函数，那么原本会生成是100 * 10 = 1000个函数，现在编译器只会生成 5 * 10 = 50 个函数，其余的950个函数代码讲会被忽略。这大大节省了空间提升了编译效率。&lt;/h4&gt;

&lt;h4 id=&quot;那么编译器是如何生成template代码的呢&quot;&gt;那么编译器是如何生成template代码的呢？&lt;/h4&gt;

&lt;p&gt;首先要发现template使用情况，在.h和.cpp文件中寻找template使用情况，如果有使用则继续生成，否则忽略。&lt;/p&gt;

&lt;p&gt;其次编译器尝试模拟链接操作，检查看看哪一个函数真正需要，将真正需要的生成的函数提取出来，位它们生成具体的函数代码。&lt;/p&gt;

&lt;p&gt;最后编译器要阻止template function在多个.o文件中被生成出来，它会从链接器提供的支持中获取信息，只留下一份代码，其余的都将忽略。&lt;/p&gt;

&lt;h2 id=&quot;rtti-执行期类型识别&quot;&gt;RTTI 执行期类型识别&lt;/h2&gt;

&lt;p&gt;执行期类型识别(Runtime Type Identification)最初是由于支持异常处理(Exception Handling)而产生的，可以说它是异常处理的副产品，后来被大量的使用在执行期代码中。&lt;/p&gt;

&lt;p&gt;C++被吹毛求疵的一点就是，它缺乏一个保证安全的向下转换操作，只有在类型真的可以被转换的情况下，你才能够执行转换。想要实现安全的转换，则需要额外的类信息支持，于是就有了类信息(type information)来作为RTTI的保障。&lt;/p&gt;

&lt;p&gt;type_info是C++标准所定义的类型描述器的class名称，该class中放置着待索求的类型信息。虚表空间中的第一个空格就是指向type_info信息的地址。&lt;/p&gt;

&lt;p&gt;在现代C++编译器中，如果我们想要有RTTI功能，则class必须有虚函数或者基类有虚函数，即&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;
class Point
{
	float x;
	virtual int PointCount();
};

class Point2D: public Point {...};

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;- Point2D 和 Point实例中的内存布局情况
- virtual table 虚表地址 --------&amp;gt;   Point2D的虚表空间
									- type_info ptr 类信息地址
									- PointCount()地址
									- PrintPoint()地址
- x
- y
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Point2D和Point的​虚表头，都是type_info的信息地址，它们的type信息地址分别指向两个不同的type_info静态数据内存地址。这样看来，每次我们使用指针取得class object类型描述器时，其实就是通过虚表指针去取得类信息地址，即如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;((type_info)(pt-&amp;gt;vptr[0]))-&amp;gt;name(); //从虚表指针中的第一个槽位中取得类信息
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;type_info object在C++标准下的定义为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;class type_info
{
public:
	virtual ~type_info();
	bool operator==(const type_info&amp;amp;) const;
	bool operator!=(const type_info&amp;amp;) const;
	bool before(const type_info&amp;amp;) consnt;
	const char* name() const;
	const char* raw_name() const;//返回类名称的编码字符串
private:
    void *_m_data;
    char _m_d_name[1];
	type_info(const type_info&amp;amp;);
	type_info&amp;amp; operator=(const type_info&amp;amp;);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;有了类信息，我们在做向下转换时，就可以用根据类信息来判断是否可以转换，即如下代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;Point2D pt2d = dynamic_cast&amp;lt;Point2D&amp;gt;(pt);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;相当于：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c++&quot;&gt;Point2D pt2d = NULL;
type_info type_pt2d = typeid(Point2D);
type_info type_pt = typeid(Point);
if(type_pt2d == type_pt || type_pt.before(&amp;amp;type_pt2d))
{
	pt2d = (Point2D)pt;
}
return pt2d;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;总结class内存分布由成员变量虚表指针组成布局大小会根据计算机的内存对齐方式不同而不同inline内联函数并不一样会真的内联跟编译器根据函数的复杂度判断是否可以内联的如果帧的内联了其优化会节省函数调用开始和计算次数开销template模板会根据template-class使用情况生成代码生成步骤是先判断是否有被使用-生成代码-去除重复想要有rtti执行期类型识别则必须有额外的信息空间支持即在c中我们必须有虚继承或基类有虚继承才能获得rtti的功能甚至我们可以自己写一个执行期类型识别功能来替代标准c有了执行期类型识别功能我们在向下转换时才更加安全即dynamic_cast调用时先判断是否类型一致或者是父类的情况再转换否则为null&quot;&gt;总结，class内存分布由成员变量+虚表指针组成，布局大小会根据计算机的内存对齐方式不同而不同。inline内联函数并不一样会真的内联，跟编译器根据函数的复杂度判断是否可以内联的，如果帧的内联了其优化会节省函数调用开始和计算次数开销。Template模板会根据template class使用情况生成代码，生成步骤是先判断是否有被使用-&amp;gt;生成代码-&amp;gt;去除重复。想要有RTTI执行期类型识别，则必须有额外的信息空间支持，即在C++中我们必须有虚继承或基类有虚继承才能获得RTTI的功能，甚至我们可以自己写一个执行期类型识别功能来替代标准C++，有了执行期类型识别功能，我们在向下转换时才更加安全，即dynamic_cast调用时先判断是否类型一致或者是父类的情况，再转换否则为NULL。&lt;/h4&gt;

</description>
               <pubDate>Fri, 20 Nov 2020 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2020/11/20/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B014</link>
               <guid isPermaLink="true">http://www.luzexi.com/2020/11/20/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B014</guid>
            </item>
        
            <item>
               <title>安卓性能分析工具Simpleperf详解与应用</title>
               <description>&lt;h3 id=&quot;本文关注三个问题simpleperf的工作原始里是什么simpleperf该如何使用它如何在unity项目上使用&quot;&gt;本文关注三个问题：Simpleperf的工作原始里是什么？Simpleperf该如何使用？它如何在Unity项目上使用？&lt;/h3&gt;

&lt;p&gt;关注Simpleperf的缘由是，虽然一直使用Xcode Intruments 、 Unity profiler 、Perfdog、以及一些自制的工具（自定义打点+内存快照）来做性能分析，但一直缺少专门针对安卓设备的的函数耗时分析。偶尔间搜到Simpleperf这么好的分析工具，于是开始研究 Simpleperf，最后把它用到项目中去并且建立起日常性能监控流水线。&lt;/p&gt;

&lt;h4 id=&quot;simpleperf是android开源项目aosp的一部分-是一个-cpu-性能剖析工具可以剖析-android-客户端-java-和-c-代码是-android-ndk-工具的一部分其包含两部分simpleperf可执行文件命令行和python脚本&quot;&gt;Simpleperf是Android开源项目（AOSP）的一部分， 是一个 CPU 性能剖析工具，可以剖析 Android 客户端 Java 和 C++ 代码，是 Android NDK 工具的一部分。其包含两部分：Simpleperf可执行文件（命令行）和python脚本。&lt;/h4&gt;

&lt;p&gt;python脚本整合了Simpleperf可执行文件（命令行）和adb的功能，让Simpleperf使用起来更加方便快捷。&lt;/p&gt;

&lt;p&gt;Simpleperf中可执行文件：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image7.png&quot; alt=&quot;1&quot; /&gt;
&lt;img src=&quot;/assets/simpleperf/image21.png&quot; alt=&quot;2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Simpleperf中整合了命令行的Python脚本：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image23.png&quot; alt=&quot;3&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;simpleper可执行文件支持安卓50及以上的系统但python脚本只支持安卓70及以上的系统&quot;&gt;Simpleper可执行文件支持安卓5.0及以上的系统，但python脚本只支持安卓7.0及以上的系统。&lt;/h4&gt;

&lt;p&gt;这里的Python脚本不仅封装了命令行可执行文件的操作，同时提供了生成测试数据报告，线程消耗图，火焰调用图等功能。由于数据报告生成方面，Simpleperf命令行本身只支持文本数据报告的生成，因此要生成可视化的数据报告，还得依靠python。&lt;/p&gt;

&lt;h4 id=&quot;所以我把数据分析和数据报告生成给拆分开来直接用可执行文件去执行性能分析的任务让simpleperf可以支持更低的安卓系统性能分析完毕后再用python脚本对所得的数据文件来生成可视化的数据报告以及文本数据报告&quot;&gt;所以我把数据分析和数据报告生成给拆分开来，直接用可执行文件去执行性能分析的任务，让Simpleperf可以支持更低的安卓系统。性能分析完毕后，再用python脚本对所得的数据文件来生成可视化的数据报告，以及文本数据报告。&lt;/h4&gt;

&lt;h4 id=&quot;其中数据报告也分成两部分一部分是文本数据报告在生成文本数据报告后对文本数据报告中的数据再加工和筛选筛选出关键的信息上传到性能数据平台作为每日的性能日常报告另一部分是火焰图和消耗图的数据报告用于查看更细致的函数消耗分析&quot;&gt;其中，数据报告也分成两部分，一部分是文本数据报告，在生成文本数据报告后，对文本数据报告中的数据再加工和筛选，筛选出关键的信息上传到性能数据平台作为每日的性能日常报告，另一部分是火焰图和消耗图的数据报告，用于查看更细致的函数消耗分析。&lt;/h4&gt;

&lt;p&gt;我用一个demo做实验，demo的程序就是每帧运行1000w次浮点数和随机数计算，作为实验性能分析数据：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image3.png&quot; alt=&quot;4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以下展示的是性能报告生成后的火焰图和文本数据报告：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image19.png&quot; alt=&quot;5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image12.png&quot; alt=&quot;6&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image9.png&quot; alt=&quot;7&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面就来详细介绍一下，如何使用Simpleperf来做性能分析。&lt;/p&gt;

&lt;h3 id=&quot;功能概要&quot;&gt;功能概要&lt;/h3&gt;

&lt;p&gt;Simpleperf主要功能分为事件摘要（stat），记录样本(record)和生成数据报告(report)三个功能。stat功能给出了在一个时间段内被分析的进程中发生了多少事件的摘要。record功能必须在Android系统中运行，当Simpleperf运行分析时会不断将数据写入到性能数据文件，所以它可以随时停止，随时拷贝分析数据文件。分析完毕后我们可以需要将输出数据文件拷贝到PC上，再使用report功能解析成数据报告。&lt;/p&gt;

&lt;h3 id=&quot;前提条件&quot;&gt;前提条件&lt;/h3&gt;

&lt;p&gt;Simpleperf需要有权限去做性能采样，所以想要使用Simpleperf做性能分析，需要满足4个条件中的一个就够了。&lt;/p&gt;

&lt;p&gt;1.debug版本，即在manifest中设置了android::debuggable=”true”，并且允许JNI 测试，并且C/C++没有被编译器优化过。也就是Unity构建的Development Build版本。&lt;/p&gt;

&lt;p&gt;2.release版本，如果安卓10以上则需要manifest中加入&lt;profileable android:shell=&quot;true&quot;&gt;&lt;/profileable&gt;就可以。&lt;/p&gt;

&lt;p&gt;3.release版本，如果是安卓8以上则在manifest中加入&amp;lt;application android::debuggable=”true” …&amp;gt;后，把wrap.sh 放入 lib/arch 文件夹中。 wrap.sh 会在没有debug标志给ART的情况下跑app。&lt;/p&gt;

&lt;p&gt;4.release版本，你的手机是root过的，有root权限Simpleperf就会畅通无阻。&lt;/p&gt;

&lt;h3 id=&quot;底层原理&quot;&gt;底层原理&lt;/h3&gt;

&lt;p&gt;现代CPU具有一个硬件组件，称为性能监控单元(PMU)。PMU具有一些硬件计数器，计数一些诸如经历了多少次CPU周期，执行了多少条指令，或发生了多少次缓存未命中等事件。&lt;/p&gt;

&lt;p&gt;Linux内核将这些硬件计数器包装到硬件perf事件 (hardware perf events)中。此外，Linux内核还提供了独立于硬件的软件事件和跟踪点事件。Linux内核通过 perf_event_open 系统调用将这些都暴露给了用户空间，这正是simpleperf所使用的机制。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image25.png&quot; alt=&quot;8&quot; /&gt;&lt;/p&gt;

&lt;p&gt;linux系统在各个层都封装了一套性能接口。图中perf字样的接口主要位于CPU层，系统调用层，系统库层，调度层，内存层中。我们通过simpleperf list可以查看受支持的事件类型，有硬件事件类型和软件事件类型之分。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image6.png&quot; alt=&quot;9&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image1.png&quot; alt=&quot;10&quot; /&gt;&lt;/p&gt;

&lt;p&gt;硬件事件借助现代CPU中的PMU（性能监控单元）部件实现采样，比如cpu-cycle，cache-miss等硬件级数据，kernel会开启PMU的计数器去采集对应进程的数据。&lt;/p&gt;

&lt;h5 id=&quot;pmu是cpu中的部件专门用于性能监控cpu在运行时可以收集关于处理器和内存的各种统计信息对于处理器来说这些统计信息中的事件非常有用这样我们可以利用它们来调试或者剖析代码&quot;&gt;PMU是CPU中的部件，专门用于性能监控，CPU在运行时可以收集关于处理器和内存的各种统计信息。对于处理器来说这些统计信息中的事件非常有用，这样我们可以利用它们来调试或者剖析代码。&lt;/h5&gt;

&lt;h5 id=&quot;软件事件则是系统内核kernel层自行实现统计操作系统相关性能事件在各个功能模块中如内存对齐断层事件线程context-switch上下文切换事件cpu时钟事件cpu迁移事件页断层事件等等&quot;&gt;软件事件则是系统内核kernel层自行实现，统计操作系统相关性能事件在各个功能模块中，如内存对齐断层事件、线程context-switch上下文切换事件、cpu时钟事件、cpu迁移事件、页断层事件等等。&lt;/h5&gt;

&lt;p&gt;事实上SimplePerf就是通过linux系统的perf_event_open接口来获得这些perf数据。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image17.png&quot; alt=&quot;11&quot; /&gt;&lt;/p&gt;

&lt;p&gt;linux内核perf_event_open接口 https://www.man7.org/linux/man-pages/man2/perf_event_open.2.html&lt;/p&gt;

&lt;h3 id=&quot;那么stat和record是如何工作的呢&quot;&gt;那么stat和record是如何工作的呢？&lt;/h3&gt;

&lt;h4 id=&quot;stat命令给出时&quot;&gt;Stat命令给出时&lt;/h4&gt;

&lt;p&gt;1.simpleperf调用linux系统接口启用perf分析。&lt;/p&gt;

&lt;p&gt;2.设置监控事件和周期。&lt;/p&gt;

&lt;p&gt;3.Linux 内核在调度到被分析进程时启用计数器。&lt;/p&gt;

&lt;p&gt;4.simpleperf从内核读取计数器，并报告计数器摘要。&lt;/p&gt;

&lt;p&gt;cmd_stat.cpp 471行 StatCommand::Run&lt;/p&gt;

&lt;p&gt;https://android.googlesource.com/platform/system/extras/+/master/simpleperf/cmd_stat.cpp&lt;/p&gt;

&lt;h4 id=&quot;record-命令给出时&quot;&gt;Record 命令给出时&lt;/h4&gt;

&lt;p&gt;1.Simpleperf通过对linux内核接口调用加入监控，锁定监控进程对象。&lt;/p&gt;

&lt;p&gt;2.调用linux系统接口启用perf分析。&lt;/p&gt;

&lt;p&gt;3.Simpleperf在simpleperf 和 linux 内核之间创建共享映射缓冲区。&lt;/p&gt;

&lt;p&gt;4.设置需要监控的事件和采样频率，告诉linux 内核将样本数据转储到映射缓冲区。&lt;/p&gt;

&lt;p&gt;5.开启线程不断监控共享映射缓冲区，从映射缓冲区读取数据并写入到数据文件。&lt;/p&gt;

&lt;p&gt;cmd_record.cpp 455行 RecordCommand::PrepareRecording&lt;/p&gt;

&lt;p&gt;https://android.googlesource.com/platform/system/extras/+/master/simpleperf/cmd_record.cpp&lt;/p&gt;

&lt;h3 id=&quot;这里有2个重要的节点我们深入了解下这两个重点能映射出simpleperf是如何在linux系统工作的&quot;&gt;这里有2个重要的节点我们深入了解下，这两个重点能映射出Simpleperf是如何在Linux系统工作的？&lt;/h3&gt;

&lt;h3 id=&quot;第一个它是如何与linux操作系统通信的&quot;&gt;第一个，它是如何与Linux操作系统通信的？&lt;/h3&gt;

&lt;p&gt;通常进程之间通信都是通过共享内存进行，Simpleperf通过创建映射缓冲区来与系统共享一块内存。那么它是怎么创建和映射的呢？&lt;/p&gt;

&lt;p&gt;我们来看看源码中的关键函数，CreateMappedBuffer创建映射缓冲区，其中mmap为Linux系统接口，调用它使得进程之间通过映射同一块内存(或文件)实现共享内存。
Simpleperf调用mmap创建指定的共享内存大小，设置读写权限，设置共享标记，以及设置通道句柄。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image13.png&quot; alt=&quot;12&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有了共享内存，接着Simpleperf需要告诉与系统把性能数据放入共享缓冲中去。&lt;/p&gt;

&lt;p&gt;其中ioctl为Linux系统接口，是设备驱动程序中对设备的I/O通道进行管理的函数。所谓对I/O通道进行管理，就是对设备的一些特性进行控制，例如串口的 传输波特率、马达的转速等等。&lt;/p&gt;

&lt;p&gt;Simpleperf调用ioctl告诉Linux系统将性能数据写入通道缓存。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image2.png&quot; alt=&quot;13&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ioctl调用格式为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-c&quot;&gt;int ioctl(int fd, ind cmd, …)；
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以通过ioctl的命令码(cmd)告诉Linux驱动程序我们想做什么，至于怎么解释这些命令和怎么实现这些命令，这都是驱动程序要做的事情。
现在我们使用cmd命令码PERF_EVENT_IOC_SET_OUTPUT，告诉系统让内核把性能相关事件数据放入指定缓冲中。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image20.png&quot; alt=&quot;14&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;第二个它是如何得到linux操作系统的性能信息的&quot;&gt;第二个，它是如何得到Linux操作系统的性能信息的？&lt;/h3&gt;

&lt;p&gt;Simpleperf通过创建一个线程来监控数据并记录数据，它就是RecordReadThread。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image11.png&quot; alt=&quot;14&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个线程也会不断的接收用户的命令输入，来暂停和恢复数据记录。&lt;/p&gt;

&lt;p&gt;创建线程后，接着实例化需要监控的事件，并开始记录和监控。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image10.png&quot; alt=&quot;15&quot; /&gt;&lt;/p&gt;

&lt;p&gt;此线程不断循环监控共享内存的状况，同时记录性能数据：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image24.png&quot; alt=&quot;16&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;第一个问题中我们说simpleperf通过linux系统接口mmap申请共享内存再通过linux系统接口ioctl告诉内核把性能监控的数据放在共享内存中由于linux系统在各个层都封装了一套perf性能接口于是在接下来的程序运行中linux内核将这些perf事件-perf-events数据放入simpleperf设置的共享内存中而simpleperf又开启了一个线程来不断监控是否有数据加入并将它们放入自己缓存中去最后再通知主线程适当的时候将这些数据写入本地文件&quot;&gt;第一个问题中我们说，Simpleperf通过Linux系统接口mmap申请共享内存，再通过Linux系统接口ioctl告诉内核把性能监控的数据放在共享内存中。由于Linux系统在各个层都封装了一套perf性能接口，于是在接下来的程序运行中，Linux内核将这些perf事件 (perf events)数据放入Simpleperf设置的共享内存中。而Simpleperf又开启了一个线程来不断监控是否有数据加入，并将它们放入自己缓存中去，最后再通知主线程适当的时候将这些数据写入本地文件。&lt;/h4&gt;

&lt;h2 id=&quot;执行性能分析&quot;&gt;执行性能分析&lt;/h2&gt;

&lt;h3 id=&quot;record-命令行说明&quot;&gt;record 命令行说明&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image16.png&quot; alt=&quot;17&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;性能分析命令执行步骤&quot;&gt;性能分析命令执行步骤&lt;/h3&gt;

&lt;p&gt;现在我们用Simpleperf命令行的形式来对安卓系统进行C/C++的性能分析：&lt;/p&gt;

&lt;p&gt;1.将simpleperf可执行文件放入安卓系统&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;adb push .\ndk21\simpleperf\bin\android\arm64\simpleperf /data/local/tmp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.将可执行文件设置为可执行文件&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;adb shell chmod a+x /data/local/tmp/simpleperf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.开始执行分析，这里设定一个99秒的持续时间。也可以设定为99999秒，然后用杀进程的方式来终止分析。因为我们前面说过，simpleperf是逐步写入数据文件的，数据文件随时保持完整性。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;adb shell /data/local/tmp/simpleperf record -o /data/local/tmp/perf.data -g --app com.xxx.xxx --duration 99 -f 800
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4.停止分析&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;adb shell pkill -l 2 simpleperf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5.将分析数据文件拷贝出来&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;adb pull /data/local/tmp/perf.data .\report_data\report\perf.data
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;生成数据报告步骤&quot;&gt;生成数据报告步骤&lt;/h3&gt;

&lt;p&gt;有了Simpleperf生成的性能数据后，我们就可以对这份性能数据文件进行分析并生成数据报告。&lt;/p&gt;

&lt;h4 id=&quot;生成报告前我们首先需要准备符号表&quot;&gt;生成报告前，我们首先需要准备符号表。&lt;/h4&gt;

&lt;h4 id=&quot;为什么要准备符号表呢因为这样就可以通过分析数据中调用地址映射到具体的函数名这些都由simpleperf帮我们完成只是我们需要为此准备这个带符号表的so&quot;&gt;为什么要准备符号表呢，因为这样就可以通过，分析数据中调用地址映射到具体的函数名。这些都由Simpleperf帮我们完成，只是我们需要为此准备这个带符号表的so。&lt;/h4&gt;

&lt;p&gt;Unity引擎带符号表so的放在Unity的安装目录下&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image8.png&quot; alt=&quot;1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;打完apk包后带符号的il2cpp的so在项目的Temp目录下面：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image5.png&quot; alt=&quot;1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有了这些准备接下我们来开始讲生成数据报告的操作步骤：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image14.png&quot; alt=&quot;1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;1.准备符号表&lt;/p&gt;

&lt;p&gt;把包地址打印出来，因为真正的包地址可能会在你知道的包名后面加些字符串&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;adb shell pm path com.xxxx.xxx &amp;gt; tmp_appinfo.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;把符号表拷贝过去到./binary_cache/data/app/com.xxx.xxxx/lib/arm(或者arm64)/里去&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;python:
cp_src1 = 'libil2cpp.so.debug'
cp_target1 = './binary_cache/data/app/com.xxx.xxxx/lib/arm/libil2cpp.so'
if os.path.exists(cp_src1):
    shutil.copy(cp_src1, cp_target1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里只拷贝了il2cpp的，至少还需要拷贝带符号的libunity.so。符号表是simpleperf用来查找调用函数名的。&lt;/p&gt;

&lt;h4 id=&quot;simpleperf是怎么查到函数名的呢它是通过调用地址与符号表中的函数名对应关系来获得所调用的函数名的我们可以用simpleperf解析后数据打开文本数据获得调用地址来查看到底是怎么回事&quot;&gt;Simpleperf是怎么查到函数名的呢，它是通过调用地址与符号表中的函数名对应关系来获得所调用的函数名的。我们可以用Simpleperf解析后数据，打开文本数据获得调用地址，来查看到底是怎么回事。&lt;/h4&gt;

&lt;p&gt;举个例子，我们查看数据报告中的88.31%的耗时占比函数调用库指令地址为83cb7c：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image18.png&quot; alt=&quot;1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在汇编工具IDA中加载libil2cpp带符号的so文件，查看到83cb7c地址恰好是在Random调用地址上：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image4.png&quot; alt=&quot;1&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;也就是说有8831的消耗在randomrange这个函数上simpleperf就是通过指令调用地址来获取符号表中的函数名的通过调用地址和符号表上的函数名对齐后得到最终的函数名&quot;&gt;也就是说，有88.31%的消耗在Random.Range这个函数上。Simpleperf就是通过指令调用地址来获取符号表中的函数名的，通过调用地址和符号表上的函数名对齐后得到最终的函数名。&lt;/h4&gt;

&lt;p&gt;2.生成普通数据报告&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;python .\ndk21\simpleperf\report.py -i .\perf.data -o .\report.txt -n --full-callgraph --symfs .\binary_cache
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.生成调用者耗时分布数据报告&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-shs&quot;&gt;python .\ndk21\simpleperf\report.py -i .\perf.data -o .\report.caller.txt -g caller --full-callgraph --symfs .\binary_cache
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4.生成被调用者耗时分布数据报告&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;python .\ndk21\simpleperf\report.py -i .\perf.data -o .\report.callee.txt -g callee --full-callgraph --symfs .\binary_cache
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后生成的文本数据如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image9.png&quot; alt=&quot;1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;生成火焰图和消耗图&quot;&gt;生成火焰图和消耗图&lt;/h3&gt;

&lt;p&gt;1.用simpleperf提供的report_html.py生成可视图&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;python .\ndk21\simpleperf\report_html.py -i .\perf.data -o .\report.html --binary_filter .\binary_cache
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.拷贝可视图网页需要用到的js文件&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;copy  &quot;.\ndk21\simpleperf\report_html.js&quot; &quot;.\report_html.js&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image12.png&quot; alt=&quot;1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;日常性能监控流程建设&quot;&gt;日常性能监控流程建设：&lt;/h3&gt;

&lt;p&gt;那么我们是否可以将Simpleperf运用到日常性能监控中去呢？&lt;/p&gt;

&lt;p&gt;经过Simpleperf的性能分析后，我们得到了性能数据文本数据，我们可以对这个文本类型的数据文件再解析，然后将我们需要的重要的函数性能数据加入到后台数据库中，并在每日自动化性能测试报告中体现出来。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image22.png&quot; alt=&quot;1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们来看看上图中，生成出来的性能数据格式。根据性能数据格式，百分比、采样次数、线程名、库文件名、调用函数名的格式，我们可以将数据解析到内存中，并用http的方式上传到web后台。web后台对数据加工后，可以用趋势图的形式在后台页面上展现出来。例如下面的样例图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/simpleperf/image15.png&quot; alt=&quot;1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;参考文献&quot;&gt;参考文献：&lt;/h3&gt;

&lt;p&gt;Simpleperf官方地址：&lt;/p&gt;

&lt;p&gt;https://android.googlesource.com/platform/system/extras/+/master/simpleperf/doc/README.md#executable-commands-reference&lt;/p&gt;

&lt;p&gt;Simpleperf源码地址：&lt;/p&gt;

&lt;p&gt;https://android.googlesource.com/platform/system/extras/+/master/simpleperf/&lt;/p&gt;

&lt;p&gt;《SimplePerf 安卓客户端性能剖析及自动化性能测试》&lt;/p&gt;

&lt;p&gt;http://km.oa.com/articles/show/466087?kmref=search&amp;amp;from_page=1&amp;amp;no=1&lt;/p&gt;

&lt;p&gt;《Simpleperf介绍》&lt;/p&gt;

&lt;p&gt;https://blog.csdn.net/tq08g2z/article/details/77311712&lt;/p&gt;

</description>
               <pubDate>Fri, 13 Nov 2020 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2020/11/13/%E5%AE%89%E5%8D%93%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7Simpleperf%E8%AF%A6%E8%A7%A3</link>
               <guid isPermaLink="true">http://www.luzexi.com/2020/11/13/%E5%AE%89%E5%8D%93%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7Simpleperf%E8%AF%A6%E8%A7%A3</guid>
            </item>
        
            <item>
               <title>向内看自己(九) 慌乱的内心世界</title>
               <description>&lt;p&gt;来深圳快1年了，我以为我会适应的很快，但恰恰相反。我感觉自己像一个惊弓之鸟，被很多事情震惊到了，包括，今年的疫情、远离亲人、陌生的城市、周围很多牛人、项目重要而又紧迫、孩子们慢慢长大了、感觉自己肩负的责任又重了一些。&lt;/p&gt;

&lt;p&gt;好几次我都迫不及待的坐飞机回家看看老婆孩子，多休息几天跟她们多呆几天是几天，感觉自己在逃避。&lt;/p&gt;

&lt;p&gt;这让我想起了幼年时自己被送去武术学校的那段回忆。父母想给我一些锻炼的机会，他们打听到10公里外有个武术学校可以在暑假时间里收一些学生锻炼一下意志力，于是将我送去了那里。那段时间我很害怕，不知道为何，感觉自己被丢到了一个无人关心的地方，虽然后来我慢慢适应了，但两星期后还是忍不住逃了回来。&lt;/p&gt;

&lt;p&gt;这段回忆好像我现在的样子，恐慌不安，犹如惊弓之鸟，童年的阴影困住了我。所以有时我很苦恼，像是被自己所设的陷阱困住了。&lt;/p&gt;

&lt;p&gt;​长大后我才知道每个人都有这样那样大大小小的童年阴影，起先我一直责怪父母给我了一个不好的童年，自从自己当了父母，特别是看了《自卑与超越》之后，才明朗了些，才知道这些童年阴影无法避免，作为父母在这个社会生存，很多时候也是生不由己，没有人是容易的。&lt;/p&gt;

&lt;p&gt;现在轮到自己了，我成为了别人的父母。我已经在社会上独立了，但仍然被这个社会中的小事所很震惊，我想对于这种恐慌我的父母在我这个岁数时也有过同样的经历。&lt;/p&gt;

&lt;p&gt;想到这一层时，我对自己孩子的教育和关心有更加深刻的理解，我不想犯父母的错误，同时很多错误也无法避免。我该如何去补救和行动，我想我应该更努力的去关心她们，感受她们的心灵，并引导她们往好的方向发展。虽然我在很远的地方不能陪伴她们，但我想我也可以做些力所能及的事情作为补救。&lt;/p&gt;

&lt;p&gt;说到自己恐慌，大多数时候是因为压力导致的，压力导致焦虑，焦虑又破坏了我原本的行动准则，没有了行动准则就变得紊乱没有方向。&lt;/p&gt;

&lt;p&gt;其实都是自己的问题，是我忘了初心。&lt;/p&gt;

&lt;p&gt;​于是我深深的问了自己一下，我的初心是什么？第一反应给我的答案是，我的初心是学习，学习是我最大的愿望，我很享受学习的时间，包括学习如何学习，学习具体的知识和技能，以及学习如何运用所学到的。&lt;/p&gt;

&lt;p&gt;我希望自己不忘初心，不断学习，学习知识，学习心态，学习与他人交流，学习如何认识自己等等等等，这是我最终想要的。&lt;/p&gt;

</description>
               <pubDate>Wed, 04 Nov 2020 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2020/11/04/%E5%90%91%E5%86%85%E7%9C%8B%E8%87%AA%E5%B7%B19</link>
               <guid isPermaLink="true">http://www.luzexi.com/2020/11/04/%E5%90%91%E5%86%85%E7%9C%8B%E8%87%AA%E5%B7%B19</guid>
            </item>
        
    </channel>
</rss>