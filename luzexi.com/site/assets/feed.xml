<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title></title>
        <description>技术，哲学，金融</description>
        <link>http://www.luzexi.com</link>
        <atom:link href="http://www.luzexi.com/assets/feed.xml" rel="self" type="application/rss+xml" />
        
            <item>
               <title>读书笔记(五十二) 《如何精彩演讲》#3 如何即兴演讲</title>
               <description>&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;不知不觉看完了6本关于演讲的主题，按推荐顺序排列分别是《高效演讲》、《演讲与口才》、《即兴演讲》、《关键对话》、《TED演讲的力量》、《说话的艺术》。&lt;/p&gt;

&lt;p&gt;我希望自己能够对演讲有一个系统性的学习，于是自己在平常的生活和工作中做了很多实践和训练。&lt;/p&gt;

&lt;p&gt;目标是，改善平常的工作、生活中表达的流畅和清晰度，能让人感觉到舒服，让人感觉有活力。&lt;/p&gt;

&lt;p&gt;同时在公众演讲上，希望自己能够很好的呈现所思所想以及所知所学。&lt;/p&gt;

&lt;p&gt;因此开启这个精彩演讲系列的总结文章，我将对这六本书（其实不止六本）的内容加上我的实践经验做一次全面的系统性的总结。&lt;/p&gt;

&lt;h2 id=&quot;概述&quot;&gt;概述：&lt;/h2&gt;

&lt;h3 id=&quot;1即兴演讲与普通演讲的区别&quot;&gt;1.即兴演讲与普通演讲的区别&lt;/h3&gt;

&lt;h3 id=&quot;2即兴演讲的框架&quot;&gt;2.即兴演讲的框架&lt;/h3&gt;

&lt;h3 id=&quot;3即兴演讲的练习方法&quot;&gt;3.即兴演讲的练习方法&lt;/h3&gt;

&lt;h2 id=&quot;内容&quot;&gt;内容：&lt;/h2&gt;

&lt;p&gt;如果你仔细一些，就会发现我们生活当中会用到很多很多的机械演讲，很多人并不在意进行演讲认为进行演讲，只是脑袋里迸发出了一些火花，或者说自己总结的那些方法。那其实在我们平常的沟通沟通跟表达过程当中进行演讲，在我们沟通表达当中占据的位置非常重要。&lt;/p&gt;

&lt;p&gt;（即兴演讲运用场景）&lt;/p&gt;

&lt;p&gt;特别是作为领导人，作为一个想要做更多有效工作的人。更多的需要激情演讲来，让自己的沟通效率更高，让自己的工作效率更高，让自己的生活效率更高。&lt;/p&gt;

&lt;p&gt;欣欣的我们会发现，在我们生活当中经常会有一些即兴演讲。讲的不好的情况让。让对话让对方让大家感觉到非常不舒服。&lt;/p&gt;

&lt;p&gt;其中一些高调的领导者，会在即兴时刻跟着感觉走，结果让自己。悔恨终生一些管理者在会议上被点名发言却无语无伦次，舌头就像打了结一样，还有一些管理者一开口就滔滔不绝没完没了，最后连自己讲了什么都忘记了。另一些领导者呢，在回答问题时没有主题，东拉西扯，最后拼命解释说我的意思是这种体验非常非常的不好。&lt;/p&gt;

&lt;p&gt;因此进行演讲，需要引起我们足够多的重视，这在我们平常沟通工作生活当中，有非常非常多的场景可以运用，并且它是我们。提高效率。让自己生活工作更美好的一个非常非常好的技巧。&lt;/p&gt;

&lt;h2 id=&quot;即兴演讲与普通演讲的区别&quot;&gt;即兴演讲与普通演讲的区别&lt;/h2&gt;

&lt;p&gt;（普通演讲特点）&lt;/p&gt;

&lt;p&gt;我们可以用几个星期甚至几个月的时间来准备我们的演讲稿，从计划、研究、大纲、讨论、草拟、完善的步骤来为即将到来的演讲准备演讲稿。这是一件非常有趣的事情，也非常值得去准备。&lt;/p&gt;

&lt;p&gt;（即兴演讲特点）&lt;/p&gt;

&lt;p&gt;只是平时的生活和工作当中，我们90%情况都没有任何准备，大部分人都会“临时抱佛脚”或“跟着感觉走”说两句，这让我们错失了很多关键时刻。&lt;/p&gt;

&lt;p&gt;对于普通的有预期的演讲，我们可以提前花时间去准备去练习，而即兴演讲大部分情况都不在我们的预料范围内，难道即兴演讲就只能靠天赋吗？并不是，它也是有方法可寻，并且可以通过练习来加强和巩固的。&lt;/p&gt;

&lt;h3 id=&quot;实际上优秀的即兴演讲它的秘密就在于准备&quot;&gt;实际上，优秀的即兴演讲，它的秘密就在于准备。&lt;/h3&gt;

&lt;h3 id=&quot;也就说你必须为看起来像是很自然的即兴发挥而做充分的准备&quot;&gt;也就说，你必须为“看起来像是很自然的即兴发挥”而做充分的准备。&lt;/h3&gt;

&lt;p&gt;（即兴演讲准备工作）&lt;/p&gt;

&lt;p&gt;我们要为此准备的东西很多，包括选择合适的时间和地点，在什么样的场合说什么样的话，会让对方感觉更自然。与此同时，在讲话前需要快速整理思路，知道自己要说的内容，围绕自己的中心思想讲话。同时自己的讲话的主题和内容要有价值，这是能够让周围的人愿意倾听且被你吸引的关键。最后要意识到我们的“麦克风”始终是开着的，要保持这种麦克风始终开着的状态，不管在办公室内还是办公室外，都要得体的沟通，语言可以激发人也可以威胁人，说符合自己身份的话。&lt;/p&gt;

&lt;p&gt;大量的练习让乔布斯可以在讲话时基本不用草稿。他在展示产品时，虽然也会小心遮住笔记不让观众看见，但他从来不会逐字逐句念出来。如果你什么都不准备就跟着感觉走，很容易让自己陷入尴尬的境地，到时候你只能胡乱说一些你不了解的东西。&lt;/p&gt;

&lt;p&gt;（即兴内容知识分类图）&lt;/p&gt;

&lt;p&gt;对于要说的主题人们总是期望你展示出科学、丰富、经验的知识内容。因此知识内容，通常分为三类：
科学知识，讲话的内容有扎实的知识背景
一般性知识，丰富的观点让你更有说服力
经验性知识，讲述个人经历让讲话更有吸引力&lt;/p&gt;

&lt;p&gt;在我们即兴讲话前，写下这些关键信息和支持性信息，将这些信息记在脑子里，这将构成你即兴演讲草稿的基础。如果所有即兴演讲都事先做好准备、构建扎实的知识基础，牢记关键信息，相信我们会体会到最棒的即兴演讲体验：“最棒的即兴演讲，是当我做足准备，熟知相关材料时，脱口而出的状况。”&lt;/p&gt;

&lt;p&gt;（即兴演讲时的心态）&lt;/p&gt;

&lt;p&gt;演讲的心态非常重要，是与听众连接的通道，也是我们保持真实自我和正念的好方法。&lt;/p&gt;

&lt;p&gt;演讲心态，保持真实、保持专注、保持尊重非常重要，同时也是保持我们保持真实领导力的好方法。&lt;/p&gt;

&lt;p&gt;我们一定要有当领导者的意愿，让自己始终处于领导位置，将每一次讲话和沟通都视为潜在的领导力时刻，为此做出自己的进行领导力即兴讲话。&lt;/p&gt;

&lt;p&gt;真实领导力，让自己专注于当下的对话，真实有勇气的分享你的想法、价值观和信念，分享自己的感受、自己的故事和自己的脆弱。&lt;/p&gt;

&lt;p&gt;成为真正的领导者需要挖掘自己内在，不断与同事、队友和朋友分享你的当下、想法、价值观、信念、感受和故事。&lt;/p&gt;

&lt;h3 id=&quot;通过保持自己的真实性激励鼓舞他人这让我们变得更加温暖同时也能让我们找到更多乐趣&quot;&gt;通过保持自己的真实性，激励鼓舞他人，这让我们变得更加温暖，同时也能让我们找到更多乐趣。&lt;/h3&gt;

&lt;h2 id=&quot;即兴演讲的框架&quot;&gt;即兴演讲的框架&lt;/h2&gt;

&lt;p&gt;很多人会问“为什么要用框架？”，这会让我们感觉是把自己禁锢在一个笼子里，看上去有些死板。当然这也是我一开始接触框架的感受，但练习一段时间后我就改变了我的想法。&lt;/p&gt;

&lt;p&gt;实际上，我们在即兴演讲中，如果没有可依的规则会感觉迷茫。特别是在练习即兴演讲时，没有规则没有方法没有可依的练习方式，很容易迷失在五花八门的“错觉”中。因此框架就起到了重要作用，它为长期技能的练习提供规则，为技能成长提供了依据。&lt;/p&gt;

&lt;h3 id=&quot;用模板去建立自己的即兴演讲框架是一种非常好又非常有效提高自己即兴演讲水平的方法&quot;&gt;用模板去建立自己的即兴演讲框架是一种非常好又非常有效提高自己即兴演讲水平的方法。&lt;/h3&gt;

&lt;p&gt;框架让我们更好的总结完善自己的即兴技巧，通过模板（也有很多人称为模型）和框架，让我们有道可循的思考自己的即兴演讲该如何改进。&lt;/p&gt;

&lt;p&gt;（即兴演讲框架图）&lt;/p&gt;

&lt;p&gt;《即兴演讲》为我们介绍了一种即兴演讲的框架：抓手、要点、结构体、呼吁行动。&lt;/p&gt;

&lt;p&gt;实际上即兴演讲有很多种框架，但都离不开上述这个结构，因此我认为从这个最通用最中心的框架出发来看即兴演讲会更好一些。&lt;/p&gt;

&lt;h3 id=&quot;注意即使有了即兴框架也并不代表我们就万事大吉了这是一个不断打磨和练习的过程通过框架来练习最终会做到将框架融会融入心中做到心中有框架口中无框架&quot;&gt;注意，即使有了即兴框架，也并不代表我们就万事大吉了，这是一个不断打磨和练习的过程。通过框架来练习，最终会做到将框架融会融入心中，做到心中有框架，口中无框架。&lt;/h3&gt;

&lt;p&gt;如果我们可以无论事先还是在讲话现场，都用这个模板去写自己的讲话草稿，通过不断的练习，我们就能让即兴效果更好。&lt;/p&gt;

&lt;p&gt;（即兴模板应用步骤与调整）&lt;/p&gt;

&lt;p&gt;即使完全不允许我们打底草稿，我们也可以借助这个模板去讲话。&lt;/p&gt;

&lt;h3 id=&quot;这里有个关键点即在每讲完每个部分后暂停下来思考下一个部分的内容然后再讲&quot;&gt;这里有个关键点，即在每讲完每个部分后暂停下来，思考下一个部分的内容，然后再讲。&lt;/h3&gt;

&lt;h3 id=&quot;在思考抓手时暂停讲完抓手内容后暂停思考一下讲话的核心要点讲完要点后暂停思考结构体的内容讲完结构体后暂停思考呼吁行动部分最后讲呼吁行动部分&quot;&gt;在思考抓手时暂停；讲完抓手内容后暂停，思考一下讲话的核心要点；讲完要点后暂停，思考结构体的内容；讲完结构体后暂停，思考呼吁行动部分；最后讲呼吁行动部分。&lt;/h3&gt;

&lt;h3 id=&quot;简而言之在讲完每一部分后都要暂停以便思考下一部分内容但你暂停时你会看起来更自信而你讲话的脚本也会更好&quot;&gt;简而言之，在讲完每一部分后都要暂停，以便思考下一部分内容。但你暂停时，你会看起来更自信，而你讲话的脚本也会更好。&lt;/h3&gt;

&lt;h3 id=&quot;注意模板和模型在实际情况中需要我们灵活的去调整例如当你发现讲话的时间已经不允许我们继续完整的讲完所有部分时要即使的调整特别是当你发现对方表现焦虑不安时你就要马上精简模板可能只说要点和呼吁但无论什么情况下都必须包含要点&quot;&gt;注意，模板和模型在实际情况中需要我们灵活的去调整，例如，当你发现讲话的时间已经不允许我们继续完整的讲完所有部分时要即使的调整，特别是当你发现对方表现焦虑不安时，你就要马上精简模板，可能只说要点和呼吁，但无论什么情况下都必须包含要点。&lt;/h3&gt;

&lt;h2 id=&quot;即兴框架要点&quot;&gt;即兴框架：要点&lt;/h2&gt;

&lt;p&gt;（即兴演讲框架-要点的关键点）&lt;/p&gt;

&lt;p&gt;坦率的说，说话没有要点就等于在浪费大家的时间。&lt;/p&gt;

&lt;p&gt;你会发现，当我们没有要点时，语音中会充满很多赘词，“你知道…”，“就是”，“那么”，“然后”，“是吧”等。&lt;/p&gt;

&lt;p&gt;究其原因时语言背后的思路不清。所以，一定要确保你的讲话有核心要点。&lt;/p&gt;

&lt;p&gt;乔布斯越成熟、自信，他就越能与周围实力强大、有想法的管理者自信地对话，而对方在和他争论时也感觉很舒适。&lt;/p&gt;

&lt;p&gt;要点的关键是三个部分：&lt;/p&gt;

&lt;p&gt;1.必须是你的观点&lt;/p&gt;

&lt;p&gt;2.要点要有吸引力&lt;/p&gt;

&lt;p&gt;3.要点必须积极正面&lt;/p&gt;

&lt;p&gt;首先，确保要点是的观点，是承载你信念的一部分，只要这样你才能有信心，并强势、明确的凸显出你的观点，并提炼中心思想，一句话简洁表达你的观点。&lt;/p&gt;

&lt;p&gt;其次，你的观点要有吸引力，这意味着你要了解什么会触动听众的内心，只有这样才能吸引听众的全部注意力，让你的即兴演讲效果发挥到极致。&lt;/p&gt;

&lt;p&gt;最后，要点必须是积极正面的，这是打动整个会场的必备前提。&lt;/p&gt;

&lt;p&gt;注意，你也可以在听众中先建立一种紧迫感，然后再转向更高层次的要点，但一定要确保最后以积极因素结尾。&lt;/p&gt;

&lt;p&gt;通过练习，每次即兴演讲都要有要点，让要点自然的成为你演讲时的第二天性。当你讲话时，胡自然地想讲要点，这在与上级对话，或汇报时尤为重要，它们希望你说话清晰、切中要害，而不浪费他们的时间。&lt;/p&gt;

&lt;h2 id=&quot;即兴框架结构体&quot;&gt;即兴框架：结构体&lt;/h2&gt;

&lt;p&gt;一个合理的结构体，可以让你的讲话举重若轻，它可以让你更清楚地传达要点。&lt;/p&gt;

&lt;p&gt;（结构体组织模式）&lt;/p&gt;

&lt;p&gt;在讲具体内容是，最好用结构体的组织方式去讲话，这样会让讲话更有条理，清晰的表达我们的观点，支撑我们提出的要点。&lt;/p&gt;

&lt;p&gt;结构体组织模式：
1.原因模式，罗列各种原因和理由来支撑我们提出的要点。
2.方法模式，围绕提出的要点，我们可以罗列各种方法来支撑它。
3.情况模式，通过描述当前的状况和对应的实施措施来支撑要点。
4.时间模式，通过时间顺序来描述支撑要点的关键点。&lt;/p&gt;

&lt;p&gt;注意，我们在说完要点后一定要暂停，花一点时间思考后，再选择恰当的结构体模式。&lt;/p&gt;

&lt;p&gt;学习以上四种组织模式，构建讲话核心要点并加上标志词，如果你能做到这些，那么你的即兴演讲将非常有说服力。&lt;/p&gt;

&lt;h2 id=&quot;即兴框架抓手&quot;&gt;即兴框架：抓手&lt;/h2&gt;

&lt;p&gt;我们必须思考如何讲话才能在争夺注意力中胜出，因为“获得整个会场”的注意力是很难的，甚至获得一个人的注意力也很难，如今社会有太多信息干扰我们的注意力，包括智能手机、电子邮件、主流话题、八卦信息等，所以我们更应该仔细思考这个部分。&lt;/p&gt;

&lt;p&gt;也就是说只有抓住大家的注意力，才能让我们的演讲放到最大的效果。&lt;/p&gt;

&lt;p&gt;(图：抓手关键点)&lt;/p&gt;

&lt;h3 id=&quot;把抓手部分看作是一种口头的握手会更好它让你与听众建立联结使听众想要跟随你一旦与听众联结你就可以讲述要点部分而你也将获得听众的注意力并发挥领导力作用&quot;&gt;把抓手部分看作是一种“口头的握手”会更好，它让你与听众建立联结，使听众想要跟随你。一旦与听众联结，你就可以讲述要点部分，而你也将获得听众的注意力并发挥领导力作用。&lt;/h3&gt;

&lt;p&gt;抓手的关键点有三个：
1.抓住听众注意力
2.与听众建立联结
3.避免偏离主题&lt;/p&gt;

&lt;p&gt;可以通过，直呼名称、说关于他们的事情、讲他们曾经的观点、提出与他们的某次对话、询问他们的情况等方式来抓住听众的注意力。&lt;/p&gt;

&lt;h3 id=&quot;总之与听众有关的事情才能将听众的注意力转移到你这里&quot;&gt;总之，与听众有关的事情，才能将听众的注意力转移到你这里。&lt;/h3&gt;

&lt;p&gt;同时，为了能更好的与听众链接，我们需要讲听众感兴趣的事，找到与他们的共同点和共同利益，建立积极、正面、有建设性的对话，来建立与听众的链接。&lt;/p&gt;

&lt;h3 id=&quot;总之通过找对方的兴趣点和彼此共同利益点才能触及听众的内心通过触及内心来建立更好的链接&quot;&gt;总之，通过找对方的兴趣点和彼此共同利益点，才能触及听众的内心，通过触及内心来建立更好的链接。&lt;/h3&gt;

&lt;p&gt;最后对话中避免抵触和反抗，或者让对话时间过长，以及说些无关紧要的话题。&lt;/p&gt;

&lt;h2 id=&quot;即兴框架以呼吁行动结束&quot;&gt;即兴框架：以呼吁行动结束&lt;/h2&gt;

&lt;p&gt;呼吁行动通常要求听众采取行动，一旦后续行动发生，你将实现你的领导力。&lt;/p&gt;

&lt;p&gt;（图：呼吁行动分解）&lt;/p&gt;

&lt;p&gt;即兴演讲的收尾特别重要，我们人能记忆的东西很少，对于一件不是特别重要的事情来说，我们只会记住开头和结尾。&lt;/p&gt;

&lt;p&gt;如果开头和结尾是非常愉悦的，即使中间过程比较枯燥乏味，在人们的心中都是一场还不错的演讲和对话。&lt;/p&gt;

&lt;p&gt;这里罗列下如何收尾的方法：&lt;/p&gt;

&lt;p&gt;1.将话语权交给对方
2.要求做出最终决定
3.介绍具体步骤
4.鼓励他人
5.传达最后通牒&lt;/p&gt;

&lt;p&gt;根据现场实际和即兴的内容来选择收尾会更好一些，特别是在结构体讲完后，应该给自己暂停一下，流一点时间来思考该用什么方式收尾。&lt;/p&gt;

&lt;h2 id=&quot;了解听众&quot;&gt;了解听众&lt;/h2&gt;

&lt;p&gt;当我们了解听众时会让即兴演讲更成功。&lt;/p&gt;

&lt;p&gt;（图：如何了解听众）&lt;/p&gt;

&lt;p&gt;听众分析包括：&lt;/p&gt;

&lt;p&gt;1.事前分析：&lt;/p&gt;

&lt;p&gt;提前了解听众会让你意识到可能存在与你想法完全不同的人，通过事先分析听众可以知道我们会遇到哪些问题，该如何应对。&lt;/p&gt;

&lt;p&gt;听众们关心什么事，把自己的观点建立在他们的想法上，这样才能有一个更稳固的协作式讨论。&lt;/p&gt;

&lt;p&gt;对方背景（组织）文化是如何，文化冲突有哪些，建立在尊重互利的基础上，会让即兴更加舒适。&lt;/p&gt;

&lt;p&gt;2.演讲中调整：&lt;/p&gt;

&lt;p&gt;现在观众的注意力如何&lt;/p&gt;

&lt;p&gt;哪些观点有吸引力可以把听众的注意力拉回来&lt;/p&gt;

&lt;p&gt;哪些听众头脑反应比较迅速是关键决策者，可以去征求他的意见，让他主动发言。&lt;/p&gt;

&lt;h3 id=&quot;最后在讲话结束后要对自己的即兴演讲做一个复盘这是我们提高演讲技能有效快速的方法&quot;&gt;最后，在讲话结束后，要对自己的即兴演讲做一个复盘，这是我们提高演讲技能有效快速的方法。&lt;/h3&gt;

&lt;h2 id=&quot;关于生活中的即兴谈话&quot;&gt;关于生活中的即兴谈话&lt;/h2&gt;

&lt;p&gt;在生活中交谈时尽量找到自己谈话的目标，否则将会成为一场空前浪费时间的闲聊。&lt;/p&gt;

&lt;p&gt;你可以这样想，当人们转身离开时，你想让他们记住关于你的什么信息？&lt;/p&gt;

&lt;p&gt;只要带着这个问题去思考，你将会让每次即兴谈话都畅快淋漓。&lt;/p&gt;

&lt;h3 id=&quot;一位副总裁这样说我发现闲谈非常耗费精力除非是有目的的聊天如果毫无准备就交谈我就会觉得自己迫不及待地想结束谈话但是如果事先准备了谈话就会变得很顺利&quot;&gt;一位副总裁这样说：“我发现闲谈非常耗费精力，除非是有目的的聊天。如果毫无准备就交谈，我就会觉得自己迫不及待地想结束谈话。但是如果事先准备了，谈话就会变得很顺利。”&lt;/h3&gt;

&lt;p&gt;优秀的管理者会问自己，“我想让他们从这次谈话中记住什么？”，或者“人们为什么和我做生意”。&lt;/p&gt;

&lt;p&gt;让我们一起为每一场即兴谈话成为更有效的沟通。&lt;/p&gt;

</description>
               <pubDate>Thu, 06 Jan 2022 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2022/01/06/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B053</link>
               <guid isPermaLink="true">http://www.luzexi.com/2022/01/06/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B053</guid>
            </item>
        
            <item>
               <title>给女儿的信(二十) 观察自己的情绪</title>
               <description>&lt;h2 id=&quot;要点&quot;&gt;要点：&lt;/h2&gt;

&lt;p&gt;用跟自己说说话和闭上眼睛数数的方式，观察自己的情绪，同时化解了自己的情绪&lt;/p&gt;

&lt;h2 id=&quot;结构&quot;&gt;结构：&lt;/h2&gt;

&lt;p&gt;1.遇到困难的时候心里很难受
2.当遇到枯燥乏味的工作时心里很苦闷
3.爸爸想解决这些困难，但就是提不起劲
4.于是爸爸闭上眼睛观察自己
5.爸爸观察自己的情绪是怎样的
6.是难受还是紧张
7.难受是怎么个难受法是脑袋嗡嗡的吗还是整个人紧绷的
8.紧张是怎样的表现是肌肉很痛吗还是腿和胳膊在抖动
9.细致的观察自己的在难受和紧张时的身体状况
10.慢慢发现自己的难受和紧张被化解了
11.当我发现原来紧张和难受时脑袋时这样的感觉肌肉时这样在抖动
12.难受和紧张就慢慢消失了神奇吗
13.原来难受和紧张只是我们想当然的感受，其根本原因是因为肌肉在收缩&lt;/p&gt;

&lt;h2 id=&quot;内容&quot;&gt;内容：&lt;/h2&gt;

&lt;p&gt;Hello 秀恩，Hello Anne。爸爸好想你们爸爸喜欢你们啊，爱你们哟。&lt;/p&gt;

&lt;p&gt;爸爸在深圳又过了2周多的时间了，这里的天气比以往更冷一些。&lt;/p&gt;

&lt;p&gt;爸爸给你们讲一讲爸爸最近的状况好不好？&lt;/p&gt;

&lt;p&gt;最近爸爸遇到一些困难，工作上的和学习上的困难都有。爸爸心里感觉到很难受。&lt;/p&gt;

&lt;p&gt;爸爸发现每次当遇到枯燥的乏味的工作时，心里就很郁闷。除了工作呢，有时候自己想要学习，但是又提不起劲的时候，心里也很难受。&lt;/p&gt;

&lt;p&gt;有时候爸爸觉得自己心里很浮躁，心情很急躁，就是看不进书，写不进东西，心里安静不下来。所以爸爸想着该怎么办呢？怎么解决这个心里难受情绪混乱的状态呢？&lt;/p&gt;

&lt;p&gt;爸爸想了两个办法，第1个办法是跟自己说说话，爸爸每天抽15分钟到20分钟的时间来跟自己说说话，每天跟自己说说今天我遇到了什么困难，我的感受怎样。然后跟自己说说，我应该怎么去解决这个困难，跟自己说说我应该怎样去调整自己的情绪。&lt;/p&gt;

&lt;p&gt;你知道吗？爸爸跟自己说着说着，自己的情绪就真的慢慢好起来了，不那么难受，也不那么急躁了，也不紧张了。所以爸爸觉得跟自己说说话，这个办法非常棒。&lt;/p&gt;

&lt;p&gt;跟自己说说话，不但练习了口头的表达能力和沟通能力，并且还化解了自己的情绪，爸爸觉得这个方法非常非常棒。所以呢，爸爸每天都在坚持跟自己说说话，像跟秀恩聊天一样跟自己说说话。&lt;/p&gt;

&lt;p&gt;第2个办法是。当爸爸感觉到紧张、难受、急躁的时候，就坐下来闭上眼睛去数数，数数的时候，我会观察自己。&lt;/p&gt;

&lt;p&gt;观察自己的哪里难受，哪里紧张，是哪块肌肉很难受，是紧张还是疼痛？细致的观察自己。&lt;/p&gt;

&lt;p&gt;爸爸就这样去观察自己的身体，在这种紧张和难受的状态下，肌肉是怎么收缩和抖动的？&lt;/p&gt;

&lt;p&gt;慢慢地观察着观察着，爸爸发现自己的情绪开始化解了，爸爸发现自己没有这么难受和紧张了，原来只要爸爸闭上眼睛专注地观察他们，观察肌肉的疼痛和收缩，观察脑袋的紧绷，观察整个人的状态的时候，难受和紧张就慢慢的消失了。这种感觉太棒了。就感觉自己重新平静了下来，无论是生气还是难受，情绪都被化解了。&lt;/p&gt;

&lt;p&gt;爸发现用这两种调节情绪的办法非常棒。&lt;/p&gt;

&lt;p&gt;爸爸现在常用这种方式去化解自己的情绪，那些痛苦啊、难受啊、紧张啊、焦虑啊、急躁啊，都可以通过这样的方式去把它化解。&lt;/p&gt;

&lt;p&gt;太棒了，爸爸每天都要坚持跟自己说说，观察自己的状态和身体的变化，化解掉自己的情绪。&lt;/p&gt;

&lt;p&gt;今天的写信就到这里喽，宝宝们喜欢你们，爸爸爱你们哟。&lt;/p&gt;

</description>
               <pubDate>Mon, 03 Jan 2022 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2022/01/03/%E7%BB%99%E5%A5%B3%E5%84%BF%E7%9A%84%E4%BF%A120</link>
               <guid isPermaLink="true">http://www.luzexi.com/2022/01/03/%E7%BB%99%E5%A5%B3%E5%84%BF%E7%9A%84%E4%BF%A120</guid>
            </item>
        
            <item>
               <title>新书发售《Unity3D高级编程-主程手记》</title>
               <description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU1ODY1ODY2NA==&amp;amp;mid=2247485108&amp;amp;idx=1&amp;amp;sn=b949ce0d6f031a2108586940aa0eadfa&amp;amp;chksm=fc2263b3cb55eaa5b5c3fe41399d47d7f1e0f66ce5b130c0e31648be035e9535f5c6c3d5ed39&amp;amp;token=330432434&amp;amp;lang=zh_CN#rd&quot;&gt;已发布微信公众号&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/book/fengmian.jpg&quot; alt=&quot;封面&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;新书发售了感恩朋友们的厚爱&quot;&gt;新书发售了，感恩朋友们的厚爱。&lt;/h3&gt;

&lt;p&gt;这么多年读书与写作给我最大的体会是，&lt;/p&gt;

&lt;p&gt;静下心来保持专注，是最有效率的。&lt;/p&gt;

&lt;p&gt;希望自己继续保持这份专注，并用最真诚的方式对待朋友们。&lt;/p&gt;

&lt;h3 id=&quot;本书共10章每章都是一个独立的知识领域读者可以按照章节顺序阅读本书也可以根据喜好挑选自己感兴趣的章节学习&quot;&gt;本书共10章，每章都是一个独立的知识领域，读者可以按照章节顺序阅读本书，也可以根据喜好挑选自己感兴趣的章节学习。&lt;/h3&gt;

&lt;p&gt;第1章讲了架构的意义、架构的原理以及如何实现架构。&lt;/p&gt;

&lt;p&gt;第2章对C#技术的基础知识做了讲解。&lt;/p&gt;

&lt;p&gt;第3章针对客户端中的表格数据、程序的协作与应用进行讲解。&lt;/p&gt;

&lt;p&gt;第4章讲解了用户界面（UI）的工作原理与优化方法。&lt;/p&gt;

&lt;p&gt;第5章针对3D模型的原理、动画的原理以及两者的优化做了详细的讲解。&lt;/p&gt;

&lt;p&gt;第6章讲解的是网络层的业务架构与底层原理。&lt;/p&gt;

&lt;p&gt;第7章针对各类AI做了详细的讲解。&lt;/p&gt;

&lt;p&gt;第8章主要讲解场景构建与优化、地图构建以及寻路算法优化的相关知识。&lt;/p&gt;

&lt;p&gt;第9章讲解了图形数学、图形学常用算法、渲染管线的相关知识。&lt;/p&gt;

&lt;p&gt;第10章针对客户端各类渲染技术的渲染原理做了详细的解剖。&lt;/p&gt;

&lt;h3 id=&quot;此书非常适合那些上进积极热爱技术的伙伴们&quot;&gt;此书非常适合那些上进、积极、热爱技术的伙伴们。&lt;/h3&gt;

&lt;p&gt;如果你想更上一层楼，想了解主程需要做什么，主程需要哪方面的技术深度，就来看看这本书。&lt;/p&gt;

&lt;p&gt;整本书字里行间都透露着对游戏开发的深度理解，以及对主程工作的感悟。&lt;/p&gt;

&lt;h3 id=&quot;20211228预售开始了后面的日子里会陆续上架各大平台包括新华书店机械工业出版社平台以及当当网&quot;&gt;2021.12.28，预售开始了，后面的日子里会陆续上架各大平台，包括新华书店、机械工业出版社平台、以及当当网。&lt;/h3&gt;

&lt;h2 id=&quot;感恩遇见&quot;&gt;感恩遇见&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/book/shudian1.jpg&quot; alt=&quot;淘宝预售&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/book/shudian3.jpg&quot; alt=&quot;京东预售&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/book/shudian2.jpg&quot; alt=&quot;淘宝搜索&quot; /&gt;&lt;/p&gt;

</description>
               <pubDate>Wed, 29 Dec 2021 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2021/12/29/%E6%96%B0%E4%B9%A6%E5%8F%91%E5%94%AE</link>
               <guid isPermaLink="true">http://www.luzexi.com/2021/12/29/%E6%96%B0%E4%B9%A6%E5%8F%91%E5%94%AE</guid>
            </item>
        
            <item>
               <title>读书笔记(五十一) 《游戏引擎架构》#4 低阶渲染器（4）</title>
               <description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU1ODY1ODY2NA==&amp;amp;mid=2247485096&amp;amp;idx=1&amp;amp;sn=c027b6af4677515ba1e5950aac8ba68d&amp;amp;chksm=fc2263afcb55eab9204898b39fb77ee04f5767ac450507b6192a5c6d5612a45b6d29b1bcee16&amp;amp;token=853743270&amp;amp;lang=zh_CN#rd&quot;&gt;已发布在微信公众号上，点击跳转&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;背景&quot;&gt;背景：&lt;/h1&gt;

&lt;p&gt;作为游戏开发从业者，从业务到语言到框架到引擎，积累了一些知识和经验，特别是在看了几遍《游戏引擎架构》后对引擎架构的理解又深入了些。&lt;/p&gt;

&lt;p&gt;近段时间有对引擎剖析的想法，正好借这书本对游戏引擎架构做一个完整分析。&lt;/p&gt;

&lt;p&gt;此书用简明、清楚的方式覆盖了游戏引擎架构的庞大领域，巧妙地平衡了广度与深度，并且提供了足够的细节。&lt;/p&gt;

&lt;p&gt;借助《游戏引擎架构》这本书、结合引擎源码和自己的经验，深入分析游戏引擎的历史、架构、模块，最后通过实践简单引擎开发来完成对引擎知识的掌握。&lt;/p&gt;

&lt;p&gt;游戏引擎知识面深而广，所以对这系列的文章书编写范围做个保护，即不对细节进行过多的阐述，重点剖析的是架构、流程以及模块的运作原理。&lt;/p&gt;

&lt;p&gt;同时《游戏引擎架构》中部分知识太过陈旧的部分，会重新深挖后总结出自己的观点。&lt;/p&gt;

&lt;h1 id=&quot;概述&quot;&gt;概述：&lt;/h1&gt;

&lt;p&gt;本系列文章对引擎中的重要的模块和库进行详细的分析，我挑选了十五个库和模块来分析：&lt;/p&gt;

&lt;p&gt;1.时间库
2.自定义容器库
3.字符串散列库
4.内存管理框架
5.RTTI与反射模块
6.图形计算库
7.资产管理模块
8.低阶渲染器
9.剔除与合批模块
10.动画模块
11.物理模块
12.UI底层框架
13.性能剖析器的核心部分
14.脚本系统
15.视觉效果模块&lt;/p&gt;

&lt;p&gt;本篇内容为列表中的第8个部分的第1节。&lt;/p&gt;

&lt;h1 id=&quot;正文&quot;&gt;正文：&lt;/h1&gt;

&lt;p&gt;简单回顾下前文&lt;/p&gt;

&lt;p&gt;前文我们聊了下显卡在计算机硬件主板中的位置与结构，知道了CPU、GPU的通信介质，并简单介绍了手机上的主板结构。本篇开头对上一篇做一些内容补充，PC和手机的不同硬件组织，以及CPU与其他芯片的通信过程。&lt;/p&gt;

&lt;p&gt;下面我们开始这篇内容&lt;/p&gt;

&lt;p&gt;本次内容会围绕GPU来写，从硬件架构到软件驱动再到引擎架构，目标是帮大家理解GPU硬件的运作原理，理解图形接口的架构，理解引擎低阶渲染器的架构。&lt;/p&gt;

&lt;p&gt;目录：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;主板结构中的显卡&lt;/li&gt;
  &lt;li&gt;GPU功能发展史&lt;/li&gt;
  &lt;li&gt;GPU与CPU的差异&lt;/li&gt;
  &lt;li&gt;GPU硬件特点&lt;/li&gt;
  &lt;li&gt;图形驱动程序架构&lt;/li&gt;
  &lt;li&gt;引擎低阶渲染架构&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;内容结构：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CPU硬件结构&lt;/li&gt;
  &lt;li&gt;GPU硬件结构&lt;/li&gt;
  &lt;li&gt;GPU手机管线与PC管线的差异&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;接着上篇的内容。前面说了CPU、GPU的硬件结构，CPU的构造和GPU的构造，下面我们来聊聊GPU是如何工作的，以及GPU的管线在手机端和PC端的差异。&lt;/p&gt;

&lt;h2 id=&quot;nvidia基于fermi管线的架构&quot;&gt;NVIDIA基于Fermi管线的架构&lt;/h2&gt;

&lt;p&gt;关于GPU的逻辑管线，这篇Nvidia这篇文章《Life of a triangle - NVIDIA’s logical pipeline》说的很清楚。&lt;/p&gt;

&lt;p&gt;（NVIDIA的整体架构图）&lt;/p&gt;

&lt;p&gt;下面我以此为标准进行翻译并重新剖析。&lt;/p&gt;

&lt;p&gt;为了简单起见，省略了几个细节，假设 drawcall 引用了一些已经充满数据并存在于 GPU DRAM 中的索引和顶点缓冲区，并且仅使用顶点和像素着色器（GL：片段着色器）。&lt;/p&gt;

&lt;p&gt;（从图形API调用到图元处理过程图）&lt;/p&gt;

&lt;p&gt;1.引擎或业务程序调用图形 API（DX 或 GL）中的绘图函数，接着驱动程序会被调用，驱动程序会进行一些验证以检查参数是否“合法”，再将指令写入到GPU可读写的缓冲队列中。在这个地方 CPU 方面可能会出现很多瓶颈，这也是为什么程序员要好好使用 API 以利用当今 GPU 的强大功能的技术很重要的原因。&lt;/p&gt;

&lt;p&gt;（绘制接口调用图）&lt;/p&gt;

&lt;p&gt;2.经过一段时间渲染，画面“刷新”被调用，驱动程序在缓冲区中已经缓冲了足够多的工作命令，接着将其发送给 GPU 进行处理（操作系统会参与）。最后 GPU 的主机接口接收命令并交给GPU前端的处理。&lt;/p&gt;

&lt;p&gt;（绘制队列与刷新图）&lt;/p&gt;

&lt;p&gt;3.接着图元分配器（Primitive Distributor）开始分配工作。为了批量处理索引和三角形，将数据发送给多个图形处理集群（GPC）并行处理。&lt;/p&gt;

&lt;p&gt;（SM整体结构图）&lt;/p&gt;

&lt;p&gt;4.在 GPC 中，每个 SM 的 Poly Morph 引擎负责从三角形索引中获取顶点数据(Vertex Fetch)。&lt;/p&gt;

&lt;p&gt;5.在获取数据后，SM中每32个线程为一捆线程束（Warp），它们被调度去处理这些顶点工作。 线程束（Warp）是典型的单指令多线程（SIMT，SIMD单指令多数据的升级）的实现，也就是32个线程同时执行的指令是一模一样的，只是线程数据不一样，这样的好处就是一个Warp只需要一套逻辑对指令进行解码和执行就可以了，芯片可以做的更小更快。&lt;/p&gt;

&lt;p&gt;（线程束与线程束调度器图）&lt;/p&gt;

&lt;p&gt;6.SM的线程束（Warp）调度器会按照顺序分发指令给整个线程束（Warp），单个线程束（Warp）中的线程会锁步(lock-step)执行各自的指令。线程束（Warp）会使用SIMT的方式来做分支预测，每个线程执行的分支会不同，当线程遇到到错误判断的执行情况会被遮蔽(be masked out)。&lt;/p&gt;

&lt;p&gt;（单个GPU线程与存储设备的关系图）&lt;/p&gt;

&lt;p&gt;被遮蔽的原因是SIMT执行中错误预测，例如当前的指令是if(true)的分支，但是当前线程的数据的条件是false，或者循环的次数不一样（比如for循环次数n不是常量，或被break提前终止了但是别的还在走），因此在Shader中的分支会显著增加时间消耗，在一个线程束（Warp）中的分支除非32个线程都走到同一个里面，否则相当于所有的分支都走了一遍，线程不能独立执行指令而是以线程束（Warp）为单位，而这些线程束中的线程之间才是相互独立的。&lt;/p&gt;

&lt;p&gt;（SIMT线程束做分支预测图）&lt;/p&gt;

&lt;p&gt;7、线程束（Warp）中的指令可以被一次完成，也可能经过多次调度，例如通常SM中的LD/ST(加载存取)单元数量明显少于基础数学操作单元。&lt;/p&gt;

&lt;p&gt;8、由于某些指令比其他指令需要更长的时间才能完成，特别是内存加载，线程束（Warp）调度器可能会简单地切换到另一个没有内存等待的线程束（Warp），这是GPU如何克服内存读取延迟的关键，其操作为简单地切换活动线程组。为了使这种切换更快，调度器管理的所有线程束（Warp）在寄存器列阵（Register File）中都有自己的寄存器。这里就会有个矛盾产生，Shader需要的寄存器越多，给线程束（Warp）留下的空间就越少，于是就会导致能用的线程束（Warp）就越少。此时如果碰到指令在内存获取数据等待就只会等待，而没有其他可以运行的线程束（Warp）可以切换。&lt;/p&gt;

&lt;p&gt;（线程与寄存器列阵关系图）&lt;/p&gt;

&lt;p&gt;（线程束调度器调度线程图）&lt;/p&gt;

&lt;p&gt;9、一旦线程束（Warp）完成了顶点着色器（vertex-shader）的所有指令，运算结果会被Viewport Transform模块处理，三角形会被裁剪然后准备光栅化，此时GPU会使用L1和L2缓存来进行顶点着色起（vertex-shader）和片元着色起（pixel-shader）的数据通信。&lt;/p&gt;

&lt;p&gt;（管线中节点、数据、存储器的关系图）&lt;/p&gt;

&lt;p&gt;10、接下来这些三角形将被分割，通过 Work Distribution Crossbar 将三角形再分配给多个GPC，三角形的范围决定着它将被分配到哪个光栅引擎(raster engines)，每个光栅引擎（raster engines）覆盖了多个屏幕上的图块（tile），这等于把三角形的渲染分配到多个图块（tile）上面。也就是说在像素阶段前就把三角形划分成了方块格式范围，三角形处理分成许多较小的工作。&lt;/p&gt;

&lt;p&gt;（三角形被拆分成多个块派发到多个光栅引擎图）&lt;/p&gt;

&lt;p&gt;（图块拆分任务派发图）&lt;/p&gt;

&lt;p&gt;11、SM上的属性安装器（Attribute Setup）保证了从顶点着色器（vertex-shader）生成的数据，经过插值后，在片元着色器（pixel-shade）上是可读的。&lt;/p&gt;

&lt;p&gt;12、GPC上的光栅引擎(raster engines)处理它接收到的三角形，并为它负责的那些部分生成像素信息（同时会处理裁剪Clipping、背面剔除和Early-Z剔除）。&lt;/p&gt;

&lt;p&gt;13、再次做批量处理，32个像素线程被分成一组（或者说8个2x2的像素块），这是在像素着色器上面的最小工作单元（2x2 四边形允许我们计算诸如纹理 mip 贴图过滤之类的导数–四边形内纹理坐标的大变化会导致更高的 mip）。在这个像素线程内，如果没有被任何三角形覆盖就会被剔除。SM中的线程束（Warp）调度器会管理像素着色器的任务。&lt;/p&gt;

&lt;p&gt;（2x2像素组传入到线程束处理像素着色器的图）&lt;/p&gt;

&lt;p&gt;14、接下来是同样的线程束调度策略，和顶点着色器（vertex-shader）中的逻辑步骤完全一样，但是变成了在像素着色器线程中执行。 由于不耗费任何性能从2x2四边形中获取一个像素，这使得锁步执行非常便利，于是所有的线程可以保证指令可以在同一点同步执行。&lt;/p&gt;

&lt;p&gt;（线程束锁步执行图）&lt;/p&gt;

&lt;p&gt;15、最后一步，现在像素着色器已经完成了颜色的计算和深度值的计算。在这个点上，我们必须考虑三角形的调用API顺序，然后才将数据移交给ROP(render output unit，渲染输出单元)，一个ROP内部有很多ROP单元，在ROP单元中处理深度测试和帧缓冲（framebuffer）的混合等，深度和颜色的设置必须是原子操作，否则两个不同的三角形在同一个像素点就会有冲突和错误。NVIDIA 通常应用内存压缩，以减少内存带宽要求，从而增加“有效”带宽。&lt;/p&gt;

&lt;p&gt;（像素着色器后的像素处理过程图）&lt;/p&gt;

&lt;p&gt;以上这些信息有助于我们理解 GPU 中的一些工作和数据流，还可以帮助我们理解CPU与GPU之间的交互。&lt;/p&gt;

&lt;h2 id=&quot;总结cpu和gpu的交互&quot;&gt;总结CPU和GPU的交互&lt;/h2&gt;

&lt;p&gt;GPU是设备，设备都有驱动，CPU可以直接执行二进制指令集，对于GPU设备，图形接口有opengl，directx标准及库封装，计算有cuda和opencl封装。程序代码调用这些图形或计算库，这些库调用驱动，驱动再来对接操作GPU设备，CPU与GPU直接的通信是遵循总线和内存的规则。&lt;/p&gt;

&lt;p&gt;原则上CPU、内存外的设备都属于IO设备，通过总线连上来，它们必须遵守IO总线规范，如显卡就走pcie总线，这里还有ionmu，统一内存等，来共享资源，缩短路径，提升效率等。&lt;/p&gt;

&lt;p&gt;这里专门说下驱动，计算机有专门的程序接口指定一个计算任务到GPU上，这个接口程序就是驱动程序。CPU给GPU下发任务时通过调用驱动程序，不同GPU厂商实现自己的驱动，并且提供了各种的编程接口。图形计算上实现了OpenGL标准接口规范的图形库，它会调用各厂商的驱动，用户可以通过GLSL编写计算任务进行通用计算。后来的CUDA编程模型专门推出用于编写通用计算任务的接口，于是OpenGL就专门用于图形渲染了。而CUDA则是通过kenel函数来编写计算任务，通过cudaLaunch接口来下发任务。&lt;/p&gt;

&lt;p&gt;（从图形库到驱动到GPU指令队列的图）&lt;/p&gt;

&lt;p&gt;从硬件角度看：&lt;/p&gt;

&lt;p&gt;（从硬件角度看指令和数据处理流程图）&lt;/p&gt;

&lt;p&gt;1.GPU设备的配置空间物理地址映射到虚拟地址，可以被程序直接访问；同时建立任务队列缓冲，声明中断等等；&lt;/p&gt;

&lt;p&gt;2.CPU在进程内准备数据和缓冲，基于虚拟地址VA、VM将其转换为显存的物理地址IPA。驱动程序获取任务，再将任务信息填充至任务队列内。&lt;/p&gt;

&lt;p&gt;3.根据虚拟内存绑定的地址信息，将任务队列的指针更新至GPU设备侧，这个端口称为doorbell寄存器；&lt;/p&gt;

&lt;p&gt;4.设备接收到doorbell操作，会触发中断，再读取主存中的任务队列，包括队列内的信息和其指向的任务数据，GPU设备侧读取该数据。&lt;/p&gt;

&lt;p&gt;5.完成后，再将数据发送给CPU侧。一般来说，GPU设备侧发送至CPU的读写请求使用的是虚拟地址，由CPU的IOMMU或SMMU转换为物理地址。&lt;/p&gt;

&lt;h2 id=&quot;gpu手机管线与pc管线的差异&quot;&gt;GPU手机管线与PC管线的差异&lt;/h2&gt;

&lt;p&gt;为什么要了解手机与PC管线的差异？
PC的能耗和发热比手机端可以更大一些，因此PC与手机在硬件架构上有天然的不同，进而使得它们在GPU管线上也有很大的差异，这使得我们在优化手机端时必须了解这种差异再做针对性的做优化。&lt;/p&gt;

&lt;h2 id=&quot;tbdrtile-base-deffered-rendering是现代移动端gpu的设计架构它同传统pc上irimmediate-rendering架构的gpu在硬件设计上有很大的差别&quot;&gt;TBDR(Tile-Base-Deffered-Rendering)是现代移动端GPU的设计架构，它同传统PC上IR（Immediate-Rendering）架构的GPU在硬件设计上有很大的差别。&lt;/h2&gt;

&lt;p&gt;为什么呢？因为功耗是Mobile设备设计的第一考虑因素，而带宽是功耗的第一杀手。&lt;/p&gt;

&lt;p&gt;我们来看PC的GPU管线，即传统的IR（Immediate-Rendering）模式：&lt;/p&gt;

&lt;p&gt;（IMR管线图：源自网络）&lt;/p&gt;

&lt;p&gt;IMR（Immediate Mode Rendering）模式中，GPU直接在主存或显存上读写深度缓存（Depth Buffer）和帧缓存（Frame Buffer），这导致带宽消耗很大，如果在手机上耗电和发热都无法承受。&lt;/p&gt;

&lt;p&gt;手机使用统一内存架构，CPU和GPU都通过总线来访问主存。GPU需要获取三角形数据（Geometry Data）、贴图数据（Texture Data）以及帧缓存（Frame Buffer），它们都在主存中。如果GPU直接从主存频繁地访问这些数据，就会导致带宽消耗大，成为性能瓶颈。&lt;/p&gt;

&lt;h2 id=&quot;tbrtile-based-rendering管线&quot;&gt;TBR（Tile-Based-Rendering）管线&lt;/h2&gt;

&lt;p&gt;基于以上所述原因，手机GPU使用自己的缓存区（SRAM），例如On-Chip深度缓存（On-Chip Depth Buffer）和On-Chip颜色缓存（On-Chip Color Buffer），它们与存取主存相比，速度更快，功耗更低。但它们的存储空间很小。（SRAM不需要充电来保持存储记忆，因此SRAM的读写基本不耗电，缺点是价格昂贵）&lt;/p&gt;

&lt;p&gt;如果手机直接读写帧缓存（Frame Buffer）就相当于让一辆火车在你家和公司之间来回奔跑，非常耗电。于是手机端想要拆分绘制内容，每次只绘制一小部分，再把所有绘制完成的部分拼起来。&lt;/p&gt;

&lt;p&gt;把帧缓存（Frame Buffer）拆分成很多个小块，使得每个小块可以被GPU附近的SRAM容纳，块的多少取决于GPU硬件的SRAM大小。这样GPU就可以分批的一块块的在SRAM上读写帧缓存（Frame Buffer），一整块都读写完毕后，再整体转移回主存上。&lt;/p&gt;

&lt;p&gt;这种模式就叫做TBR（Tile-Based-Rendering），整体管线如下图：&lt;/p&gt;

&lt;p&gt;（TBR管线图：源自网络）&lt;/p&gt;

&lt;p&gt;屏幕分块后的大小一般为16x16或32x32像素 ，在几何阶段之后再执行分块(Tiling)，接着将各个块（Tile）逐个光栅化，最后写入帧缓存中（Frame Buffer）中 。&lt;/p&gt;

&lt;p&gt;这里有一些细节要注意，TBR在接受每个指令（CommandBuffer）时并不立即绘制，而是先对这些数据做顶点处理，把顶点处理的结果暂时保存在主存上，等到非得刷新整个帧缓存时，才真正的用这批数据做光栅化。&lt;/p&gt;

&lt;p&gt;因此，TBR的管线实际可以认为被切分成两部分，前半部分为顶点数据部分，后半部分为片元数据部分：&lt;/p&gt;

&lt;p&gt;（TBR把管线切分为光栅化前和光栅化后）&lt;/p&gt;

&lt;h3 id=&quot;顶点数据先被处理并存储在frame-data中等到必须刷新时例如帧缓存置换调用glflush调用glfinish调用glreadpixels读取帧缓存像素时调用glcopytexiamge拷贝贴图时调用glbitframebuffer获取帧缓存时调用queryingocclusion解绑帧缓存时等等才被集中的拿去处理光栅化&quot;&gt;顶点数据先被处理并存储在Frame Data中，等到必须刷新时（例如帧缓存置换，调用glflush，调用glfinish，调用glreadpixels读取帧缓存像素时，调用glcopytexiamge拷贝贴图时，调用glbitframebuffer获取帧缓存时，调用queryingocclusion，解绑帧缓存时等等）才被集中的拿去处理光栅化。&lt;/h3&gt;

&lt;h3 id=&quot;那么为什么pc不使用tbr呢&quot;&gt;那么为什么PC不使用TBR呢？&lt;/h3&gt;

&lt;p&gt;实际上直接对主存或显存（这里也有多级缓存）进行整块数据的读写速度是最快的，而TBR需要一块块的绘制，然后再回拷给主存。可以简单的认为TBR牺牲了执行效率，换来了相对更难解决的带宽功耗。如果哪一天手机上解决了带宽的功耗问题，或者说SRAM足够大了，可能就没有TBR了。&lt;/p&gt;

&lt;h2 id=&quot;tbdrtile-based-deferred-rendering管线&quot;&gt;TBDR（Tile-based deferred rendering）管线&lt;/h2&gt;

&lt;p&gt;TBR会把顶点数据处理完毕后存储在Frame Data中，那么就会有很多厂商针对Frame Data做优化。&lt;/p&gt;

&lt;p&gt;TBDR整体的管线图如下：&lt;/p&gt;

&lt;p&gt;（TBDR管线图：源自网络）&lt;/p&gt;

&lt;p&gt;我们看到相比TBR，TBDR在光栅化（Raster）后多了一个HSR（Hidden Surface Removal）处理，这部分处理主要剔除无需绘制的元素，减少重绘（Overdraw）数量（高通通过优化划分块（Tile）之后执行顶点着色器（Vertex Shader）之前的节点来达到此目的，称为LRZ）。例如提前对不透明像素做深度测试并剔除，剔除被模板裁剪掉的像素等等，总之它们不会进入到像素着色器阶段（Pixel Shader）。&lt;/p&gt;

&lt;p&gt;因此在TBDR上，不透明物体的排序没有太大意义，Early-Z这种策略也不存在IOS上。这些GPU硬件巧妙的利用TBR的Frame Data队列实现了一种延迟渲染，尽可能只渲染那些会最终影响帧缓存（Frame Buffer）的像素。&lt;/p&gt;

&lt;h3 id=&quot;tbdr和软件上的延迟渲染相比有什么区别呢&quot;&gt;TBDR和软件上的延迟渲染相比有什么区别呢？&lt;/h3&gt;

&lt;p&gt;软件层面的延迟渲染与TBDR不同。软件层面的延迟渲染是针对一个Drawcall，对于从后到前的不透明物体绘制是每次都要绘制的，而硬件层面的延迟渲染，处理的是一整批Drawcall，剔除这一整批Drawcall中不会绘制的像素最后再渲染。可以说现在大部分的移动端的GPU都使用TBDR架构。&lt;/p&gt;

&lt;h3 id=&quot;参考资料&quot;&gt;参考资料：&lt;/h3&gt;

&lt;p&gt;《How Shader Cores Work》
https://engineering.purdue.edu/~smidkiff/KKU/files/GPUIntro.pdf&lt;/p&gt;

&lt;p&gt;《CPU体系结构》
https://my.oschina.net/fileoptions/blog/1633021&lt;/p&gt;

&lt;p&gt;《深入理解CPU的分支预测(Branch Prediction)模型》
https://zhuanlan.zhihu.com/p/22469702&lt;/p&gt;

&lt;p&gt;《分析Unity在移动设备的GPU内存机制（iOS篇）》
https://www.jianshu.com/p/68b41a8d0b37&lt;/p&gt;

&lt;p&gt;《PC与Mobile硬件架构对比》
https://www.cnblogs.com/kekec/p/14487050.html&lt;/p&gt;

&lt;p&gt;《针对移动端TBDR架构GPU特性的渲染优化》
https://gameinstitute.qq.com/community/detail/123220&lt;/p&gt;

&lt;p&gt;《A look at the PowerVR graphics architecture: Tile-based rendering》
https://www.imaginationtech.com/blog/a-look-at-the-powervr-graphics-architecture-tile-based-rendering/&lt;/p&gt;

&lt;p&gt;《A look at the PowerVR graphics architecture: Deferred rendering》
https://www.imaginationtech.com/blog/the-dr-in-tbdr-deferred-rendering-in-rogue/&lt;/p&gt;

&lt;p&gt;《深入GPU硬件架构及运行机制》
https://www.cnblogs.com/timlly/p/11471507.html&lt;/p&gt;

&lt;p&gt;《深入浅出计算机组成原理》
https://time.geekbang.org/column/article/105401?code=7VZ-Md9oM7vSBSE6JyOgcoQhDWTOd-bz5CY8xqGx234%3D&lt;/p&gt;

&lt;p&gt;《Nvidia Geforce RTX-series is born》
https://www.fudzilla.com/reviews/47224-nvidia-geforce-rtx-series-is-born?start=2&lt;/p&gt;

&lt;p&gt;《渲染管线与GPU（Shading前置知识）》
https://zhuanlan.zhihu.com/p/336999443&lt;/p&gt;

&lt;p&gt;《剖析虚幻渲染体系（12）- 移动端专题Part 1（UE移动端渲染分析）》
https://www.cnblogs.com/timlly/p/15511402.html&lt;/p&gt;

&lt;p&gt;《tpc-texture-processing-cluster》
https://gputoaster.wordpress.com/2010/12/11/tpc-texture-processing-cluster/&lt;/p&gt;

&lt;p&gt;《Life of a triangle - NVIDIA’s logical pipeline》
https://developer.nvidia.com/content/life-triangle-nvidias-logical-pipeline&lt;/p&gt;

&lt;p&gt;《Rasterisation wiki》
https://en.wikipedia.org/wiki/Rasterisation&lt;/p&gt;

&lt;p&gt;《PolyMorph engine and Data Caches by Hilbert Hagedoorn》
https://www.guru3d.com/articles-pages/nvidia-gf100-(fermi)-technology-preview,3.html&lt;/p&gt;

&lt;p&gt;《NVIDIA GPU的一些解析》
https://zhuanlan.zhihu.com/p/258196004&lt;/p&gt;

&lt;p&gt;《tensor-core-performance-the-ultimate-guide》
https://developer.download.nvidia.cn/video/gputechconf/gtc/2019/presentation/s9926-tensor-core-performance-the-ultimate-guide.pdf&lt;/p&gt;

&lt;p&gt;《Understanding the Understanding the graphics pipeline》
https://www.seas.upenn.edu/~cis565/LECTURES/Lecture2%20New.pdf&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU1ODY1ODY2NA==&amp;amp;mid=2247485096&amp;amp;idx=1&amp;amp;sn=c027b6af4677515ba1e5950aac8ba68d&amp;amp;chksm=fc2263afcb55eab9204898b39fb77ee04f5767ac450507b6192a5c6d5612a45b6d29b1bcee16&amp;amp;token=853743270&amp;amp;lang=zh_CN#rd&quot;&gt;已发布在微信公众号上，点击跳转&lt;/a&gt;&lt;/p&gt;

</description>
               <pubDate>Sun, 12 Dec 2021 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2021/12/12/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B051</link>
               <guid isPermaLink="true">http://www.luzexi.com/2021/12/12/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B051</guid>
            </item>
        
            <item>
               <title>读书笔记(五十) 《如何精彩演讲》#2 克服演讲时的恐惧</title>
               <description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU1ODY1ODY2NA==&amp;amp;mid=2247485068&amp;amp;idx=1&amp;amp;sn=464d36573e97c69aeab4ab996885ccee&amp;amp;chksm=fc22638bcb55ea9d3e4472e92a760b147dc2a816268e9d3a435842995723d3a02e9a26b0f4b5&amp;amp;token=1416441933&amp;amp;lang=zh_CN#rd&quot;&gt;已发布在微信公众号上，点击跳转&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;背景&quot;&gt;背景&lt;/h1&gt;

&lt;p&gt;不知不觉看完了6本关于演讲的主题，按推荐顺序排列分别是《高效演讲》、《演讲与口才》、《即兴演讲》、《关键对话》、《TED演讲的力量》、《说话的艺术》。&lt;/p&gt;

&lt;p&gt;我希望自己能够对演讲有一个系统性的学习。于是自己在平常的生活和工作中实践了一段时间，前前后后加起来有两个月时间。&lt;/p&gt;

&lt;p&gt;目标是，改善平常的工作、生活中表达的流畅和清晰度，能让人感觉到舒服让人感觉有活力。同时在公众演讲上，希望自己能够很好的呈现自己的所思所想以及所知所学。&lt;/p&gt;

&lt;p&gt;因此开启这个演讲学习系列的总结文章，我将对这6本书的内容加上我的实践经验做一次全面的系统性的总结。&lt;/p&gt;

&lt;h3 id=&quot;概述&quot;&gt;概述：&lt;/h3&gt;

&lt;p&gt;1.恐惧的原因
2.克服恐惧的原理
3.制定克服恐惧的行动&lt;/p&gt;

&lt;h3 id=&quot;内容&quot;&gt;内容：&lt;/h3&gt;

&lt;p&gt;为什么要了解演讲时的恐惧？&lt;/p&gt;

&lt;p&gt;1.只有了解恐惧的原理才能正确认识它
2.它会使得事情更加糟糕
3.它会对我们的心理产生长短期的变化&lt;/p&gt;

&lt;p&gt;在平时的生活工作学习当中，当我们恐惧时很多时候并不能了解自己的恐惧情绪。由于在很多情况下，我们观察不到自己的情绪，导致我们常常无法在情绪有问题时，及时的调整它。&lt;/p&gt;

&lt;p&gt;因此你会看到很多时候，当出现了恐惧的症状时，我们没有调整它，这直接导致事情发展变得糟糕。&lt;/p&gt;

&lt;p&gt;（恐惧表情图：来源网络）&lt;/p&gt;

&lt;p&gt;不止如此，如果没有去很好的应对恐惧的话，长此以往我们在心里会有比较大的阴影。这使得，我们在一件比较重要的会议上，由于你的恐惧而退缩或退却，会使你在精神上遭受更大的打击。&lt;/p&gt;

&lt;p&gt;如果次数多了，你会发现你对这些重要的场所，重要的机会，会产生习惯性的恐惧，这常常使你对人生产生比较多的怀疑。&lt;/p&gt;

&lt;p&gt;因此无论从长期或短期来看，我们都需要去主动的了解恐惧。这是我们必须去了解恐惧的重要原因。它会将生活弄得更加糟糕，因此我们必须了解他，特别是在演讲时。&lt;/p&gt;

&lt;p&gt;恐惧有很多种，这里我们只关注演讲时的恐惧。但其实演讲的恐惧已经覆盖了生活中很多的方面，它与生活中的恐惧有很多共性。&lt;/p&gt;

&lt;h2 id=&quot;是什么让你恐惧&quot;&gt;是什么让你恐惧？&lt;/h2&gt;

&lt;p&gt;了解恐惧产生的原因，可以让我们对恐惧问题的形成有更深刻的认识。&lt;/p&gt;

&lt;p&gt;不管是普通焦虑还是惊恐障碍，都没有单一的成因，也不可能在消除这个成因后问题就得到彻底根除。
焦虑问题是有多方面，多种原因引起的，包括遗传因素，生物因素，家庭背景和教养方式、心理条件作用、近期生活转变、自我对话和个人信念体系、表达情感的能力、当前环境压力等。&lt;/p&gt;

&lt;p&gt;恐惧的原因：
1.面对重要场面，准备不充分
2.对周围的环境很陌生
3.经历不足，导致的对事情没有底气
4.在意别人对自己的看法
5.生理反应，肌肉紧张、心跳加速、头脑晕眩
6.近期自己身边的环境变动较大
7.长期积累的心里因素，过分在意过去发生的事情&lt;/p&gt;

&lt;p&gt;我们在面对演讲时通常会有很多的恐惧，特别是在上台前一段时间，自己的恐惧心理被放大的特别多。&lt;/p&gt;

&lt;p&gt;其实说来不只是演讲，恐惧在我们平常的生活跟工作当中也非常多，我们心里常常会对某件即将到来的事产生恐惧。&lt;/p&gt;

&lt;p&gt;因此呢。并不是说在演讲时你才会恐惧，在平常的生活当中，你同样会有很多令你焦虑不安的事情。&lt;/p&gt;

&lt;p&gt;演讲跟平常我们生活、工作时产生的恐惧是一样的，并没有说因为演讲而特殊。&lt;/p&gt;

&lt;p&gt;我们究竟为什么而恐惧？我们来分析一下。&lt;/p&gt;

&lt;p&gt;前面列了7条恐惧的原因，但其实这7条可以归类一下变得更精简一些。&lt;/p&gt;

&lt;p&gt;（恐惧原因）&lt;/p&gt;

&lt;p&gt;恐惧的原因总的来说为三方面：
1.准备不充分
2.环境变化导致的恐惧
3.长期积累的心理因素&lt;/p&gt;

&lt;p&gt;（恐惧原因细节图）&lt;/p&gt;

&lt;h3 id=&quot;第一准备不充分&quot;&gt;第一，准备不充分&lt;/h3&gt;

&lt;p&gt;当我们知道我们将要去面对一件事情，但是这件事情并没有充足的把握时我们就会感到恐惧。&lt;/p&gt;

&lt;p&gt;因为这件事情是未知的，而且我预感到他可能不会有太好的结果，因为我对他没有把握，我也没有对他做任何的准备工作。&lt;/p&gt;

&lt;p&gt;可能有这么一件事情你是从来没有做过的，或者说你也不知道他将会发生什么样的情况。甚至在你的预感当中，这件事会发生比较差的或者糟糕的情况，此时你就会对这件事情产生恐惧。因而有逃避去面对这件事情的心理状态。&lt;/p&gt;

&lt;p&gt;在演讲时也是同样的，大部分人没有台上演讲的经验和习惯，因此对于上台演讲这件事情，大部分人都是有恐惧心理的。&lt;/p&gt;

&lt;p&gt;这个恐惧心理是因为我们没有，为这件事情做过任何的准备，也不知道这件事情会发生怎样的情况。此时我们心里隐隐的感觉到这这件事情会比较糟糕。因此，我们对演讲产生了恐惧。&lt;/p&gt;

&lt;p&gt;总之，当你面对一件即将到来，但未知的事情时，当你面对一件你觉得可能会发生比较糟糕的事情时，通常是因为我们没有做好足够的准备工作。这个准备工作可能需要花去几小时、几天、几个月甚至几年的时间，总之我们并没有为这件事做好足够的准备。&lt;/p&gt;

&lt;h3 id=&quot;第二环境变化导致的恐惧&quot;&gt;第二，环境变化导致的恐惧&lt;/h3&gt;

&lt;p&gt;我们周围的环境时常在变化，包括我们的工作，上下级人员调动，以及你身边人的来往，以及你亲人的离去与归来，这些的环境都在时刻变化着，影响着我们的心理。
可能是你最近比较倒霉，碰到了一些小概率事件，或者可能会因为大环境的变化使得感到沮丧。
甚至有可能你出差到了某个陌生的环境，让你感到很不舒服。&lt;/p&gt;

&lt;p&gt;这些环境的变化都会让你产生焦虑甚至恐惧的心理。&lt;/p&gt;

&lt;p&gt;总之，在当前这样的环境下，是你并不熟悉的环境，不是你能掌控而环境，因此导致你对周围的环境有一种隔离感，像是没有依靠的感觉。&lt;/p&gt;

&lt;h3 id=&quot;第三长期积累的心理因素&quot;&gt;第三，长期积累的心理因素&lt;/h3&gt;

&lt;p&gt;你可能会因为曾经的遭遇而感到痛苦，这些遭遇在你的脑中挥之不去，当再次发生或者即将发生这样的事情的时候，你就会感到焦虑和恐惧。&lt;/p&gt;

&lt;p&gt;这些痛苦的场景通常会延伸到我们生活的各个角落，比如说，你可能曾经在小组发言时，磕磕巴巴导致你对公众发言产生了恐惧，致使你在现在上台演讲时都会表现的异常的惊恐，当回忆起自己以前在小组发言时的那些场景，以及当时人们都的表情，你会不自觉的把这些场景延伸到现在的公众演讲以及公众表达上。&lt;/p&gt;

&lt;p&gt;常见比如，人们小时候玩水时掉入水中呛到过，成人后就对游泳产生了恐惧。或者在爬树时掉下来过，就对过山车产生了恐惧等等。&lt;/p&gt;

&lt;p&gt;不仅如此，人们通常会将一种痛苦的经历延展到另一个场景中，比如说，某人会因为小学里遭到过坏学生的殴打，致使他觉得现在自己面对他人安排的工作任务时会感觉自己是被压迫的或受虐待的，因此有很大的抵触情绪。&lt;/p&gt;

&lt;p&gt;总之，人们常常会延展过去的痛苦回忆，将这些痛苦的回忆放入到现在的场景里面去，这使得他们感到恐惧，同时也使他们有一个最佳的逃避借口。&lt;/p&gt;

&lt;h2 id=&quot;如何行动去克服恐惧&quot;&gt;如何行动去克服恐惧？&lt;/h2&gt;

&lt;p&gt;我罗列了所有的方法，有些方法是我自己总结的，有些则是参考《应对焦虑》埃德蒙.伯恩写的这本书。&lt;/p&gt;

&lt;p&gt;（克服恐惧的方法全图）&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;观察自己的恐惧&lt;/li&gt;
  &lt;li&gt;提前做好准备&lt;/li&gt;
  &lt;li&gt;积极变化适应环境&lt;/li&gt;
  &lt;li&gt;冥想练习排除杂念&lt;/li&gt;
  &lt;li&gt;渐进式肌肉放松&lt;/li&gt;
  &lt;li&gt;暴露疗法，应对暴露，完全暴露，想象暴露&lt;/li&gt;
  &lt;li&gt;运动，增加运动频率，增加强度增加抗压力&lt;/li&gt;
  &lt;li&gt;自我关怀，爱的言语、规律作息、简化生活、&lt;/li&gt;
  &lt;li&gt;转移注意力，专注于技巧，找人聊天，体验愉悦的事，听音乐&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以上这些技巧，可以用在我们生活当中面对焦虑与恐惧时的情况。&lt;/p&gt;

&lt;p&gt;虽然大部分技巧都可以用到演讲中，但我想讲其中在演讲时运用最有效的方法，我们来看下图：&lt;/p&gt;

&lt;p&gt;（克服演讲恐惧的有效方法）&lt;/p&gt;

&lt;h3 id=&quot;观察自己的恐惧&quot;&gt;观察自己的恐惧&lt;/h3&gt;

&lt;p&gt;我们最先要做的是观察自己的恐惧，这是所有技巧的前提。&lt;/p&gt;

&lt;p&gt;（观察恐惧图：来源网络）&lt;/p&gt;

&lt;p&gt;恐惧也是情绪的一种，我们需要观察恐惧发生时候我们的表现，我们的眼神，我们心跳，我们的肌肉，在做怎样的颤抖。通过观察我们身体上的变化，我们可以感知到自己的恐惧。当我们能够观察到恐惧时，恐惧本身就没有这么强烈了，所以我们首先要做的是，用第三者的角度观察自己的恐惧表现。&lt;/p&gt;

&lt;p&gt;通过观察我们能及时的发现我们的精神状态在变化，只要我们观察到恐惧，它就不会再扩散，此时我们就可以想办法逐渐的释放它。&lt;/p&gt;

&lt;p&gt;最糟糕的是你观察不到自己的恐惧，但仍然继续逼迫自己向前对劲，这时你会有一种无力感，同时恐惧会不断的蔓延到你的全身，使你的精神状态陷入更加崩溃的边缘。&lt;/p&gt;

&lt;p&gt;我们只有识别自己的恐惧状态，识别自己的恐惧表现，才能真正的认识到自己的情绪变化，以及事物对我们的影响程度。这为后面的措施，调整打下了好的基础。&lt;/p&gt;

&lt;h3 id=&quot;提前做好准备&quot;&gt;提前做好准备&lt;/h3&gt;

&lt;p&gt;提前做好准备，通常是最明智的选择，也是克服恐惧的最好方法。&lt;/p&gt;

&lt;p&gt;（提前准备图：来源网络）&lt;/p&gt;

&lt;p&gt;它需要我们抽出时间去为这场演讲做准备。&lt;/p&gt;

&lt;p&gt;我需要写演讲稿，并且在演讲前打磨多次。通过自己不断的练习和打磨演讲，将演讲稿打磨成自己认为完美的样子。&lt;/p&gt;

&lt;p&gt;同时，在我们平时的生活中，要为未来的可能的演讲做好准备。所以，在我们平常的生活当中，要注重收集生活的细节，收集演讲的素材，这些素材能够更快更有效的运用在未来的演讲中，让演讲和故事呈现的效果更好。&lt;/p&gt;

&lt;p&gt;因此，提前做好准备，是每个演讲达人的最重要的工作之一。&lt;/p&gt;

&lt;h3 id=&quot;积极拥抱变化适应环境&quot;&gt;积极拥抱变化适应环境&lt;/h3&gt;

&lt;p&gt;（拥抱变化：来源网络）&lt;/p&gt;

&lt;p&gt;很多时候我们避免不了会去自己陌生的地方演讲。这个时候，环境的变化对我们的精神冲击力很大，周围没有熟悉的环境没有熟悉的人，我们感到被隔离脱离群体从而感到恐惧。&lt;/p&gt;

&lt;p&gt;这个时候，我们需要积极的去拥抱变化。与台上台下的工作人员沟通，积极的与嘉宾沟通，与在场的观众沟通。通过这样沟通交流我们能够舒展我们的心情，能够释放我们的紧张情绪，能够释放我们的恐惧情绪。&lt;/p&gt;

&lt;p&gt;如果在现场当我们遇到困难的时候，需要主动寻求帮助。特别是当下环境中的管理者，或者比较熟悉的朋友，通过他们的帮助让自己这份不安的心能够安定下来，减少恐惧的蔓延。&lt;/p&gt;

&lt;p&gt;特别是在演讲开场时，自己在一个陌生的环境下非常容易紧张焦虑和恐惧，此时在开场时需要跟大家有一个沟通交流的时间，留出这样一个前置的时间跟大家沟通交流非常必要，然后再慢慢进入状态，开始自己的演讲。也可以通过说出自己的感受来跟大家做一些互动，这样让自己的紧张情绪和压力能够释放掉，这为后面的事情进展顺利而铺平了道路。&lt;/p&gt;

&lt;h3 id=&quot;放松练习&quot;&gt;放松练习&lt;/h3&gt;

&lt;p&gt;我们可以用身体上的练习和精神的上的练习来放松自己。&lt;/p&gt;

&lt;p&gt;（冥想图：来源网络）&lt;/p&gt;

&lt;p&gt;精神上的练习，可以通过说出感受来接纳自己释放压力。也可以通过就地坐下或稳定站立并闭上眼睛来做冥想，通过专注于自己的呼吸，将杂念排除，也可以通过腹式呼吸来将注意力转移到自己的腹部上，让自己更加专注于当下。&lt;/p&gt;

&lt;p&gt;冥想的要点是专注于呼吸，这会让你排除杂念，专注于当下。&lt;/p&gt;

&lt;p&gt;身体上的练习，也可以起到放松作用。&lt;/p&gt;

&lt;p&gt;（与文无关的放松练习图：来源网络）&lt;/p&gt;

&lt;p&gt;这里有一个叫渐进式肌肉放松法。我们来具体介绍一下：&lt;/p&gt;

&lt;p&gt;腹式呼吸，用腹部呼吸，吸气时肚子吸入空气突出呼气时因气体排除而扁平，呼吸要慢，想象全身的紧张感开始从体内流去。&lt;/p&gt;

&lt;p&gt;撰紧拳头，保持7-10秒，再从开拳头15-20秒，反复循环&lt;/p&gt;

&lt;p&gt;双手前臂抬起，前臂与上臂尽量靠拢，紧绷肱二头肌，保持，然后放松。&lt;/p&gt;

&lt;p&gt;双手手臂向外延展到水平位置，伸肘，拉紧肱三头肌，保持，然后放松。&lt;/p&gt;

&lt;p&gt;尽量抬高眉毛，收缩前额肌肉，保持，然后放松。放松时，想象前额肌肉慢慢舒展、松弛。&lt;/p&gt;

&lt;p&gt;紧闭双眼，绷紧眼周肌肉，保持，然后放松。想象深度放松的感觉在眼镜周围蔓延。&lt;/p&gt;

&lt;p&gt;张大嘴巴，拉伸下颚关节周围的肌肉，绷紧下巴，保持，然后放松。张着嘴，让下巴自然放松。&lt;/p&gt;

&lt;p&gt;头向后仰，尽量靠向后背，收紧脖子后面的肌肉，专注于收紧颈部肌肉的动作，保持，然后放松。&lt;/p&gt;

&lt;p&gt;双肩同时最大限度地向上耸起，绷紧肩部肌肉，保持，然后放松。&lt;/p&gt;

&lt;p&gt;双肩外展，尽量向背部中线靠拢，绷紧肩胛骨周围的肌肉。让肩胛处的肌肉保持绷紧，然后放松。&lt;/p&gt;

&lt;p&gt;深吸一口气，绷紧胸部肌肉，保持10秒，然后慢慢呼气。&lt;/p&gt;

&lt;p&gt;收紧腹部肌肉，保持，然后放松。&lt;/p&gt;

&lt;p&gt;背部弓起，拉紧下背部肌肉，保持，然后放松。&lt;/p&gt;

&lt;p&gt;收紧臀部，保持，然后放松。&lt;/p&gt;

&lt;p&gt;收缩大腿肌肉，保持，然后放松。&lt;/p&gt;

&lt;p&gt;向自己的方向用力伸脚趾，绷紧小腿肌肉，保持，然后放松。&lt;/p&gt;

&lt;p&gt;卷起脚趾，绷紧脚面，保持，然后放松。&lt;/p&gt;

&lt;p&gt;以上是一整套的渐进式肌肉放松法，一整套下来需要20-30分钟，在平时的放松练习可以通过抽取几个对自己比较有效的姿势去做放松练习，这样更容易将这些放松练习融入到我们的生活中，特别是演讲前的放松练习。&lt;/p&gt;

&lt;h3 id=&quot;参考资料&quot;&gt;参考资料：&lt;/h3&gt;

&lt;p&gt;《三招搞定演讲构思》朱林滢&lt;/p&gt;

&lt;p&gt;《应对焦虑》埃德蒙.伯恩&lt;/p&gt;

&lt;p&gt;《高效演讲》彼得.迈尔斯，尚恩.尼克斯&lt;/p&gt;
</description>
               <pubDate>Sun, 05 Dec 2021 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2021/12/05/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B049</link>
               <guid isPermaLink="true">http://www.luzexi.com/2021/12/05/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B049</guid>
            </item>
        
            <item>
               <title>给女儿的信(十九) 说出自己的感受积极化解情绪</title>
               <description>&lt;h2 id=&quot;要点&quot;&gt;要点：&lt;/h2&gt;

&lt;p&gt;说出自己的感受，积极化解情绪&lt;/p&gt;

&lt;h2 id=&quot;结构&quot;&gt;结构：&lt;/h2&gt;

&lt;p&gt;1.半年一次的俱乐部选举即将开始
2.我自己写了ppt，做了选举前的准备
3.选举很激烈，主席选举经过2次平分后终于选出结果，大家也很欢乐
4.接着我上台选举VPE，上台很紧张，自己讲的有点死板
5.由于最近在俱乐部里挺活跃的，抱着一线希望，但最后还是败下阵来
6.接着收拾下心情，继续竞选后面的职位
7.有人提议VPM，我接受了
8.我上台后，先化解自己的情绪，说出了自己的感受
9.同时为VPM制定了目标，并真诚说出自己的内心话，希望跟大家交朋友
10.爸爸认为练习技巧前应该先交朋友，有了朋友技巧才有用，得到大家的认可，最后成功选举获得VPM
11.价值升华，失败不可怕，及时调整心态，说出感受，主动卸下压力，能让事情进展的更加顺利&lt;/p&gt;

&lt;h2 id=&quot;内容&quot;&gt;内容：&lt;/h2&gt;

&lt;p&gt;Hello Sharon and hello，Anne，爸爸喜欢你们。爸爸到深圳了，要再过一个月回来，到时候再跟你玩，爸爸喜欢跟你们玩游戏，喜欢跟你们聊天，喜欢跟你们一起学习，喜欢跟你们一起加油。&lt;/p&gt;

&lt;p&gt;今天爸爸跟你们聊一下，爸爸最近在演讲俱乐部里面做的一些事情好不好？&lt;/p&gt;

&lt;p&gt;最近半年爸爸都在演讲俱乐部里面练习演讲，练习表达，这和Sharon在学校里面练小主播一样，非常像，爸爸每天都会练习那个绕口令，都会练习口步操，是不是跟你们很像？平时的时候爸爸会做一些演讲，上台演讲，这样呢会让爸爸在公众表达上更好一些，平常跟人沟通交流时，也能更自然一些。&lt;/p&gt;

&lt;p&gt;那爸爸想跟确认跟安妮说说说最近爸爸在俱乐部里面的一件事好不好？最近俱乐部里面要选举官员，怎么是官员？呢就是嗯宣传学校里面选班长，选学习委员，选体育委员，这些是一样的，爸爸在俱乐部里面也要选主席，要选副会长，要选秘书长等这些岗位，那这些岗位呢要做竞选演讲。&lt;/p&gt;

&lt;p&gt;于是爸爸上台做了竞选演讲，爸爸上台了两次，做了两次竞选演讲，分别去竞选了两个职位。&lt;/p&gt;

&lt;p&gt;第一个职位的时候爸爸上台很紧张，自己说话也有点很死板，说话的内容不是很清楚，因为爸爸太紧张了，通常紧张的时候爸爸说话都是有一点点啊有语无伦次，虽然抱着一线希望，但是最后还是败下阵来了。&lt;/p&gt;

&lt;p&gt;于是就收拾了一下心情继续的后面的竞选岗位。等爸爸第二次上台的时候，爸爸先做的一件事情就是爸爸先化解情绪，再开始自己的演讲内容，爸爸第二次上台的时候也还是很紧张，于是我上台时先说出自己的感受，说说自己为什么紧张，说自己还在想怎么去改进就第二次上台了。&lt;/p&gt;

&lt;p&gt;在说出自己的感受的时候，爸爸已经慢慢的化解了自己的情绪，接着爸爸就说出自己的内心话，希望能跟大家交朋友，希望能在这个俱乐部里面啊有更好的练习，跟大家一起学习，真心真诚的跟大家交朋友。&lt;/p&gt;

&lt;p&gt;那当爸爸说出这些真心话的时候，得到了大家的认可，爸爸也同时告诉大家，来这里练习演讲，爸爸首先希望能跟大家先交朋友，然后再练习，这种方式。得到了大家的认可，最后成功获得了会员副主席的这个职位。&lt;/p&gt;

&lt;p&gt;爸爸想跟Sharon和安妮说，这次经历告诉爸爸，其实失败并不可怕，在失败以后要及时调整自己的状态，调整自己的心情，怎么去调整呢，就是说出自己的感受，向周围人说出自己的感受，说出自己的看法，这样就能主动卸下自己的压力，让自己放松下来，这杨可以让后面的事情进展的更加顺利。&lt;/p&gt;

&lt;p&gt;今天的故事就讲到这里，爸爸爱你们，喜欢你们了。&lt;/p&gt;

</description>
               <pubDate>Sat, 27 Nov 2021 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2021/11/27/%E7%BB%99%E5%A5%B3%E5%84%BF%E7%9A%84%E4%BF%A119</link>
               <guid isPermaLink="true">http://www.luzexi.com/2021/11/27/%E7%BB%99%E5%A5%B3%E5%84%BF%E7%9A%84%E4%BF%A119</guid>
            </item>
        
            <item>
               <title>读书笔记(四十九) 《游戏引擎架构》#4 低阶渲染器（3）</title>
               <description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU1ODY1ODY2NA==&amp;amp;mid=2247485051&amp;amp;idx=1&amp;amp;sn=e98f1e1971d56ce6543926b4f9bad204&amp;amp;chksm=fc22637ccb55ea6a4c16c5c0d8fd43cff936350490d79f1e377b61e4914300c39c4fc2911da1&amp;amp;token=53415989&amp;amp;lang=zh_CN#rd&quot;&gt;已发布在微信公众号上，点击跳转&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;背景&quot;&gt;背景：&lt;/h1&gt;

&lt;p&gt;作为游戏开发从业者，从业务到语言到框架到引擎，积累了一些知识和经验，特别是在看了几遍《游戏引擎架构》后对引擎架构的理解又深入了些。&lt;/p&gt;

&lt;p&gt;近段时间有对引擎剖析的想法，正好借这书本对游戏引擎架构做一个完整分析。&lt;/p&gt;

&lt;p&gt;此书用简明、清楚的方式覆盖了游戏引擎架构的庞大领域，巧妙地平衡了广度与深度，并且提供了足够的细节。&lt;/p&gt;

&lt;p&gt;借助《游戏引擎架构》这本书、结合引擎源码和自己的经验，深入分析游戏引擎的历史、架构、模块，最后通过实践简单引擎开发来完成对引擎知识的掌握。&lt;/p&gt;

&lt;p&gt;游戏引擎知识面深而广，所以对这系列的文章书编写范围做个保护，即不对细节进行过多的阐述，重点剖析的是架构、流程以及模块的运作原理。&lt;/p&gt;

&lt;p&gt;同时《游戏引擎架构》中部分知识太过陈旧的部分，会重新深挖后总结出自己的观点。&lt;/p&gt;

&lt;p&gt;概述：&lt;/p&gt;

&lt;p&gt;本系列文章对引擎中的重要的模块和库进行详细的分析，我挑选了十五个库和模块来分析：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;时间库&lt;/li&gt;
  &lt;li&gt;自定义容器库&lt;/li&gt;
  &lt;li&gt;字符串散列库&lt;/li&gt;
  &lt;li&gt;内存管理框架&lt;/li&gt;
  &lt;li&gt;RTTI与反射模块&lt;/li&gt;
  &lt;li&gt;图形计算库&lt;/li&gt;
  &lt;li&gt;资产管理模块&lt;/li&gt;
  &lt;li&gt;低阶渲染器&lt;/li&gt;
  &lt;li&gt;剔除与合批模块&lt;/li&gt;
  &lt;li&gt;动画模块&lt;/li&gt;
  &lt;li&gt;物理模块&lt;/li&gt;
  &lt;li&gt;UI底层框架&lt;/li&gt;
  &lt;li&gt;性能剖析器的核心部分&lt;/li&gt;
  &lt;li&gt;脚本系统&lt;/li&gt;
  &lt;li&gt;视觉效果模块&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;本篇内容为列表中的第8个部分的第1节。&lt;/p&gt;

&lt;h1 id=&quot;正文&quot;&gt;正文：&lt;/h1&gt;

&lt;p&gt;简单回顾下前文&lt;/p&gt;

&lt;p&gt;前文我们聊了下显卡在计算机硬件主板中的位置与结构，知道了CPU、GPU的通信介质，并简单介绍了手机上的主板结构。本篇开头对上一篇做一些内容补充，PC和手机的不同硬件组织，以及CPU与其他芯片的通信过程。&lt;/p&gt;

&lt;p&gt;下面我们开始这篇内容&lt;/p&gt;

&lt;p&gt;本次内容会围绕GPU来写，从硬件架构到软件驱动再到引擎架构，目标是帮大家理解GPU硬件的运作原理，理解图形接口的架构，理解引擎低阶渲染器的架构。&lt;/p&gt;

&lt;p&gt;目录：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;主板结构中的显卡&lt;/li&gt;
  &lt;li&gt;GPU功能发展史&lt;/li&gt;
  &lt;li&gt;GPU与CPU的差异&lt;/li&gt;
  &lt;li&gt;GPU硬件特点&lt;/li&gt;
  &lt;li&gt;图形驱动程序架构&lt;/li&gt;
  &lt;li&gt;引擎低阶渲染架构&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;内容结构&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;CPU硬件结构&lt;/li&gt;
  &lt;li&gt;GPU硬件结构&lt;/li&gt;
  &lt;li&gt;GPU手机管线与PC管线的差异&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;简单回顾下前文，前文我们主要讲了显卡的发展历史，知道了显卡功能和管线是如何一步步转变为现在这样子的。&lt;/p&gt;

&lt;h2 id=&quot;cpu结构与工作原理&quot;&gt;CPU结构与工作原理&lt;/h2&gt;

&lt;p&gt;我们知道，CPU运行时有三类元器件构成，取指器、译码器、运算器（逻辑算术运算器、浮点数运算器、单指令多数据运算器等）。&lt;/p&gt;

&lt;p&gt;这三类元器件代表三个阶段取指阶段（Fetch）、指令译码阶段（Decode）、执行阶段（Execute），它们在CPU内执行的步骤如下图：&lt;/p&gt;

&lt;p&gt;（图-取指-译指-执行三步骤）&lt;/p&gt;

&lt;p&gt;取指阶段为从内存或缓存中取得指令并存放到寄存器中的过程。&lt;/p&gt;

&lt;p&gt;接着，译码器会将寄存器中的指令翻译成操作指令，指令译码器按照预定的指令格式，对取回的指令进行拆分和解释，识别区分出不同的指令类别以及各种获取操作数的方法。在组合逻辑控制的计算机中，指令译码器对不同的指令操作码产生不同的控制电位，以形成不同的微操作序列；在微程序控制的计算机中，指令译码器用指令操作码来找到执行该指令的微程序的入口，并从此入口开始执行。&lt;/p&gt;

&lt;p&gt;运算阶段，则根据指令执行不同的运算单元，完成指令所规定的各种操作，具体实现指令的功能。为此，CPU 的不同部分被连接起来，以执行所需的操作。&lt;/p&gt;

&lt;p&gt;（图-控制单元-运算单元-存储单元）&lt;/p&gt;

&lt;p&gt;因此，通常我们将取指器、译码器统称为控制单元，计算器称为算术逻辑单元（ALU），寄存器和高速缓存称为存储单元。&lt;/p&gt;

&lt;p&gt;除了这三个基本单元，当下这样复杂的CPU中还有包括分支预测器、乱序控制器、内存预加载器等等。&lt;/p&gt;

&lt;p&gt;这里简单介绍下CPU指令流水线、分支预测、乱序执行的原理。&lt;/p&gt;

&lt;h2 id=&quot;指令流水线&quot;&gt;指令流水线&lt;/h2&gt;

&lt;p&gt;起初CPU指令执行是线性的，只靠取指、译码、运算顺序执行三个模块，这导致元器件的工作顺序是线性的，当一个元器件执行时，其他元器件是空等待状态，CPU执行效率比较低。&lt;/p&gt;

&lt;p&gt;为了提高效率，提高空等待的元器件的利用率，对指令执行流水线进行了拆分，并同时增加多个流水线不断减少元器件的空等待装填。如下图：&lt;/p&gt;

&lt;p&gt;（拆分多级流水线）&lt;/p&gt;

&lt;p&gt;将原本线性的三个指令执行顺序，拆分成一个个小模块，让这些独立的小模块可以自顾自的循环工作，减少前后的等待时间，从而提高了指令执行效率。&lt;/p&gt;

&lt;p&gt;用这种方式把一个指令拆分成“取指令 - 指令译码 - 执行指令”这样三个部分，这就是一个三级的流水线。进一步把“执行指令”拆分成“ALU 计算（指令执行）- 内存访问 - 数据写回”，就会变成一个五级的流水线。&lt;/p&gt;

&lt;p&gt;继续拆分，将一个长时间的操作步骤，拆分成更多的步骤，让所有步骤需要执行的时间尽量都差不多长。这样，也就可以解决我们在单指令周期处理器中遇到的复杂指令性能问题。（同时多级流水线会出现许多问题，例如模块间寄存器的写入次数太多，多模块读写同一个资源相互冲突等，这里不细说，CPU最终都有解决方案去解决）现代的 ARM 或 Intel 的 CPU，流水线级数都已经到了 14 级。&lt;/p&gt;

&lt;h2 id=&quot;乱序执行&quot;&gt;乱序执行&lt;/h2&gt;

&lt;p&gt;我们在写程序时，常常会发现函数内几个执行操作顺序并不互相依赖，哪个在前哪个在后都没有太大的关系。此时不仅编译器会对这些不相互依赖的计算操作进行重新顺序排序用于优化CPU执行效率（这也是导致线程不同步的其中一个原因），CPU也会将不相互依赖的指令放在不相同的指令流水线上以加快执行速度。&lt;/p&gt;

&lt;p&gt;（指令在不同CPU流水线上乱序执行：图来源网络）&lt;/p&gt;

&lt;p&gt;我们从图中可以看到，在流水线里，当后面的指令不依赖前面的指令时，就不用等待前面的指令执行完毕后再执行，可以另起一个流水线执行，否则就需要用NOP隔周期等待的方式将执行单元延后计算。因此我们所写的代码的执行顺序其实并不是我们所想象的那样，在CPU中大部分时候其实是乱序执行的，这样元器件的利用率更高，执行效率也更高，而依赖而停顿的次数也更少。&lt;/p&gt;

&lt;p&gt;（乱序执行的流程图）&lt;/p&gt;

&lt;p&gt;乱序执行实际的过程比我们想象的要复杂一些，总体上它会先拆分指令，再分发给执行单元，结束后将结果重新排序，最后提交缓冲。&lt;/p&gt;

&lt;h2 id=&quot;分支预测&quot;&gt;分支预测&lt;/h2&gt;

&lt;p&gt;程序中有很多true或false的判断来跳转下文要执行的指令，这种跳转会使得执行流水线发生停顿，因为要依赖前面代码计算的结果再决定要执行哪段程序，因此流水线不中断并等待结果，这会使CPU执行效率降低。&lt;/p&gt;

&lt;p&gt;在CPU中有分支预测器，它是一种数字电路，在分支指令执行前，猜测哪一个分支会被执行，这样能显著提高pipeline的性能。&lt;/p&gt;

&lt;p&gt;可以理解为，分支预测器会主动猜测分支是true还是false。&lt;/p&gt;

&lt;p&gt;如果猜错了，处理器要flush掉pipeline, 回滚到之前的分支，然后重新热启动，选择另一条路径。 
如果猜对了，处理器不需要暂停，继续往下执行。&lt;/p&gt;

&lt;p&gt;也就是说，如果CPU每次都猜错，处理器将耗费大量时间在停止-回滚-热启动这一周期性过程里。反之，如果侥幸每次都猜对了，那么处理器将从不停止、无需等待的执行后面的指令。&lt;/p&gt;

&lt;p&gt;（分支预测图）&lt;/p&gt;

&lt;p&gt;CPU执行指令遇到条件时不知道该读取哪些指令，需要等待判断条件中的计算结果，这样就中断了后面指令执行流水线使得执行效率下降。于是CPU增加了分支预测器，猜if条件中是True还是False，如果猜对了效率就会提高，如果猜错了，则重新计算。&lt;/p&gt;

&lt;p&gt;分支预测的关键是，预测算法能猜对多少。&lt;/p&gt;

&lt;p&gt;分支预测分为动态分支预测和静态分支预测。动态预测在执行过程中统计了通过率，根据通过率去调整预测方向，静态则始终以一个值作为判断标准。动态预测有好几种，最常见的是双模预测，通过四个状态位来动态调整预测结果。其它常见分支预测器如两级自适应预测器，局部/全局分支预测器，融合分支预测器，Agree预测期，神经分支预测器等。&lt;/p&gt;

&lt;h2 id=&quot;cpu原理小结&quot;&gt;CPU原理小结&lt;/h2&gt;

&lt;p&gt;（CPU抽象元件图）&lt;/p&gt;

&lt;p&gt;现在我们知道了CPU指令周期的工作方式，分为三个步骤，取指、译码、运算。运算后需要寄存器和高速缓存来作为存储器，CPU会从内存中获取指令并最终将数据写入内存。&lt;/p&gt;

&lt;p&gt;我们把CPU中的元件抽象成，取指和译码元件、逻辑运算元件、数据缓存，就有了上面这幅简单抽象的CPU结构图。&lt;/p&gt;

&lt;p&gt;下面我们来看看硬件上的元器件是如何分布的：&lt;/p&gt;

&lt;p&gt;（CPU硬件结构图：来源网络）&lt;/p&gt;

&lt;p&gt;我们看到CPU除了基本的控制器、运算器、寄存器、高速缓存外，还额外放置了乱序执行器、分支预测器、内存预装载器等用于提高CPU效率。这些元器件全部加起来，整个就是一个CPU Core。&lt;/p&gt;

&lt;p&gt;（多核架构图：来源网络）&lt;/p&gt;

&lt;p&gt;实际的设备中通常由多个CPU Core组成多核的架构，每个CPU Core都有自己的高速缓存L1，不同CPU Core之间也有共享的高速缓存L2，通常每级缓存的存取速度有10倍的差距，而内存的存取速度比高速缓存差的更多，对于CPU Core来说可以认为它是一个外部存储设备，通过桥接芯片连接。&lt;/p&gt;

&lt;p&gt;GPU硬件结构与原理&lt;/p&gt;

&lt;p&gt;前面介绍了CPU的内部结构，现代无论是手机还是PC机基本都是多核的，每个核就是1个CPU Core，每个CPU Core里都有取指器和译码器，还有逻辑运算器，以及寄存器和高速缓存。除了上述基本元件外还有其他元器件用于优化CPU执行效率，包括乱序执行器、分支预测器、内存预装载器等。&lt;/p&gt;

&lt;p&gt;GPU图形管线的变迁&lt;/p&gt;

&lt;p&gt;我们从GPU历史里知道，原本显卡只是一个数据传输和画面转换接口，在不断的变革下成了主板上一个独立的芯片，之后就有了GPU的概念。CPU将数据传输到显存再通知GPU处理这些数据，GPU则拥有图形图像的处理流水线，专门处理图像。&lt;/p&gt;

&lt;p&gt;起初图形的顶点、片元都在CPU上计算，到了Voodoo FX显卡时已经将图元生成后的步骤拆分到了GPU上，最后再将顶点处理部分的计算合入到GPU上，此时GPU才真正形成了自己的图形管线。如下图：&lt;/p&gt;

&lt;p&gt;（图形计算管线变迁1-1982年前的纯2D时代）&lt;/p&gt;

&lt;p&gt;1982年前，CPU承担大部分的工作，当时还没有GPU的概念，还只能以显示适配器的名称称呼。&lt;/p&gt;

&lt;p&gt;（图形计算管线变迁2-1996年3dfx Voodoo）&lt;/p&gt;

&lt;p&gt;到1996年，GPU已经可以分担CPU的部分功能，只留下顶点处理部分部分给CPU。&lt;/p&gt;

&lt;p&gt;（图形计算管线变迁3-1998年GeForce）&lt;/p&gt;

&lt;p&gt;到1998年，所有顶点处理和片元处理都由GPU来完成了，但没有可编程部分，管线是固定的，传入顶点后无法控制顶点和片元的变化。&lt;/p&gt;

&lt;p&gt;（图形计算管线变迁4-2002年GeForce FX）&lt;/p&gt;

&lt;p&gt;到2002年，正式加入了可编程着色器，让顶点和片元的计算和展示有了更多变化。&lt;/p&gt;

&lt;p&gt;（图形计算管线变迁5-2006年GeForce 8800）&lt;/p&gt;

&lt;p&gt;到2006年，GPU管线中又增加了细分着色器，pre-Z等节点。&lt;/p&gt;

&lt;p&gt;这部分历史我们也可以通过OpenGL的功能变化来看这段历史的发展过程。&lt;/p&gt;

&lt;p&gt;（来源 wiki）&lt;/p&gt;

&lt;p&gt;1.1 1997 年 3 月，纹理对象，顶点数组&lt;/p&gt;

&lt;p&gt;1.2 1998 年 3 月，3D 纹理、BGRA 和打包像素格式&lt;/p&gt;

&lt;p&gt;1.2.1 1998年10月，ARB 扩展概念&lt;/p&gt;

&lt;p&gt;1.3 2001 年 8 月，多重纹理、多重采样、纹理压缩&lt;/p&gt;

&lt;p&gt;1.4 2002 年 7 月，深度图，GLSlang&lt;/p&gt;

&lt;p&gt;1.5 2003 年 7 月，顶点缓冲对象 (VBO)，遮挡查询&lt;/p&gt;

&lt;p&gt;2.0 2004 年 9 月， GLSL 1.1，MRT，两个纹理的非幂，点精灵，双面模板&lt;/p&gt;

&lt;p&gt;2.1 2006 年 7 月 ，GLSL 1.2，像素缓冲对象 (PBO)，sRGB 纹理&lt;/p&gt;

&lt;p&gt;3.0 2008 年 8 月 ，GLSL 1.3，纹理数组，条件渲染，帧缓冲对象 (FBO)&lt;/p&gt;

&lt;p&gt;3.1 2009 年 3 月， GLSL 1.4，Instancing，纹理缓存对象，统一缓存对象，图元重启&lt;/p&gt;

&lt;p&gt;3.2 2009 年 8 月， GLSL 1.5，几何着色器，多重采样纹理&lt;/p&gt;

&lt;p&gt;3.3 2010 年 3 月， GLSL 3.30，从 OpenGL 4.0 规范向后移植尽可能多的功能&lt;/p&gt;

&lt;p&gt;4.0 2010 年 3 月， GLSL 4.00，GPU 上的曲面细分，具有 64 位精度的着色器&lt;/p&gt;

&lt;p&gt;4.1 2010 年 7 月， GLSL 4.10，开发人员友好的调试输出，与 OpenGL ES 2.0 的兼容性&lt;/p&gt;

&lt;p&gt;4.2 2011 年 8 月， GLSL 4.20，带原子计数器的着色器，绘制传输给Feed back实例，着色器打包，性能改进&lt;/p&gt;

&lt;p&gt;4.3 2012 年 8 月， GLSL 4.30，利用 GPU 并行性的计算着色器、着色器存储缓冲区对象、高质量 ETC2/EAC 纹理压缩、增强的内存安全性、多应用程序稳健性扩展、与 OpenGL ES 3.0 的兼容性&lt;/p&gt;

&lt;p&gt;4.4 2013 年 7 月， GLSL 4.40，缓冲区放置控制，高效异步查询，着色器变量布局，高效多对象绑定，Direct3D 应用程序的流线型移植，无绑定纹理扩展，稀疏纹理扩展&lt;/p&gt;

&lt;p&gt;4.5 2014 年 8 月， GLSL 4.50，直接状态访问 (DSA)，刷新控制，鲁棒性，OpenGL ES 3.1 API 和着色器兼容性，DX11 仿真功能&lt;/p&gt;

&lt;p&gt;4.6 2017 年 7 月， GLSL 4.60，更高效的几何处理和着色器执行，更多信息，无错误上下文，多边形偏移钳位，SPIR-V，各向异性过滤&lt;/p&gt;

&lt;p&gt;经过显卡历史、GPU管线的变化历史、OpenGL的功能变迁史，让我们把GPU看的更清楚。&lt;/p&gt;

&lt;h2 id=&quot;gpu-core结构&quot;&gt;GPU Core结构&lt;/h2&gt;

&lt;p&gt;我们知道现代的 CPU 里除了基本的元器件外，还有许多围绕提高执行效率的元器件，以及增加诸多功能的其他元器件。这些元器件在 GPU 里有点多余了，GPU 的整个处理过程是一个流式处理过程，没有那么多分支条件，以及复杂的依赖关系。&lt;/p&gt;

&lt;p&gt;因此我们可以把 GPU 里这些对应的元器件去掉，只留下取指令、指令译码、ALU 以及执行这些计算需要的寄存器和缓存。如图：&lt;/p&gt;

&lt;p&gt;（GPU元器件瘦身图）&lt;/p&gt;

&lt;p&gt;这样看来GPU core比CPU Core的构造简单的多了，由于传输GPU的数据并不相互依赖的，因此我们可以用很多个GPU Core来并行计算这些数据。&lt;/p&gt;

&lt;p&gt;于是就有了，多GPU Core的结构，如下图：&lt;/p&gt;

&lt;p&gt;（多个Core并行工作图）&lt;/p&gt;

&lt;p&gt;多个Core并行工作时它们使用了相同的取指器并且有相同的代码，为什么不把它们并起来呢。&lt;/p&gt;

&lt;p&gt;前面我们说过SIMD，它把4个数据一起提交并用一个指令执行它完成计算。在GPU中借鉴了SIMD，用了一种跟它很像的处理技术叫做SIMT（Single Instruction Multiple Threads），如下图：&lt;/p&gt;

&lt;p&gt;（ 单指令多数据流管线）&lt;/p&gt;

&lt;p&gt;在SIMT中，向GPU Core输入的是8个图元或片元，同时输出8个结果，每次输入多个数据到GPU Core中，并获得多个结果。SIMT 比 SIMD 更加灵活。&lt;/p&gt;

&lt;p&gt;SIMT可以把多条数据，交给不同的线程去处理。各个线程里面执行的指令流程是一样的，但是可能根据数据的不同，走到不同的条件分支。这样，相同的代码和相同的流程，可能执行不同的具体的指令。这个线程走到的是 if 的条件分支，另外一个线程走到的就是 else 的条件分支了。&lt;/p&gt;

&lt;h2 id=&quot;gpu的分支处理&quot;&gt;GPU的分支处理&lt;/h2&gt;

&lt;p&gt;我们CPU有对分支做预测，让流水线停顿更少，GPU Core也会对分支做优化处理。&lt;/p&gt;

&lt;p&gt;（GPU的分支处理）&lt;/p&gt;

&lt;p&gt;常用的GPU分支处理SIMD里，为每个指令都分配一个ALU做并行处理，用多个周期分别计算分支的两种结果。&lt;/p&gt;

&lt;p&gt;这样做就不会让流水线停滞，但是这样做有效率问题，在一个指令周期里，很多ALU是闲置的。&lt;/p&gt;

&lt;p&gt;因此在SIMD之后，SIMT（Single Instruction，Multiple Threads）技术可以变相的做分支的顺序执行，如下图：&lt;/p&gt;

&lt;p&gt;（SIMT 分支预测并行计算）&lt;/p&gt;

&lt;p&gt;在SIMT中，各个线程里面执行的指令流程是一样的，只是走的不同的分支。相同的代码和相同的流程，执行不同的分支。
可能一些线程走到的是 if 的条件分支，而另外一些线程走到的就是 else 的条件分支，这种并行计算使得计算本身无需依赖上文，也让ALU不再空闲停滞。&lt;/p&gt;

&lt;p&gt;这里简单说下解决SIMIT流水线中的卡顿问题&lt;/p&gt;

&lt;p&gt;拆分存储缓存，让上下文依赖的计算在不同时段同时计算，以提高ALU的利用率。&lt;/p&gt;

&lt;p&gt;（卡顿时启动另一条管线）&lt;/p&gt;

&lt;p&gt;（拆分整个缓存为独立缓存）&lt;/p&gt;

&lt;p&gt;GPU为了不等待分支条件而导致的停顿流水线，就要对每个分支做都做计算。分支内的数据仍然会有依赖关系，依赖关系就会造成卡顿，需要等待计算或等待获取资源。&lt;/p&gt;

&lt;p&gt;因此将原来的一整个缓存，拆分为多个缓存，使得流水线在阻塞时能更好的使用闲置ALU计算下一条数据。这样就能更好的利用ALU计算做优化了。&lt;/p&gt;

&lt;p&gt;现实GPU硬件中的物理架构&lt;/p&gt;

&lt;p&gt;前面我们说的都是抽象的GPU Core结构，下面我们来看下实际中的GPU物理架构。&lt;/p&gt;

&lt;p&gt;看到这些GPU架构可以发现它们虽然彼此有差异，但很多概念相同，下面我们俩理清一下这些架构中组建的概念：&lt;/p&gt;

&lt;p&gt;GPC（Graphics Processing Cluster） ： 图形处理集群，GPU划分多个GPC，每个GPC里有多个TPC，每个TPC里包含了多个SM和1个Rester Engine&lt;/p&gt;

&lt;p&gt;TPC（Texture Processing Cluster） ： 图像处理集群，是由若干个SM、1个纹理单元（Texture Unit）和一些逻辑控制和ALU组成。&lt;/p&gt;

&lt;p&gt;RT Core（Ray Trace Core） ： RT Core是SM里面加了一条专用的流水线(ASIC)来计算射线和三角形求交（可以访问BVH，用于光线追踪）。由于是ASIC专用电路逻辑，与shader code做求交计算相比，性能有数量级的提升。&lt;/p&gt;

&lt;p&gt;Rester Engine ： 光栅引擎，处理它接收到的三角形，并为它负责的那些部分生成像素信息（也处理背面剔除和 Z 剔除）。&lt;/p&gt;

&lt;p&gt;PolyMorp Engine：曲面引擎，是一个带有顶点提取器、视口变换的累积集群，它处理属性设置和流输出，这些都合并到了这个处理器中，极大地扩展了曲面细分和（当发送到光栅引擎时）光栅化性能。&lt;/p&gt;

&lt;p&gt;Thread Engine：线程引擎，调度线程到核的引擎&lt;/p&gt;

&lt;p&gt;SM（Stream Multiprocessor）、SMX、SMM ：SM包含GPU Core内核，指令单位，调度程序。&lt;/p&gt;

&lt;p&gt;Warp Scheduler、Dispatch Unit：负责线程束调度，将软件线程按一捆一捆（不是一个一个）的方式分配到计算核上。一个Warp由32个线程组成，Warp Scheduler的指令通过Dispatch Units派送到Core核上执行。&lt;/p&gt;

&lt;p&gt;SP（Streaming Processors）、Core ：SP有时也叫CUDA core，一个 SP 包括多个 ALU 和 FPU。SP是作用于顶点或像素数据的真正处理单元。&lt;/p&gt;

&lt;p&gt;ALU（Arithmetic Logic Unit）、FPU（Float Point Unit）：ALU 是算术和逻辑单元，FPU 是浮点单元。&lt;/p&gt;

&lt;p&gt;INT32，FP32 ：在GPU里支持单精度运算的Single Precision ALU称之为FP32 core或简称core，而把双精度运算的Double Precision ALU称之为DP unit或者FP64 core。第三代的Kepler架构里，FP64单元和FP32单元的比例是高端机1:3或者低端机1:24，到了第五代比例为1:2，低端型号里仍然保持为1:32。&lt;/p&gt;

&lt;p&gt;SFU（Special Function Unit）：执行特殊数学运算（sin、cos、log等）&lt;/p&gt;

&lt;p&gt;TENSO CORE ： 精度混合计算单元，转换不同精度之间的运算结果，用于执行矩阵乘法的计算单元，精度混合分为整数精度和浮点数精度。&lt;/p&gt;

&lt;p&gt;ROP（Render Output Unit） ：渲染输出单元 ，一个ROP内部有很多ROP单元，在ROP单元中有深度测试和Framebuffer混合，深度和颜色的设置必须是原子操作，否则两个不同的三角形在同一个像素点就会有冲突和错误。&lt;/p&gt;

&lt;p&gt;LD/ST（Load/Store Unit）：加载和存储数据&lt;/p&gt;

&lt;p&gt;Share Memory、L1 Data Cache、L1 Cache、L2 Cache ：共享内存，以及多级的高速缓存&lt;/p&gt;

&lt;p&gt;RF（Register File）：寄存器堆，多个寄存器组成的阵列&lt;/p&gt;

&lt;p&gt;Instruction Cache ：指令缓存&lt;/p&gt;

&lt;p&gt;未完待续…&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《How Shader Cores Work》&lt;/p&gt;

&lt;p&gt;https://engineering.purdue.edu/~smidkiff/KKU/files/GPUIntro.pdf&lt;/p&gt;

&lt;p&gt;《CPU体系结构》&lt;/p&gt;

&lt;p&gt;https://my.oschina.net/fileoptions/blog/1633021&lt;/p&gt;

&lt;p&gt;《深入理解CPU的分支预测(Branch Prediction)模型》&lt;/p&gt;

&lt;p&gt;https://zhuanlan.zhihu.com/p/22469702&lt;/p&gt;

&lt;p&gt;《分析Unity在移动设备的GPU内存机制（iOS篇）》&lt;/p&gt;

&lt;p&gt;https://www.jianshu.com/p/68b41a8d0b37&lt;/p&gt;

&lt;p&gt;《针对移动端TBDR架构GPU特性的渲染优化》&lt;/p&gt;

&lt;p&gt;https://gameinstitute.qq.com/community/detail/123220&lt;/p&gt;

&lt;p&gt;《A look at the PowerVR graphics architecture: Tile-based rendering》&lt;/p&gt;

&lt;p&gt;https://www.imaginationtech.com/blog/a-look-at-the-powervr-graphics-architecture-tile-based-rendering/&lt;/p&gt;

&lt;p&gt;《A look at the PowerVR graphics architecture: Deferred rendering》&lt;/p&gt;

&lt;p&gt;https://www.imaginationtech.com/blog/the-dr-in-tbdr-deferred-rendering-in-rogue/&lt;/p&gt;

&lt;p&gt;《深入GPU硬件架构及运行机制》&lt;/p&gt;

&lt;p&gt;https://www.cnblogs.com/timlly/p/11471507.html&lt;/p&gt;

&lt;p&gt;《深入浅出计算机组成原理》&lt;/p&gt;

&lt;p&gt;https://time.geekbang.org/column/article/105401?code=7VZ-Md9oM7vSBSE6JyOgcoQhDWTOd-bz5CY8xqGx234%3D&lt;/p&gt;

&lt;p&gt;《Nvidia Geforce RTX-series is born》&lt;/p&gt;

&lt;p&gt;https://www.fudzilla.com/reviews/47224-nvidia-geforce-rtx-series-is-born?start=2&lt;/p&gt;

&lt;p&gt;《渲染管线与GPU（Shading前置知识）》&lt;/p&gt;

&lt;p&gt;https://zhuanlan.zhihu.com/p/336999443&lt;/p&gt;

&lt;p&gt;《剖析虚幻渲染体系（12）- 移动端专题Part 1（UE移动端渲染分析）》&lt;/p&gt;

&lt;p&gt;https://www.cnblogs.com/timlly/p/15511402.html&lt;/p&gt;

&lt;p&gt;《tpc-texture-processing-cluster》&lt;/p&gt;

&lt;p&gt;https://gputoaster.wordpress.com/2010/12/11/tpc-texture-processing-cluster/&lt;/p&gt;

&lt;p&gt;《Life of a triangle - NVIDIA’s logical pipeline》&lt;/p&gt;

&lt;p&gt;https://developer.nvidia.com/content/life-triangle-nvidias-logical-pipeline&lt;/p&gt;

&lt;p&gt;《Rasterisation wiki》&lt;/p&gt;

&lt;p&gt;https://en.wikipedia.org/wiki/Rasterisation&lt;/p&gt;

&lt;p&gt;《PolyMorph engine and Data Caches by Hilbert Hagedoorn》&lt;/p&gt;

&lt;p&gt;https://www.guru3d.com/articles-pages/nvidia-gf100-(fermi)-technology-preview,3.html&lt;/p&gt;

&lt;p&gt;《NVIDIA GPU的一些解析》&lt;/p&gt;

&lt;p&gt;https://zhuanlan.zhihu.com/p/258196004&lt;/p&gt;

&lt;p&gt;《tensor-core-performance-the-ultimate-guide》&lt;/p&gt;

&lt;p&gt;https://developer.download.nvidia.cn/video/gputechconf/gtc/2019/presentation/s9926-tensor-core-performance-the-ultimate-guide.pdf&lt;/p&gt;

&lt;p&gt;《Understanding the Understanding the graphics pipeline》&lt;/p&gt;

&lt;p&gt;https://www.seas.upenn.edu/~cis565/LECTURES/Lecture2%20New.pdf&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU1ODY1ODY2NA==&amp;amp;mid=2247485051&amp;amp;idx=1&amp;amp;sn=e98f1e1971d56ce6543926b4f9bad204&amp;amp;chksm=fc22637ccb55ea6a4c16c5c0d8fd43cff936350490d79f1e377b61e4914300c39c4fc2911da1&amp;amp;token=53415989&amp;amp;lang=zh_CN#rd&quot;&gt;已发布在微信公众号上，点击跳转&lt;/a&gt;&lt;/p&gt;

</description>
               <pubDate>Mon, 22 Nov 2021 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2021/11/22/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B050</link>
               <guid isPermaLink="true">http://www.luzexi.com/2021/11/22/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B050</guid>
            </item>
        
            <item>
               <title>读书笔记(四十八) 《游戏引擎架构》#4 低阶渲染器（2）</title>
               <description>&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU1ODY1ODY2NA==&amp;amp;mid=2247484981&amp;amp;idx=1&amp;amp;sn=b5199f84ed73d28916dbb9143eeeb992&amp;amp;chksm=fc226332cb55ea2417b89e499284ab3a552ce591caba09d637912306503e4b457ed45c2e1d2d&amp;amp;token=1023740201&amp;amp;lang=zh_CN#rd&quot;&gt;已发布在微信公众号上，点击跳转&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;背景&quot;&gt;背景：&lt;/h2&gt;

&lt;p&gt;作为游戏开发从业者，从业务到语言到框架到引擎，积累了一些知识和经验，特别是在看了几遍《游戏引擎架构》后对引擎架构的理解又深入了些。&lt;/p&gt;

&lt;p&gt;近段时间有对引擎剖析的想法，正好借这书本对游戏引擎架构做一个完整分析。&lt;/p&gt;

&lt;p&gt;此书用简明、清楚的方式覆盖了游戏引擎架构的庞大领域，巧妙地平衡了广度与深度，并且提供了足够的细节。&lt;/p&gt;

&lt;p&gt;借助《游戏引擎架构》这本书、结合引擎源码和自己的经验，深入分析游戏引擎的历史、架构、模块，最后通过实践简单引擎开发来完成对引擎知识的掌握。&lt;/p&gt;

&lt;p&gt;游戏引擎知识面深而广，所以对这系列的文章书编写范围做个保护，即不对细节进行过多的阐述，重点剖析的是架构、流程以及模块的运作原理。&lt;/p&gt;

&lt;p&gt;同时《游戏引擎架构》中部分知识太过陈旧的部分，会重新深挖后总结出自己的观点。&lt;/p&gt;

&lt;h2 id=&quot;概述&quot;&gt;概述：&lt;/h2&gt;

&lt;p&gt;本系列文章对引擎中的重要的模块和库进行详细的分析，我挑选了十五个库和模块来分析：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;时间库&lt;/li&gt;
  &lt;li&gt;自定义容器库&lt;/li&gt;
  &lt;li&gt;字符串散列库&lt;/li&gt;
  &lt;li&gt;内存管理框架&lt;/li&gt;
  &lt;li&gt;RTTI与反射模块&lt;/li&gt;
  &lt;li&gt;图形计算库&lt;/li&gt;
  &lt;li&gt;资产管理模块&lt;/li&gt;
  &lt;li&gt;低阶渲染器&lt;/li&gt;
  &lt;li&gt;剔除与合批模块&lt;/li&gt;
  &lt;li&gt;动画模块&lt;/li&gt;
  &lt;li&gt;物理模块&lt;/li&gt;
  &lt;li&gt;UI底层框架&lt;/li&gt;
  &lt;li&gt;性能剖析器的核心部分&lt;/li&gt;
  &lt;li&gt;脚本系统&lt;/li&gt;
  &lt;li&gt;视觉效果模块&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;本篇内容为列表中的第8个部分的第1节。&lt;/p&gt;

&lt;h2 id=&quot;正文&quot;&gt;正文：&lt;/h2&gt;

&lt;p&gt;简单回顾下前文&lt;/p&gt;

&lt;p&gt;前文我们聊了下显卡在计算机硬件主板中的位置与结构，知道了CPU、GPU的通信介质，并简单介绍了手机上的主板结构。本篇开头对上一篇做一些内容补充，PC和手机的不同硬件组织，以及CPU与其他芯片的通信过程。&lt;/p&gt;

&lt;p&gt;下面我们开始这篇内容&lt;/p&gt;

&lt;h3 id=&quot;本次内容会围绕gpu来写从硬件架构到软件驱动再到引擎架构目标是帮大家理解gpu硬件的运作原理理解图形接口的架构理解引擎低阶渲染器的架构&quot;&gt;本次内容会围绕GPU来写，从硬件架构到软件驱动再到引擎架构，目标是帮大家理解GPU硬件的运作原理，理解图形接口的架构，理解引擎低阶渲染器的架构。&lt;/h3&gt;

&lt;p&gt;目录：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;主板结构中的显卡&lt;/li&gt;
  &lt;li&gt;GPU功能发展史&lt;/li&gt;
  &lt;li&gt;GPU与CPU的差异&lt;/li&gt;
  &lt;li&gt;GPU硬件特点&lt;/li&gt;
  &lt;li&gt;图形驱动程序架构&lt;/li&gt;
  &lt;li&gt;引擎低阶渲染架构&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;继续上篇未结束的内容&lt;/p&gt;

&lt;p&gt;说硬件结构时，我们常常从台式 PC 开始说起，因为智能手机本质上是袖珍型计算机，具有一些额外的无线电，并且在功耗、热量输出等方面极其受限的条件下运行。PC 主要由主板芯片组组成（通常分为连接处理器和内存“北桥”（例如 Intel 的 P45）和连接各种外围总线（例如 PCI-Express、USB 等）的“南桥”（例如 Intel 的 ICH10R） )、中央处理器（例如 CPU – Intel 的 Core 2 Duo）、随机存储器内存 (RAM)、永久存储器（硬盘或固态硬盘）、图形处理单元（例如 GPU – ATI 的 Radeon HD5890） 、电源和多个连接到 PCI 或 PCI-Express 总线的外围设备（例如，内置声音芯片组或附加 Wi-Fi 卡）。&lt;/p&gt;

&lt;p&gt;（三星手机拓扑图：图片来源网络）&lt;/p&gt;

&lt;p&gt;（iPhone6p A8 正面图：图片来源网络）&lt;/p&gt;

&lt;p&gt;（iPhone6p A8 背面图：图片来源网络）&lt;/p&gt;

&lt;p&gt;（苹果A8芯片内部结构：图片来源网络）&lt;/p&gt;

&lt;p&gt;智能手机也具有所有这些组件，只是集成度更高而已。一些主要芯片通常可以包含 CPU、GPU、其他专用协处理器、主板总线、内存控制器、LCD 控制器、声音芯片组、CMOS 摄像头接口、板载内存 ，以及一些外围设备（例如 Cell、Wifi 和蓝牙无线电）。 “应用处理器”是负责一般处理的芯片（类似于 CPU + 主板芯片组），并且可能内置了一些其他功能。 “基带处理器”负责蜂窝无线通信。&lt;/p&gt;

&lt;p&gt;智能手机与 PC 如此相似，那么为什么我们今天在智能手机中看不到像 Core 2 Duo 这样的 x86 CPU？答案是，Core 2 Duo 消耗的功率和产生的热量远远超出手机的可接受范围。典型的台式机 Core 2 Duo CPU 的功耗最高可达 65W，并且需要一个主动冷却系统来防止过热。即使是英特尔的 Atom 芯片也消耗 4W（峰值 TDP），而整个手机通常必须满足低于 1W 的功率。&lt;/p&gt;

&lt;p&gt;今天我们很多智能手机都使用 ARM 芯片， ARM 的运作方式与Intel截然不同。 Intel 自己设计和构建所有处理器，而 ARM 则创建指令集，任何跟随它们的 CPU 都将能够运行与 ARM 兼容的代码。 它还为适合其指令集的处理器创建参考设计，这使公司能够围绕 ARM 的核心设计轻松生产自己的芯片组。 一些公司，如英伟达、三星和德州仪器，只是简单地许可并采用 ARM CPU 参考设计，而其他公司，如高通和 Marvell，只许可指令集并创建自己的处理器以适应它们。 第一个 ARMv7 参考设计是 Cortex A8，其架构可在今天的智能手机中找到。很久以前低端智能手机倾向于使用实现 ARMv6 指令集的 ARM11 芯片，现在已经不复存在。&lt;/p&gt;

&lt;p&gt;这里再补充一下前文的硬件通信过程，每个带有处理程序的硬件都有自己的芯片，CPU是整个电脑的主要计算芯片，GPU则被单独拆分出来作为图像的处理芯片，除了这两个大家熟知的芯片，还有内存芯片，硬盘芯片，声卡芯片，网卡芯片等，这些芯片都通过总线进行数据交互。其中前面我们提到南桥和北桥芯片桥接了快慢不同的芯片之间的通信，让不同种类的设备通信效率更高更有序。&lt;/p&gt;

&lt;p&gt;（PC端CPU与GPU通信结构图）&lt;/p&gt;

&lt;p&gt;（手机端CPU与GPU通信结构图）&lt;/p&gt;

&lt;h3 id=&quot;cpu与其他芯片之间的通信步骤可以简单理解为cpu通过总线发送指令数据到其他芯片芯片收到指令并处理后再通过总线将反馈数据给cpu中间处理过程也会与内存芯片或其他芯片通信后再反馈给cpu&quot;&gt;CPU与其他芯片之间的通信步骤，可以简单理解为，CPU通过总线发送指令数据到其他芯片，芯片收到指令并处理后，再通过总线将反馈数据给CPU，中间处理过程也会与内存芯片或其他芯片通信后再反馈给CPU。&lt;/h3&gt;

&lt;p&gt;（CPU用虚拟地址访问内存拓扑图）&lt;/p&gt;

&lt;h3 id=&quot;cpu-在访问内存时需要通过-mmu-把虚拟地址转化为物理地址再通过总线访问内存mmu-开启后-cpu-看到的所有地址都是虚拟地址cpu-把这个虚拟地址发给-mmu-后mmu-会在页表里查出这个虚拟地址对应的物理地址再通过总线去访问ddr内存芯片&quot;&gt;CPU 在访问内存时需要通过 MMU 把虚拟地址转化为物理地址，再通过总线访问内存。MMU 开启后 CPU 看到的所有地址都是虚拟地址，CPU 把这个虚拟地址发给 MMU 后，MMU 会在页表里查出这个虚拟地址对应的物理地址，再通过总线去访问DDR内存芯片。&lt;/h3&gt;

&lt;p&gt;从这个芯片通信角度看，我们可以明白，总线传输数据的速度，限制了计算机的运行速度。因此我们在优化计算机程序时会常常去减少CPU与GPU之间通信量，原因就是在无法增加带宽上限这个大前提下，尽量减少它们之间通信数据量，从而减少访问消耗时间。&lt;/p&gt;

&lt;h2 id=&quot;gpu功能发展史&quot;&gt;GPU功能发展史&lt;/h2&gt;

&lt;p&gt;第一篇中我们介绍过一些图形接口的发展历史，现在我们来介绍一下GPU硬件的发展历史。硬件的发展史其实是一个商业的竞争过程，中间夹杂着很多商业战略与决策。尤其是当大家都看到GPU这块高新的技术’蛋糕’，有一系列公司参与进来相互竞争。因此这里不过多的介绍商业上的活动与竞争，而是专注于介绍GPU功能的发展过程。&lt;/p&gt;

&lt;p&gt;第一个真正的3D图形卡始于早期的显示控制器，即视频移位器和视频地址生成器（video shifters and video address generators）。它们充当主处理器和显示器之间的直通通道（pass-through）。传入的数据流被转换为串行位图视频输出，例如亮度，颜色以及垂直和水平复合同步，这将像素行保持在显示生成中，并同步每条连续行以及消隐间隔（时间间隔为 结束一条扫描线并开始下一条扫描线）。&lt;/p&gt;

&lt;p&gt;（图片来源网络）&lt;/p&gt;

&lt;p&gt;1970年代开始这些视频适配器出现了一系列的改进，主要兼容了不同分辨率以及不同的视频信号。&lt;/p&gt;

&lt;p&gt;1976年，ANTIC使用直接存储器访问（DMA）处理2D显示指令。&lt;/p&gt;

&lt;p&gt;1978年，英特尔82720图形卡芯片，它能够以256x256的分辨率（或以512x512的单色）显示八种颜色数据。其32KB的显示内存足以绘制线，弧，圆，矩形和字符位图。该芯片还提供了缩放，屏幕分区和滚动的功能。&lt;/p&gt;

&lt;p&gt;1979年，SGI推出了用于工作站的IRIS图形卡-GR1.x图形卡板，其中提供了用于颜色选项，几何图形卡，Z缓冲区和覆盖/底层的单独的外接（子）板。&lt;/p&gt;

&lt;p&gt;从第一块图形卡发明到现在，整个过程可以分为，视频适配器时代，2D时代、3D时代启程、3D时代崛起、3D时代巅峰，这4个部分。&lt;/p&gt;

&lt;p&gt;为此我画了一副时序图并标出了重要节点，便于大家理解显卡的发展史，同时以文字形式告知大家图形显卡的发展历史。&lt;/p&gt;

&lt;p&gt;（显卡发展史）&lt;/p&gt;

&lt;h2 id=&quot;2d时代&quot;&gt;2D时代&lt;/h2&gt;

&lt;p&gt;1981年, IBM推出了个人电脑时，它提供了两种显卡，一种是“单色显卡”(简称 MDA), 一种是 “彩色绘图卡” (简称 CGA), 从名字上就可以看出，MDA是与单色显示器配合运用的, 它可以显示80行x25列的文数字, CGA则可以用在RGB的显示屏上, 它可以绘制的图形和文数字资料。&lt;/p&gt;

&lt;p&gt;1982年，IBM又推出了MGA（Monochrome Graphic Adapter）, 又称Hercules Card (大力士卡),  除了能显示图形外，还保留了原来 MDA 的功能。&lt;/p&gt;

&lt;p&gt;这些显卡均为采纳使用数字方式的，直到MCGA（Multi-Color Graphics Array）的出现，才揭开了采纳使用模拟方式的显卡的序幕。MCGA是整合在 PS/2 Model 25和30上的影像系统。它采纳使用了Analog RGA影像信号, 解析度可高达640x480, 数位RGB和类比RGB不同的的方就像是ON-OFF式切换和微调式切换之间的差别。&lt;/p&gt;

&lt;p&gt;1986年ATI推出了第一款产品，即OEM颜色仿真卡。它用于通过9针DE-9连接器将黑色背景的单色绿色，琥珀色或白色磷光体文本输出到TTL监视器，该卡至少配备了16KB的内存。&lt;/p&gt;

&lt;p&gt;1987年，ATI在其OEM产品线中增加了Graphics Solution Plus系列，该产品线将IBM PC / XT ISA 8位总线用于基于Intel 8086/8088的IBM PC。该芯片通过DIP开关支持MDA，CGA和EGA图形卡模式。ATI EGA 800：16色VGA仿真，支持800x600。&lt;/p&gt;

&lt;p&gt;VGA（Video Graphic Array）即显示绘图阵列，它IBM是在其 PS/2 的Model 50, 60和80内建的影像系统。它的数字模式可以达到720x400色, 绘图模式则可以达到640x480x16色, 以及320x200x256色，这是显卡首次可以相应情况下最大限度显示256种色彩，而这些模式更成为其后所有显卡的共同标准。&lt;/p&gt;

&lt;p&gt;1988年，带有游戏控制器端口和复合输出选项的Small Wonder Graphics解决方案问世（用于CGA和MDA仿真），以及具有扩展EGA和16位VGA支持的EGA Wonder 480和800+，以及VGA 新增了VGA和SVGA支持的Wonder和Wonder 16。&lt;/p&gt;

&lt;p&gt;1988年，Trident 8900/9000显卡，它第一次使显卡成为一个独立的配件出现在电脑里，而不再是集成的一块芯片。而后其推出的Trident 9685更是第一代3D显卡的代表。不过真正称得上开启3D显卡大门的却应该是1996年的GLINT 300SX，虽然当时其3D功能非常简单，却具有里程碑的意义。&lt;/p&gt;

&lt;p&gt;1989年推出了更新的VGA Wonder / Wonder 16系列，其中包括降低成本的VGA Edge 16（Wonder 1024系列）。新功能包括一个总线鼠标端口，并支持VESA功能连接器。这是一个金手指连接器，类似于缩短的数据总线插槽连接器，它通过带状电缆链接到另一个视频控制器，以绕过拥挤的数据总线。&lt;/p&gt;

&lt;p&gt;1991年，Wonder系列的更新继续向前发展。WonderXL卡增加了VESA 32K颜色兼容性和Sierra RAMDAC，从而将最大显示分辨率提高到640x480 @ 72Hz 或 800x600 @ 60Hz。&lt;/p&gt;

&lt;p&gt;1991年5月，ATI的Mach系列与Mach8一同推出。它以芯片或电路板的形式出售，可以通过编程接口（AI）卸载有限的2D绘图操作，例如线条画，颜色填充和位图组合（Bit BLIT）.ATI添加了Wonder的一种变体 XL在扩展PCB上集成了Creative Sound Blaster 1.5芯片。它被称为VGA Stereo-F / X，它能够模拟Sound Blaster单声道文件中的立体声，并且其质量接近FM广播质量。ATI图形卡Ultra ISA（Mach8 + VGA）,将Mach8与VGA Wonder +的图形卡核心（28800-2）结合在一起以实现其3D功能。&lt;/p&gt;

&lt;p&gt;1992年1月，Silicon Graphics Inc（SGI）发布了OpenGL 1.0，这是一个针对2D和3D图形卡的多平台供应商不可知的应用程序编程接口（API）。OpenGL是从SGI专有的API（称为IRIS GL（集成的栅格成像系统图形卡库））演变而来的。最初，OpenGL瞄准的是基于UNIX的专业市场，但是由于开发人员对扩展实施的友好支持，很快将其用于3D游戏。同时微软正在开发自己的竞争对手Direct3D API，并没有确保OpenGL在Windows下也能正常运行。&lt;/p&gt;

&lt;p&gt;1993年11月，ATI宣布68890 PC电视解码器芯片的发布，该芯片首次在Video-It卡里面亮相。借助板载Intel i750PD VCP（视频压缩处理器），该芯片能够以320x240 @ 15 fps或160x120 @ 30 fps捕获视频，并能够实时压缩/解压缩。它还能够通过数据总线与图形卡板通信，从而无需使用加密狗或端口和带状电缆。&lt;/p&gt;

&lt;p&gt;1995年，ATI的Mach8发布，创造了许多著名的首创。它成为第一个以Xclaim形式在PC和Mac计算机上使用的图形卡适配器，并且与S3的Trio一起提供了全动态视频播放加速功能。&lt;/p&gt;

&lt;h2 id=&quot;3d时代开启&quot;&gt;3D时代开启&lt;/h2&gt;

&lt;p&gt;1995年5月，nVidia推出了他们的第一款图形卡芯片NV1，并成为首款能够进行3D渲染，视频加速和集成GUI加速的商业图形卡处理器。供应商发布显卡支持规格的主板（Diamond Edge 3D），D3D（Diamond Edge 3D）图形卡API确认依赖于渲染三角形多边形，而NV1则使用四边形纹理映射。nVidia通过驱动程序添加了有限的D3D兼容性，以将三角形包装为二次曲面，但是市面上仍然很少针对NV1量身定制的游戏。&lt;/p&gt;

&lt;p&gt;1995年11月，ATI宣布了他们的首个3D加速器芯片3D Rage（也称为Mach 64 GT）。&lt;/p&gt;

&lt;p&gt;1995年，3Dfx推出了业界的口碑极佳的3D图形加速卡：Voodoo。3Dfx的专利技术Glide引擎接口一度称霸了整个3D世界，直至D3D和OpenGL的出现才改变了这种局面。&lt;/p&gt;

&lt;p&gt;Voodoo标配为4Mb EDO显存，可以提供在640×480分辨率下3D显示速度和最华丽的画面。Voodoo也有硬伤，它只是一块具有3D加速功能的子卡，运用时需搭配一块具有2D功能的显卡，因此当时S3 765+Voodoo是为人津津乐道的黄金组合。&lt;/p&gt;

&lt;p&gt;S3 765显卡是当时兼容机的标准配置，最大限度支持2MB EDO显存，可以实现高分辨率显示，可以支持1024×768的分辨率，并且在低分辨率下支持最大限度32Bit真彩色，而且性能和价格比也较强。&lt;/p&gt;

&lt;p&gt;1995年，VideoLogic开发了一种基于图块的延迟渲染技术（TBDR），该技术在纹理、阴影和光照应用于剩下的渲染之前，抛弃了所有可见的几何形状，从而消除了对大规模z缓冲(在最终渲染中去除遮挡/隐藏的像素)的需求。这个过程产生的框架被分割成矩形块，每个图块都可以自行进行多边形渲染并发送到输出。一旦计算了帧所需的像素并剔除了多余的多边形(z缓冲只在平铺层发生)，对多边形渲染就开始了，这样就只需要进行最基本的计算。&lt;/p&gt;

&lt;p&gt;1995年，Rendition的VéritéV1000成为第一张具有可编程核心的显卡，它使用了基于MIPS的RISC处理器和Pixel Pipelines(像素管线)。处理器负责设置和组织管线的工作负载。 Vérité1000最初于1995年底开发，后来成为Microsoft用于开发Direct3D的主板之一。&lt;/p&gt;

&lt;p&gt;1996年 3DLabs 研制出Glint，该公司诞生于杜邦的Pixel图形卡部门。GLINT 300SX处理器能够进行OpenGL渲染，片段处理和光栅化。GLINT 300SX增加了2MB的内存。它为纹理和Z缓冲区使用了1MB，为帧缓冲区使用了1MB，但是还提供了一个选项，以增加VRAM的Direct3D兼容性。&lt;/p&gt;

&lt;p&gt;1997年3月ATI推出 3D Rage Pro，它在4MB格式下几乎可以媲美Voodoo Graphics的性能。在使用8MB和AGP接口时，其性能则优于3Dfx卡。它扩展了4kB高速缓存并增加了边缘抗锯齿功能，该显卡改进了Rage II的透视校正，纹理处理能力以及三线性滤波性能。还集成了一个浮点单元，以减少对CPU的依赖以及对DVD的硬件加速和显示支持。&lt;/p&gt;

&lt;p&gt;1997年4月，nVidia推出了RIVA 128（实时交互式视频和动画加速器），并通过渲染三角形多边形增加了Direct3D兼容性，使用新的350nm工艺，并开发了RAMDAC和视频转换器，这是nVidia具有里程碑意义的显卡。&lt;/p&gt;

&lt;p&gt;1998年1月，英特尔发布i740，它结合了R3D/100上两种不同的图形和纹理芯片的资源，实现了AGP纹理，纹理被上传到系统内存中(渲染缓冲区也可以存储在RAM中)。此前一些设计会选择使用显卡的帧缓冲区用来保存纹理，如果帧缓冲区饱和或纹理太大而无法存储在本地图形内存中，则纹理交换到系统RAM中。为了最大程度地减少延迟，英特尔的设计使用了AGP Direct Memory Execute（DiME）功能，该功能仅调用光栅化所需的那些纹理，其余的存储在系统RAM中。性能和图像质量可以接受的，性能大致与上一年的高端产品相匹配，因此该产品大放异彩。&lt;/p&gt;

&lt;p&gt;1998年3月，3Dfx推出Voodoo2。Voodoo2本身带有8Mb/12Mb EDO显存，PCI接口，卡上有双芯片，可以做到单周期多纹理运算。缺点是它的卡身很长，并且芯片发热量相当大，依然只作为一块3D加速子卡，需要一块2D显卡的支持。Voodoo2的推出使得3D加速又到达了一个新的里程碑，依仗Voodoo2的效果、画面和速度，征服了不少当时盛行一时的3D游戏，比如Fifa98，NBA98，Quake2等等。&lt;/p&gt;

&lt;p&gt;1998年7月，Matrox公司发布MGA G200继承了自己超一流的2D水准，3D方面有了革命性的提高，不但可以提供和Voodoo2差不多的处理速度和特技效果，另外还支持DVD硬解码和视频输出，并且独一无二的首创了128位独立双重总线技术，大大提高了性能，配合当时相当走红的AGP总线技术，G200也赢得了不少用户的喜爱。&lt;/p&gt;

&lt;p&gt;1998年的S3的野人系列Savage系列显卡，Savage3D采纳使用128位总线结构及单周期三线性多重贴图技术，最大像素填充率达到了125M Pixels/s，三角形生成速率也达到了每秒500万个。通过S3新设计的AGP引擎和S3TC纹理压缩技术，支持Direct3D与OpenGL，最大显存容量可达8MB SGRAM或SDRAM，支持AGP 4×规范。相应情况下也支持当时流行的如反射和散射、Alpha混合、多重纹理、衬底纹理、边缘抗锯齿、16/24位Z-buffering、Tri-linear Filtering（三线性过滤技术）、S3TC纹理压缩技术等技术。可惜就是受到驱动程序不兼容的严重影响，最终在99年时惨淡收场。&lt;/p&gt;

&lt;h2 id=&quot;3d时代崛起&quot;&gt;3D时代崛起&lt;/h2&gt;

&lt;p&gt;1999年2月，S3发布Savage4，成为的第一张支持多重纹理的显卡，也是第一张支持AGP 4x接口的显卡。&lt;/p&gt;

&lt;p&gt;1999年，NVidia推出TNT2 Ultra、TNT2和TNT2 M64三个版本的芯片，后来又有PRO和VANTA两个版本。这种分类方式也促使后来各个生产厂家对同一芯片进行高中低端的划分，以满足不同层次的消费需要。TNT系列配置了8Mb到32Mb的显存，支持AGP2X/4X，支持32位渲染等等众多技术。nVidia能战胜Voodoo3，与3Dfx公司推行的策略迫使众多生产厂家投奔nVidia也不无关系，促进了TNT系列的推广。&lt;/p&gt;

&lt;p&gt;1999年，Matrox推出 MGA G400，它拥有16Mb/32Mb的显存容量，支持AGP 2X/4X，还有支持大纹理以及32位渲染等等，独特漂亮的EMBM硬件凹凸贴图技术，营造出的完美凹凸感并能实现动态光影效果的技术，并且G400拥有优秀的DVD回放能力，只是价格有些昂贵。通过双显示控制器（被Matrox称为DualHead）驱动两台显示器的能力开始了公司的多显示器支持趋势。&lt;/p&gt;

&lt;p&gt;1999年，nVidia终于爆发了，它在99年末推出了当前革命性的显卡—Geforce 256，彻底打败了3Dfx。代号NV10的GeForce 256支持Cube-Environment Mapping，完全的硬件T&amp;amp;L（Transform &amp;amp; Lighting），把原来有CPU计算的数据直接交给显示芯片处理，大大解放了CPU，也提高了芯片的运用效率。GeForce256拥有4条图形纹理通道，单周期每条通道处理两个象素纹理，工作频率120MHz，全速可以达到480Mpixels/Sec，支持SDRAM和DDR RAM，运用DDR的产品能更好的发挥GeForce256的性能。其不足之处就在于采纳使用了0.22纳米的工艺技术，发热量相对其它的来说很高的。&lt;/p&gt;

&lt;p&gt;2000年7月，3Dfx发布的Voodoo 5引入了T-buffer技术，作为变换和照明的一种替代方法，它基本上采用了一些渲染帧并将它们聚合为一个图像的方法。这产生了稍微模糊的图片，当按帧顺序运行时，可以平滑动画的运动。&lt;/p&gt;

&lt;p&gt;2000年末，3Dfx最终被nVidia收购。&lt;/p&gt;

&lt;h2 id=&quot;3d时代巅峰&quot;&gt;3D时代巅峰&lt;/h2&gt;

&lt;p&gt;2000年，ATI依仗T&amp;amp;L技术打开市场，在经历“曙光女神”的失败后，ATI推出了自己的T&amp;amp;L芯片RADEON 256。RADEON和NVIDIA一样具有高低端的版本，完全硬件T&amp;amp;L，Dot3和环境映射凹凸贴图，还有两条纹理流水线，可以相应情况下处理三种纹理。最出彩的是HYPER-Z技术，大大提高了RADEON显卡的3D速度，拉近了与GEFORCE 2系列的距离，ATI的显卡开始在市场占据主导地位。&lt;/p&gt;

&lt;p&gt;2000年4月，nVidia发布了GeForce 2 GTS（GigaTexel Shader），称为Nvidia Shading Rasterizer，它允许将高光阴影，体积爆炸，折射，波浪，顶点混合，阴影体积，凹凸贴图和高程贴图等效果应用于每个像素通过硬件的基础。&lt;/p&gt;

&lt;p&gt;2000年8月，ATI Radeon DDR上市。在卓越的T&amp;amp;L实现和对即将推出的DirectX 8特性的支持下，Radeon DDR与GeForce 2 GTS一起，通过将对接口的支持集成到芯片本身，引入了DVI输出的使用。&lt;/p&gt;

&lt;p&gt;2001年，nVidia推出的Geforce 3系列，这张卡成为了该领域的新王者，GeForce 3显卡增加了可编程T&amp;amp;L功能，可以对几乎所有的画面效果提供硬件支持。GeForce 3总共具有4条像素管道，填充速率最大限度可以达到每秒钟800 Mpixels。支持DirectX 8，多重采样AA，梅花AA（基本上是2xMSAA +后期处理模糊），8x各向异性滤光以及无与伦比的处理8xAF +三线性滤光的能力以及可编程的顶点着色器，用于更紧密地控制多边形网格运动和更流畅的动画序列。还有LMA(光速内存架构)支持——基本上是Nvidia的HyperZ版本——用于剔除隐藏在屏幕上其他像素后面的像素(Z遮挡剔除)，以及压缩和解压数据以优化带宽使用(Z压缩)。最后，Nvidia实现了负载平衡算法，将其称为Crossbar内存控制器，该控制器由四个独立的内存子控制器（与行业标准的单个控制器相对）组成，从而可以更有效地路由传入的内存请求。&lt;/p&gt;

&lt;p&gt;2001年，ATI则推出Radeon 8500/7500系列，采纳使用0.15微米工艺制造，包括6000万个晶体管，采纳使用了不少新技术(如Truform、Smartshader等)。并根据显卡的核心/显存工作频率分成不同的档次——核心/显存分别为275/550MHz的标准版，核心/显存为250/500MHz的RADEON 8500LE，生产核心/显存频率分别为300/600MHz的Ultra版，以及中端的Radeon 7500，低端的Radeon 7200，7000等产品。值得一提的是Radeon 8500还支持双头显示技术。&lt;/p&gt;

&lt;p&gt;2002年，ATI R300 GPU发布，由最初构成ArtX核心的团队开发，交付出色。它是第一个提供DirectX 9.0支持的应用程序，并且扩展了第一个支持着色器模型2.0，顶点着色器2.0和像素着色器2.0的体系结构。&lt;/p&gt;

&lt;p&gt;2002年，nVidia与ATI的竞争更加白热化。为巩固其图形芯片市场霸主的位，nVidia推出了Geforce 4系列，GeForce4 Ti系列择定确定是最具性能和价格比的，其代号是NV25，主要针对当时的高端图形市场，是DirectX 8时代下最劲爆强大的GPU图形处理器。芯片内部包含的晶体管数量高达6千3百万，运用0.15微米工艺生产，采纳使用了新的PBGA封装，运行频率达到了300MHz，配合频率为650MHz DDR显存，可以实现每秒49亿次的采样。GeForce4 Ti核心内建4条渲染流水线，每条流水线包含2个TMU（材质贴图单元）。Geforce 4系列从高到低，横扫了整个显卡市场。&lt;/p&gt;

&lt;p&gt;2002年，ATI推出R9700/9000/9500系列，首次支持DirectX 9，使其在与NVidia的竞争中抢得先机。同时R9700支持AGP 8X、DirectX 9，核心频率是300MHz，显存时钟是550MHz。RADEON 9700实现了可程序化的革命性硬件架构。符合AGP 8X最新标准，配有8个平等处理的渲染管线，每秒可处理25亿个像素，4个并列的几何处理引擎能处理每秒3亿个形迹及光效多边形。R9000则面向低端的产品，R9500则对标Ti4200。&lt;/p&gt;

&lt;p&gt;2003年的显卡市场依旧为N系与A系所统治。nVidia的Gf FX 5800（NV30）系列拥有32位着色，颜色画面有质的提高，在基础上推出的GeForce FX 5900，提高了晶体管数，降低了核心频率与显存频率，改用了256BIT DDR以提高显存带宽。&lt;/p&gt;

&lt;p&gt;2003年7月，nVidia推出了GF FX 5950/5700系列，以取代GF FX 5900/5600。新的Detonator FX驱动程序大大改善了AA和AF。
2003年9月，ATI推出了RADEON 9800/pro/SE/XT，依仗其超强的性能以及较低的售价，再次打败GF GX 5800。&lt;/p&gt;

&lt;p&gt;2004年是ATI大放异彩的一年，其最大的功臣却是来自于面向中低端的Radeon 9550。2004年最具性能和价格比的显卡，让ATI在低端市场呼风唤雨。R9550基于RV350核心，采纳使用0.13微米制程，核心频率为250MHz，显存频率为400MHz，4条渲染管道，1个纹理单元，相应情况下兼容64bit和128bit。&lt;/p&gt;

&lt;p&gt;2005年，Nvidia推出6000系列显卡，特性包括DirectX 9.0c支持、shader model 3.0(尽管显卡从未完全利用这一点)、Nvidia的PureVideo解码和播放引擎，以及SLI支持。&lt;/p&gt;

&lt;p&gt;2006年10月25日，ATI被AMD收购，总价为54亿美元。&lt;/p&gt;

&lt;p&gt;–&lt;/p&gt;

&lt;p&gt;NVIDIA发展表：&lt;/p&gt;

&lt;p&gt;1995年，NV1&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;50K triangles/sec
1M pixel ops/sec
1M transistors
16-bit color
Nearest filtering
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1997年，Riva 128 (NV3), DX3&lt;/p&gt;

&lt;p&gt;1998 – Riva TNT (NV4), DX5&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;32位颜色,
24位Z缓存,
8位模板缓存
双纹理,
双线性过滤
每时钟2像素 (2 ppc)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1999 - GeForce 256（NV10）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;固定管线，
支持DirectX 7.0
硬件T&amp;amp;L（Transform &amp;amp; lighting，坐标变换和光照）
立方体环境图（Cubemaps）
DOT3 – bump mapping
2倍各向异性过滤
三线性过滤
DXT纹理压缩
4ppc
引入“GPU”术语
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2001 - GeForce 3&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DirectX 8.0
Shader Model 1.0
可编程渲染管线
顶点着色器
像素着色器
3D纹理
硬件阴影图
8倍各向异性过滤
多采样抗锯齿（MSAA）
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2003 - GeForce FX系列（NV3x）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DirectX 9.0
Shader Model 2.0
256顶点操作指令
32纹理 + 64算术像素操作指令
512像素操作指令
着色语言：HLSL、CGSL、GLSL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2004 - GeForce 6系列 (NV4x)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DirectX 9.0c
Shader Model 3.0
动态流控制
分支、循环、声明等
顶点纹理读取
高动态范围（HDR）
64位渲染纹理（Render Target）
FP16*4 纹理过滤和混合
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2006 - GeForce 8系列 (G8x)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DirectX 10.0
Shader Model 4.0
几何着色器（Geometry Shaders）
没有上限位（No caps bits）
统一的着色器（Unified Shaders）
Vista系统全新驱动
基于GPU计算的CUDA问世
GPU计算能力以GFLOPS计量。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2010 - GeForce 405（GF119）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DirectX 11.0
曲面细分（Tessellation）
外壳着色器（Hull Shader）
镶嵌单元（tessellator）
域着色器（Domain Shader）
计算着色器（Compute Shader）
支持Stream Output
Shader Model 5.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;DirectX 11的渲染管线。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;多线程支持
改进的纹理压缩
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Shader Model 5.0&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;更多指令、存储单元、寄存器
面向对象着色语言
曲面细分
计算着色器
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2014 - GeForceGT 710（GK208）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DirectX 12.0
轻量化驱动层
硬件级多线程渲染支持
更完善的硬件资源管理
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2016 - GeForceGTX 1060 6GB&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;首次支持RTX和DXR技术，即光线追踪
引入RT Core（光线追踪核心）
支持RTX光线追踪的显卡列表
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2018 - TITAN RTX（TU102）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DirectX 12.1，OpenGL 4.5
6GPC，36TPC，72SM，72RT Core，...
8K分辨率，1770MHz主频，24G显存，384位带宽
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《GPU历史系列》&lt;/p&gt;

&lt;p&gt;https://new.qq.com/omn/20200506/20200506A0GP6H00.html?pc&lt;/p&gt;

&lt;p&gt;《GPU发展史》&lt;/p&gt;

&lt;p&gt;http://www.360doc.com/content/16/0607/16/30123241_565810074.shtml&lt;/p&gt;

&lt;p&gt;《显卡发展史1》&lt;/p&gt;

&lt;p&gt;http://www.360doc.com/content/20/0504/17/32196507_910185372.shtml&lt;/p&gt;

&lt;p&gt;《显卡发展史2》&lt;/p&gt;

&lt;p&gt;http://www.360doc.com/content/20/0504/17/32196507_910185435.shtml&lt;/p&gt;

&lt;p&gt;《显卡发展史3》&lt;/p&gt;

&lt;p&gt;http://www.360doc.com/content/20/0504/17/32196507_910187350.shtml&lt;/p&gt;

&lt;p&gt;《Making Sense of Smartphone Processors: The Mobile CPU/GPU Guide》&lt;/p&gt;

&lt;p&gt;https://www.techautos.com/2010/03/14/smartphone-processor-guide/&lt;/p&gt;

&lt;p&gt;《移动设备GPU架构知识汇总》&lt;/p&gt;

&lt;p&gt;https://zhuanlan.zhihu.com/p/112120206&lt;/p&gt;

&lt;p&gt;《针对移动端TBDR架构GPU特性的渲染优化》&lt;/p&gt;

&lt;p&gt;https://gameinstitute.qq.com/community/detail/123220&lt;/p&gt;

&lt;p&gt;《A look at the PowerVR graphics architecture: Tile-based rendering》&lt;/p&gt;

&lt;p&gt;https://www.imaginationtech.com/blog/a-look-at-the-powervr-graphics-architecture-tile-based-rendering/&lt;/p&gt;

&lt;p&gt;《A look at the PowerVR graphics architecture: Deferred rendering》&lt;/p&gt;

&lt;p&gt;https://www.imaginationtech.com/blog/the-dr-in-tbdr-deferred-rendering-in-rogue/&lt;/p&gt;

&lt;p&gt;《深入GPU硬件架构及运行机制》&lt;/p&gt;

&lt;p&gt;https://www.cnblogs.com/timlly/p/11471507.html&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU1ODY1ODY2NA==&amp;amp;mid=2247484981&amp;amp;idx=1&amp;amp;sn=b5199f84ed73d28916dbb9143eeeb992&amp;amp;chksm=fc226332cb55ea2417b89e499284ab3a552ce591caba09d637912306503e4b457ed45c2e1d2d&amp;amp;token=1023740201&amp;amp;lang=zh_CN#rd&quot;&gt;已发布在微信公众号上，点击跳转&lt;/a&gt;&lt;/p&gt;

</description>
               <pubDate>Mon, 08 Nov 2021 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2021/11/08/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B048</link>
               <guid isPermaLink="true">http://www.luzexi.com/2021/11/08/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B048</guid>
            </item>
        
            <item>
               <title>给女儿的信(十八) 面对困难时该如何去做</title>
               <description>&lt;p&gt;要点：&lt;/p&gt;

&lt;p&gt;遇到困难时，如果我们积极的去突破，则会让情况更加明朗，反之则会陷入消沉。&lt;/p&gt;

&lt;p&gt;结构：&lt;/p&gt;

&lt;p&gt;1.阐述与孩子们有一样的情景
2.举例遇到的困难，以及自己的行动
3.呼吁孩子们跟我一起勇敢的面对困难&lt;/p&gt;

&lt;p&gt;大纲：&lt;/p&gt;

&lt;p&gt;1.在练习演讲和表达后，自己的表达和公众说话能力有了些进步
2.开始原地踏步，甚至感觉有点倒退，很疑惑，也很难受
3.面对困难和困境的几种做法。
4.激励自己勇敢面对困难，积极寻找解决问题的途径和方法，专注提高解决问题的技巧。
5.鼓励孩子们跟我一起勇敢面对困难。&lt;/p&gt;

&lt;p&gt;内容：&lt;/p&gt;

&lt;p&gt;Hello Sharon, hello Annie.爸爸好想你们啊。爸爸喜欢你们。&lt;/p&gt;

&lt;p&gt;又到了一个月一次的视频时间了。
爸爸跟你们说说爸爸最近遇到的事情好不好？&lt;/p&gt;

&lt;p&gt;最近爸爸一直在练习演讲和表达，因为爸爸发现自己在表达跟上台演讲时。表达的不够清楚，有很多紧张感。&lt;/p&gt;

&lt;p&gt;于是爸爸就找了很多的资料去练习自己的表达，以及上台说话的能力，让自己不那么紧张，在表达时也表达得更清楚一些，让别人听得更容易一些。&lt;/p&gt;

&lt;p&gt;经过一段时间的练习以后，爸爸发现自己的表达能力提升了不少。爸爸很开心，经过练习了以后，爸爸自己的说话能力提高了。&lt;/p&gt;

&lt;p&gt;然后又过了一段时间，爸爸发现爸爸在原地停了，停留了好久。甚至感觉自己的表达能力以及演讲能力有点倒退。爸爸好难受，感到很困惑，心里也很难受，爸爸。前面学习到的技巧慢慢的又退化了，又没有进步了。&lt;/p&gt;

&lt;p&gt;于是爸爸在想，其实我们生活当中常常遇到这样跟那样的困难以及阻碍。每当爸爸遇到这种困难跟阻碍的时候，我该怎么去做才能解决这个困难，才能化解现在的困境呢？&lt;/p&gt;

&lt;p&gt;爸爸想到通常我们面对困难的时候总是会选择退缩和逃避。因为每个人都害怕未知的挑战和困难。&lt;/p&gt;

&lt;p&gt;但是退缩和逃避不仅仅没有解决问题，而且让问题变得更加糟糕。&lt;/p&gt;

&lt;p&gt;于是爸爸就在想，我可不可以积极的面对困难，当困难来临时，我要主动的去寻找解决问题的方法和途径，把自己的注意力专注于解决问题的技巧。&lt;/p&gt;

&lt;p&gt;比如说爸爸最近遇到的表达上无法进步的困难。爸爸先仔细观察了自己表达上的问题，发现爸爸在说话的时候老是用喉咙和脑袋去说话，这个让爸爸感觉到自己在喉咙震动的时候脑袋也在震动，说多了就感觉自己的脑袋嗡嗡的，自己的脑袋嗡嗡的就会让自己陷入一种晕眩的状态。&lt;/p&gt;

&lt;p&gt;于是爸爸就想让在想可不可以不用喉咙去发声，不用脑袋去发声，用腹部去发声，这样的话我在说话的时候用力的是腹部，而不是脑袋和喉咙，这个让我说话变得更加的简单，更加的轻松，不必费这么大的力气。&lt;/p&gt;

&lt;p&gt;爸爸也在慢慢的练习腹部说话，练习一段时间以后吧，就会有进步，那个时候爸爸就会又开心了。&lt;/p&gt;

&lt;p&gt;雪儿跟安妮要像爸爸一样跟爸爸一起勇敢的面对困难哦，当我们面对困难时，我们要专注于寻找解决困难的途径和方法，把注意力集中在解决问题的技巧上。改善我们的技巧。寻找解决问题的途径。这样困难就变得不困难了。&lt;/p&gt;

</description>
               <pubDate>Mon, 01 Nov 2021 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2021/11/01/%E7%BB%99%E5%A5%B3%E5%84%BF%E7%9A%84%E4%BF%A118</link>
               <guid isPermaLink="true">http://www.luzexi.com/2021/11/01/%E7%BB%99%E5%A5%B3%E5%84%BF%E7%9A%84%E4%BF%A118</guid>
            </item>
        
            <item>
               <title>给女儿的信(十七) 在挫折中前进</title>
               <description>&lt;p&gt;Hi, Sharon Annie, 爸爸好想你。&lt;/p&gt;

&lt;p&gt;爸爸跟你们说说，爸爸最近，的学习跟工作的状况好不好？&lt;/p&gt;

&lt;h2 id=&quot;要点&quot;&gt;要点：&lt;/h2&gt;

&lt;p&gt;爸爸最近遇到些挫折，但爸爸没有气馁，一直在想办法如何改善自己的技巧，下次不让它失败。&lt;/p&gt;

&lt;h2 id=&quot;结构&quot;&gt;结构：&lt;/h2&gt;

&lt;p&gt;观察到自己的表达能力比较弱
很难受也很困惑，不知道该怎么办
寻找练习的方法并练习
单一的练习方法很快无效了，寻找另一种练习方法
学习速度又变快了&lt;/p&gt;

&lt;h2 id=&quot;内容&quot;&gt;内容：&lt;/h2&gt;

&lt;p&gt;爸爸最近遇到一些挫折，爸爸没有气馁，一直在想办法，怎么去完善自己的技巧，来让这个事情进行的更顺利一些。&lt;/p&gt;

&lt;p&gt;爸爸观察到自己的表达能力比较弱。观察到自己的在表达的时候的逻辑不是非常清晰，再跟别人讲事情或者说我想表达我的意思的时候，别人经常听不懂我在讲什么，或者说要听好几遍才能听明白。&lt;/p&gt;

&lt;p&gt;甚至有时候，别人听了好几遍，也没有听明白，但是假装明白了，最后把事情搞得很糟糕。&lt;/p&gt;

&lt;p&gt;所以，爸爸想改进一下自己的表达能力，希望自己在跟别人说话的时候，能够更清楚的表达爸爸的想说的意思。&lt;/p&gt;

&lt;p&gt;爸爸有时候会讲故事给别人听。其实讲故事里有很多的技巧，爸爸对于这些技桥都不太了解，所以爸爸在跟别人讲故事的时候，我发现讲的不清楚也不精彩，原本一个很好的故事，被爸爸讲的非常烂。&lt;/p&gt;

&lt;p&gt;于是爸爸很困惑，很难受。我想清楚的表达自己的意思，也很想把故事讲好，把故事讲得更有趣。&lt;/p&gt;

&lt;p&gt;爸爸就从平常的练习开始寻找方法，我在每天的打卡中加入了一个练习，想在平时每天都练习一下，如何说好一个故事，如何去表达的更清楚。&lt;/p&gt;

&lt;p&gt;爸爸每天早上都给自己布置一个任务，练习绕口令，练习发音。绕口令和发音是嘴巴的肌肉最基础的运动部分，爸爸希望自己在嘴巴的肌肉上能够运用的更好一些。&lt;/p&gt;

&lt;p&gt;在这样不断的练习过程当中，爸爸进步速度不是非常快。这个让爸爸受到很大的挫折感，爸爸花了很多时间去练习，但是效果不好，爸爸很难受啊。&lt;/p&gt;

&lt;p&gt;于是爸爸想办法在改进练习的方式，因为爸爸知道只有改进了练习的方式才能让练习的效果更好，让爸爸的练习效率更高。&lt;/p&gt;

&lt;p&gt;于是爸爸换了几种方法，第1种方法是爸爸有目标的去练习，比如说，爸爸想先把自己的，嗯啊这个词这个发音给去掉，因为爸爸在说话的时候经常会说啊额嗯、这个、然后、这些、那些等等。爸爸想把这些填充词给去掉，称它为哼哈词。&lt;/p&gt;

&lt;p&gt;做的第1步目标就是把这些填充词，在说话的时候去掉，用别的方式去代替，爸爸用沉默的方式去代替这些词语，当爸爸想发，嗯跟R的时候，想说然后、这个、那个时，用沉默去代替。&lt;/p&gt;

&lt;p&gt;爸爸发现练习了一段时间以后有比较大的效果，很开心。&lt;/p&gt;

&lt;p&gt;接着，练习着练习着，爸爸又遇到了瓶瓶颈。第1种练习方式，变得没有效果了，又变得低效了。&lt;/p&gt;

&lt;p&gt;于是爸爸又换了一种方法。第2种方法，爸爸想让自己说话的语气放慢一些，这样爸爸说话的时候，别人接受到的信息就会更清楚一些，也能听得更懂一些。&lt;/p&gt;

&lt;p&gt;于是爸爸就每天跟自己说话，并且跟自己说话的时候给自己定一个主题。比如爸爸想说今天学习到了新的知识，我把学习到的新知识说给别人听，在说话的时候，我要故意放慢语气，慢慢说慢慢说，慢慢说的时候对方也接收的也很一些。&lt;/p&gt;

&lt;p&gt;就这样爸爸，每天想一个主题，围绕这个主题去说自己的故事，在说故事的时候让自己的语速放慢一些。&lt;/p&gt;

&lt;p&gt;过了一段时间，真的起了效果，爸爸的表达能力越来越好了，很开心噢。&lt;/p&gt;

&lt;p&gt;不断的更换方法去练习，去有目标的练习自己的技能。当我发现遇到瓶颈的时候去主动更换练习方式，这让爸爸的学习效率很高，提升的效果也非常好。&lt;/p&gt;

&lt;p&gt;爸爸很开心，在这样不断更换练习方式的过程当中，爸爸的学习能力越来越强了，学习速度也越来越快了，学习效率越来越高了，爸爸很开心哦，希望Sharon跟安妮，也跟爸爸一样，当发现自己的进步少的时候主动去更换自己的练习方式，当你发现自己的练习方式进步速度比较慢时，可能是因为你的练习方式有问题哦。&lt;/p&gt;

&lt;p&gt;爸爸爱你们哦，爸爸喜欢你们，爸爸爱你们，我们来一起加油。&lt;/p&gt;

</description>
               <pubDate>Fri, 29 Oct 2021 00:00:00 +0800</pubDate>
               <link>http://www.luzexi.com/2021/10/29/%E7%BB%99%E5%A5%B3%E5%84%BF%E7%9A%84%E4%BF%A117</link>
               <guid isPermaLink="true">http://www.luzexi.com/2021/10/29/%E7%BB%99%E5%A5%B3%E5%84%BF%E7%9A%84%E4%BF%A117</guid>
            </item>
        
    </channel>
</rss>