---
layout: post
status: publish
published: false
title: 《Unity3D高级编程之进阶主程》第六章，网络层(三)
description: "unity3d 高级编程 主程 network tcp udp"
excerpt_separator: ===
tags:
- 书籍著作
- Unity3D
- 前端技术
---


四．Unity3D如何实现UDP。
    在前面介绍了如何实现TCP socket，下面要介绍下UDP的实现方式。其实两者都是长链接的方式，很多地方都有相识之处，比如两者都需要连接和断开事件支撑，都需要做发送和接收队列缓存，都需要定义数据包协议格式，都需要加密和校验。
    好了，我们来说说，TCP有而UDP没有的，需要我们实现的吧。UDP和TCP相比，UDP基本就是TCP的阉割版本，很多TCP有的功能UDP都没有。相同的地方有，都是异步发送和接收，都需要多线程操作，发送和接收都需要缓冲队列，并且发送数据时都需要合并数据包。TCP有而UDP没有的地方是，UDP不会自己校验重发，丢包概率大，数据包接收顺序不确定，而且UDP本身没有连接断开检测机制，也没有连接确认机制。

    (连接确认机制)
UDP相比TCP要麻烦许多，TCP是连接的三次握手协议，相当于在连接过程中跟服务器协商后敲定我们已经建立了连接这个一致预期，而UDP是无状态链接，它并没有三次握手的协议，所以UDP连接其实是一厢情愿的，客户端并不知道是否真正连接成功了。

那么这样的话，我们就必须先知道我们是否连接成功这个问题了。能够判断连接成功与否是第一步，只有这样才能顺利得进行下面的数据收发操作。

怎么确认连接成功呢？

首先我们来看看TCP连接的三次握手是怎么做的。
1.  首先客户端向服务器发送一个数据包，里面包含了Seq=0的变量，表示当前发送数据包的序列号为0，也就是第一个数据包。
2.  服务器收到客户端的数据包后，发现Seq=0，说明是第一个包，用来确认连接的，于是给客户端也发送了一个数据包，包含了Seq=0，和Ack=1，表示服务器已经收到你的连接确认包了。
3.  客户端收到服务器给的回应数据包后，知道了服务器已经知道了我们已经建立连接，于是向服务器发送了一个数据包，里面包含了Seq=1，Ack=1，表示确认数据包已经收到，连接已经确认，开始发送数据。

这就是TCP的三次握手来确认连接的流程。在UDP下，并没有三次握手机制，但我们可以模仿TCP的形式来确认连接。不过第3次握手有点多余，可以省掉1次，改为2次握手。

首先在连接后，先暂停其他发送和接收任何其他数据，先向服务器发送一个特殊的数据包，代表连接确认信号的数据包，包内的数据仅仅是一个序列号Seq=0，或者不是序列号也可以，而是一个特殊的字段。当服务器受到这个特殊的数据包后，也回应一个特殊的数据包，里面同样是客户端能识别确认的连接确认信号。这样当客户端接收到时就说明，我发出去给服务器的连接确认数据包有了回应，又接收到了这个连接确认响应的数据包，表明连接已经成功建立。

实现UDP连接确认具体步骤（伪代码）：
1.  首先使用API建立UDP连接。
SvrEndPoint = new IPEndPoint(IPAddress.Parse(host), port);
UdpClient = new UdpClient(host, port);
UdpClient.Connect(SvrEndPoint);

2.  启动接收数据线程。
UdpClient.BeginReceive(ReceiveCallback, this);
void ReceiveCallback(IAsyncResult ar)
{
    Byte[] data = (mIPEndPoint == null) ?
        UdpClient.Receive(ref mIPEndPoint) :
        UdpClient.EndReceive(ar, ref mIPEndPoint);

    if (null != data)
        OnData(data);

    if (mUdpClient != null)
    {
        // try to receive again.
        mUdpClient.BeginReceive(ReceiveCallback, this);
    }
}

3.  发送连接确认数据包，并屏蔽其他发送和接收功能。
SendConnectRequest();
StopSendNormalPackage();
StopReceiveNormalPackage();

4.  等待接收连接确认数据包。
Void OnData(data)
{
     If( !IsConnected )
{
        If( IsConnectResponse(data) )
{
        OnEvent( Event.ConnectSuccess );
        IsConnected = true;
}
Return;
}
ProcessNormalData(data);

}

5.  连接确认包收到，确认连接成功建立。开启发送和接收数据包的功能。
Void ProcessNormalData(data)
{
    If( !IsConnected ) return;

    DealNetworkData(data);
}
    
    经过与服务器数据包的来回，我们已经可以确认连接已经成功建立了。

(断开连接判定机制)

断开连接的判定机制，也是用数据包来回的形式，不过不是单一一个数据包，而是长时间的心跳包的形式来做持续性的判断连接状态。

如何实现？
与TCP的心跳包类似。首先，我们要与服务器有个约定，每隔X秒（比如5秒）发送一个心跳数据包给服务器，这个客户端发送的心跳数据包里包含了一些客户端信息，包括ID，角色状态，设备信息等，包体不能太大，否则会就加重了宽带负担。当服务器收到心跳数据包时，也立刻回复一个心跳数据回应包，里面包含了，服务器当前时间，服务器当前状态等信息。当客户端收到此数据包时，说明连接尚在。但当客户端很久没有收到心跳数据回应包时，就表明，连接已经断开了，比如30秒没收到心跳包，可以判断连接已经断开。服务器也是一样操作，当没有收到心跳包很久，就表明客户端的连接已经断开。然后客户端就开启相应的重连程序，或重连提示以及步骤。
具体步骤如下：
1.  每隔X秒向服务器发送心跳数据包。
2.  服务器收到心跳数据包后回复心跳响应数据包。
3.  如果，客户端和服务器都很久没有收到心跳数据包，比如30秒，则判定连接断开。
4.  主动断开连接，客户端提示用户，或者重新创建连接，服务器则是处理与之相关数据的处理。

(数据包校验与重发机制)

前面说UDP相当于是TCP的阉割版，而最关键的阉割部分就是校验和重发机制。UDP没有自我校验和重发机制，导致数据包丢失不会自我检查而使得接收端对是否收到包的确定性不大，从而导致收到的顺序也不确定。
所以我们需要自己编写增加对数据的校验和重发机制，来确保数据的可靠性。

TCP有校验和重发机制，我们不妨模仿他的校验和重发机制，在UDP上使用。这样我们即有了UDP的速度，又有了TCP的可靠性。

我们先来看TCP是如何做数据包的校验和重发的。
关于Seq和Ack。Seq即Sequence Number，为源端（source）的发送序列号；Ack即Acknowledgment Number，为目的端（destination）的接收确认序列号。
1.  首先客户端向服务器发送数据包，里面包含Seq(sequence number)序列号为1，数据包大小为比如264。
2.  服务器收数据包后就知道了当前连接的这个数据包的序号为1，也就是连接后第一个数据包。于是向客户端发送了一个确认包，确认包中包含了客户端发给服务器的Seq=1，和Ack=264(客户端发过来的数据包的大小)，告诉客户端我服务器已经收到了你序列号为1，大小为264的数据包。
3.  当客户端再次发送数据包时，里面包含的Seq序列号为2，服务器接收到后向客户端发送确认包，确认包中，包含了 客户端的Seq为2 ，数据包大小比如136，当客户端收到确认包时，确认包里包含了Seq=2，和Ack=136，表示序列号为2的大小为136的数据包已经收到，就知道了Seq为2的数据包发送成功了。
4.  然后由服务器向客户端发送数据。服务器向客户端发送数据也是同样的方法和步骤。数据包中包含了服务器的Seq为1(如果是第一个数据包的话，其他的以此类推累加)，大小为586，客户端接收到服务器的数据包后，向服务器发送确认包，包中包含了服务器发过来的Seq=1和数据包大小Ack  = 586，服务器收到确认包后，就知道了Seq为1的数据包已经被成功接收。
若在规定的时间内收到响应Seq序列号和Ack，表明该报文发送成功，可以发送下一个报文Seq；否则重传（TCP Retransmitssion）。序列号确认机制是TCP可靠性传输的保障。
以上是数据包成功接收的情况。下面我们来看假设传输失败的情况。
1.  客户端向服务器发送数据包，数据包中包含Seq=1，并将此数据包推入到已经发送但还没有确认的队列里，服务器没有接收到数据，客户端X秒后发现并没有收到Seq为1的确认包，判定为Seq=1的数据包传输失败，从已经发送但未确认的数据包队列中取出Seq=1的数据包，重新发送。
2.  客户端向服务器发送了10个数据包，分别是Seq=1，2，3，4，5，6，7，8，9，10，其中有2，6，没有收到数据包。等待确认包超时后，对2，6进行重传。
3.  加快重传确认时间。客户端向服务器发送10个数据包，分别是Seq=1，2，3，4，5，服务器收到的包是1，3，4，5，当收到3时，发现2被跳过1次，当收到4时发现2被跳过2次，立刻启动2的重传，不在等确认超时，加快丢包重传速度。

https://blog.csdn.net/suiyuan19840208/article/details/22062657


（丢包问题分析）

UDP丢包多是很正常现象，这是UDP牺牲质量而提高速度的代价。
UDP丢包的原因很多，我们这里做个分析。

1.  接收端处理时间过长导致丢包：
调用recv方法接收端收到数据后，处理数据花了一些时间，处理完后再次调用recv方法，在这二次调用间隔里,发过来的包可能丢失。对于这种情况可以修改接收端，将包接收后存入一个缓冲区，然后迅速返回继续recv。或者使用前面提到的双队列机制，来缩短锁队列的时间，从而解放了处理包的时间和接收数据包的线程之间的冲突。

2.  发送的包巨大丢包：
虽然Send方法会帮你做大包切割成小包发送的事情，但包太大也不行。例如超过50K的一个udp包，不切割直接通过send方法发送也会导致这个包丢失。发送的包较大，超过接受者缓存导致丢包：包超过mtu size数倍，几个大的udp包可能会超过接收者的缓冲，导致丢包。这种情况需要切割成小包再逐个send。报文过大的问题，可以通过控制报文大小来解决，使得每个报文的长度小于MTU。以太网的MTU通常是1500 bytes，其他一些诸如拨号连接的网络MTU值为1280 bytes，如果使用speaking这样很难得到MTU的网络，那么最好将报文长度控制在1280 bytes以下。

3.  发送的包频率太快：
虽然每个包的大小都小于mtu size 但是频率太快，例如40多个mut size的包连续发送中间不sleep，也有可能导致丢包。这种情况可以通过建立Socket接收缓冲队列解决，和建立发送缓冲队列来解决，并且在发送频率过快的时候考虑Sleep作为时间间隔。很多人会不理解发送速度过快为什么会产生丢包，原因就是UDP的SendTo不会造成线程阻塞，也就是说，UDP的SentTo不会像TCP中的SendTo那样，直到数据完全发送才会return回调用函数，它不保证当执行下一条语句时数据是否被发送。（SendTo方法是异步的）这样，如果要发送的数据过多或者过大，那么在缓冲区满的那个瞬间要发送的报文就很有可能被丢失。至于对“过快”的解释，作者这样说：“A few packets a second are not an issue; hundreds or thousands may be an issue.”（一秒钟几个数据包不算什么，但是一秒钟成百上千的数据包就不好办了）。 要解决接收方丢包的问题很简单，首先要保证程序执行后马上开始监听（如果数据包不确定什么时候发过来的话），其次，要在收到一个数据包后最短的时间内重新回到监听状态，其间要尽量避免复杂的操作（比较好的解决办法是使用多线程回调机制）。
以上是UDP的实现细节，同时阐述了UDP的实现难点和注意点。具体可以参考，https://github.com/luzexi/Unity3D-UDP

五．  包的格式，xml，json, protobuf 以及自定义格式
XML

XML 指可扩展标记语言
XML 被设计用来传输和存储数据。
XML 的设计宗旨是传输数据，而非显示数据
XML 标签没有被预定义。您需要自行定义标签。
XML 被设计为具有自我描述性。
XML 是 W3C 的推荐标准

当我们看到 XML 标准突飞猛进的开发进度，以及大批的软件开发商采用这个标准的日新月异的速度时，真的是不禁感叹这真是令人叹为观止。
目前，XML 在 Web 中起到的作用不会亚于一直作为 Web 基石的 HTML。
XML 无所不在。XML 是各种应用程序之间进行数据传输的最常用的工具，并且在信息存储和描述领域变得越来越流行。

XML 使用简单的具有自我描述性的语法：
<?xml version="1.0" encoding="ISO-8859-1"?>
<note>
    <to>George</to>
    <from>John</from>
    <heading>Reminder</heading>
    <body>Don't forget the meeting!</body>
</note>
第一行是 XML 声明。它定义 XML 的版本 (1.0) 和所使用的编码 (ISO-8859-1 = Latin-1/西欧字符集)。
下一行描述文档的根元素（像在说：“本文档是一个便签”）：
<note>
接下来 4 行描述根的 4 个子元素（to, from, heading 以及 body）：
<to>George</to>
<from>John</from>
<heading>Reminder</heading>
<body>Don't forget the meeting!</body>
最后一行定义根元素的结尾：
</note>
从本例可以设想，该 XML 文档包含了 John 给 George 的一张便签。

所有 XML 元素都须有关闭标签
在 XML 中，省略关闭标签是非法的。所有元素都必须有关闭标签：
<p>This is a paragraph</p>
<p>This is another paragraph</p>  
注释：您也许已经注意到 XML 声明没有关闭标签。这不是错误。声明不属于XML本身的组成部分。它不是 XML 元素，也不需要关闭标签。

XML 标签对大小写敏感
XML 元素使用 XML 标签进行定义。
XML 标签对大小写敏感。在 XML 中，标签 <Letter> 与标签 <letter> 是不同的。
必须使用相同的大小写来编写打开标签和关闭标签：
<Message>这是错误的。</message>
<message>这是正确的。</message>

XML 必须正确地嵌套
在 XML 中，所有元素都必须彼此正确地嵌套：
<b><i>This text is bold and italic</i></b>
在上例中，正确嵌套的意思是：由于 <i> 元素是在 <b> 元素内打开的，那么它必须在 <b> 元素内关闭。

XML 文档必须有根元素
XML 文档必须有一个元素是所有其他元素的父元素。该元素称为根元素。
<root>
  <child>
    <subchild>.....</subchild>
  </child>
</root>

XML 的属性值须加引号
与 HTML 类似，XML 也可拥有属性（名称/值的对）。
在 XML 中，XML 的属性值须加引号。请研究下面的两个 XML 文档。第一个是错误的，第二个是正确的：
<note date=08/08/2008>
    <to>George</to>
    <from>John</from>
</note> 

<note date="08/08/2008">
    <to>George</to>
    <from>John</from>
</note> 
在第一个文档中的错误是，note 元素中的 date 属性没有加引号。

XML 中的注释
在 XML 中编写注释的语法与 HTML 的语法很相似：
<!-- This is a comment -->

JSON

JSON：JavaScript 对象表示法（JavaScript Object Notation）。
它是存储和交换文本信息的语法。类似 XML，但 比 XML 更小、更快，更易解析。

JSON 是轻量级的文本数据交换格式，它独立于语言，具有自我描述性，更易理解。
JSON 是纯文本，具有“自我描述性”（人类可读），具有层级结构（值中存在值）

相比 XML 的不同之处
没有结束标签
更短
读写的速度更快
能够使用内建的 JavaScript eval() 方法进行解析
使用数组
不使用保留字

JSON 语法规则：

JSON 数据的书写格式是：名称/值对。
名称/值对包括字段名称（在双引号中），后面写一个冒号，然后是值：
"firstName" : "John"

JSON数据由逗号分隔，它的值可以是：
数字（整数或浮点数）
字符串（在双引号中）
逻辑值（true 或 false）
数组（在方括号中）
对象（在花括号中）
null

JSON 对象在花括号中书写：
对象可以包含多个名称/值对：
{ "firstName":"John" , "lastName":"Doe" }

JSON 数组在方括号中书写：
数组可包含多个对象：
{
    "employees": [
        { "firstName":"John" , "lastName":"Doe" },
        { "firstName":"Anna" , "lastName":"Smith" },
        { "firstName":"Peter" , "lastName":"Jones" }
    ]
}

JSON 使用 JavaScript 语法
因为 JSON 使用 JavaScript 语法，所以无需额外的软件就能处理 JavaScript 中的 JSON。
通过 JavaScript，您可以创建一个对象数组，并像这样进行赋值：
例子
var employees = [
    { "firstName":"Bill" , "lastName":"Gates" },
    { "firstName":"George" , "lastName":"Bush" },
    { "firstName":"Thomas" , "lastName": "Carter" }
];
可以像这样访问 JavaScript 对象数组中的第一项：
employees[0].lastName;
返回的内容是：
Gates

可以像这样修改数据：
employees[0].lastName = "Jobs";

JSON 文件
JSON 文件的文件类型是 ".json"
JSON 文本的 MIME 类型是 "application/json" 
(MIME (Multipurpose Internet Mail Extensions) 是描述消息内容类型的因特网标准。MIME 消息能包含文本、图像、音频、视频以及其他应用程序专用的数据。)

JSON 解析器
JSON 解析器可以用些比较常用的，比如simpleJson，DataContractJsonSerializer，JArray，JObject等等，都是非常通用高效的插件。倘若有空的话那你也可以自己写一个解析和构造JSON的插件。

Protobuf

Google Protocol Buffer( 简称 Protobuf) 是 Google 公司内部的混合语言数据标准，目前已经正在使用的有超过 48,162 种报文格式定义和超过 12,183 个 .proto 文件。他们用于 RPC 系统和持续数据存储系统。

Protocol Buffers 是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化。它很适合做数据存储或 RPC 数据交换格式。可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。

Protobuf 的优点

Protobuf 有如 XML，不过它更小、更快、也更简单。你可以定义自己的数据结构，然后使用代码生成器生成的代码来读写这个数据结构。你甚至可以在无需重新部署程序的情况下更新数据结构。只需使用 Protobuf 对数据结构进行一次描述，即可利用各种不同语言或从各种不同数据流中对你的结构化数据轻松读写。
它有一个非常棒的特性，即“向后”兼容性好，人们不必破坏已部署的、依靠“老”数据格式的程序就可以对数据结构进行升级。这样您的程序就可以不必担心因为消息结构的改变而造成的大规模的代码重构或者迁移的问题。因为添加新的消息中的 field 并不会引起已经发布的程序的任何改变。
Protobuf 语义更清晰，无需类似 XML 解析器的东西（因为 Protobuf 编译器会将 .proto 文件编译生成对应的数据访问类以对 Protobuf 数据进行序列化、反序列化操作）。
使用 Protobuf 无需学习复杂的文档对象模型，Protobuf 的编程模式比较友好，简单易学，同时它拥有良好的文档和示例，对于喜欢简单事物的人们而言，Protobuf 比其他的技术更加有吸引力。

Protobuf 的不足

Protbuf 与 XML 相比也有不足之处。它功能简单，无法用来表示复杂的概念。
XML 已经成为多种行业标准的编写工具，Protobuf 只是 Google 公司内部使用的工具，在通用性上还差很多。
由于文本并不适合用来描述数据结构，所以 Protobuf 也不适合用来对基于文本的标记文档（如 HTML）建模。另外，由于 XML 具有某种程度上的自解释性，它可以被人直接读取编辑，在这一点上 Protobuf 不行，它以二进制的方式存储，除非你有 .proto 定义，否则你没法直接读出 Protobuf 的任何内容。

为什么使用Protocol Buffer？

我们的客户端程序是使用Java开发的，可能运行自不同的平台，如：Linux、Windows或者是Android，而我们的服务器程序通常是基于Linux平台并使用C++开发完成的。在这两种程序之间进行数据通讯时存在多种方式用于设计消息格式，如：

1. 直接传递C/C++语言中一字节对齐的结构体数据，只要结构体的声明为定长格式，那么该方式对于C/C++程序而言就非常方便了，仅需将接收到的数据按照结构体类型强行转换即可。事实上对于变长结构体也不会非常麻烦。在发送数据时，也只需定义一个结构体变量并设置各个成员变量的值之后，再以char*的方式将该二进制数据发送到远端。反之，该方式对于Java开发者而言就会非常繁琐，首先需要将接收到的数据存于ByteBuffer之中，再根据约定的字节序逐个读取每个字段，并将读取后的值再赋值给另外一个值对象中的域变量，以便于程序中其他代码逻辑的编写。对于该类型程序而言，联调的基准是必须客户端和服务器双方均完成了消息报文构建程序的编写后才能展开，而该设计方式将会直接导致Java程序开发的进度过慢。即便是Debug阶段，也会经常遇到Java程序中出现各种域字段拼接的小错误。

2. 使用SOAP协议(WebService)作为消息报文的格式载体，由该方式生成的报文是基于文本格式的，同时还存在大量的XML描述信息，因此将会大大增加网络IO的负担。又由于XML解析的复杂性，这也会大幅降低报文解析的性能。总之，使用该设计方式将会使系统的整体运行性能明显下降。
对于以上两种方式所产生的问题，Protocol Buffer均可以很好的解决，不仅如此，Protocol Buffer还有一个非常重要的优点就是可以保证同一消息报文新旧版本之间的兼容性。至于具体的方式我们将会在后续的博客中给出。

Protocol Buffer消息定义

创建扩展名为.proto的文件，如：MyMessage.proto，并将以下内容存入该文件中。
message LogonReqMessage {
  required int64 acctID = 1;
  required string passwd = 2;
}
这里将给出以上消息定义的关键性说明。
1. message是消息定义的关键字，等同于C#中的struct/class。
2. LogonReqMessage为消息的名字，等同于结构体名或类名。
3. required前缀表示该字段为必要字段，既在序列化和反序列化之前该字段必须已经被赋值。与此同时，在Protocol Buffer中还存在另外两个类似的关键字，optional和repeated，带有这两种限定符的消息字段则没有required字段这样的限制。相比于optional，repeated主要用于表示数组字段。具体的使用方式在后面的用例中均会一一列出。
4. int64和string分别表示长整型和字符串型的消息字段，在Protocol Buffer中存在一张类型对照表，既Protocol Buffer中的数据类型与其他编程语言(C#/Java/C++)中所用类型的对照。该对照表中还将给出在不同的数据场景下，哪种类型更为高效。该对照表将在后面给出。
5. acctID和passwd分别表示消息字段名，等同于C#中的域变量名，或是Java中的成员变量名。
6. 标签数字1和2则表示不同的字段在序列化后的二进制数据中的布局位置。在该例中，passwd字段编码后的数据一定位于acctID之后。需要注意的是该值在同一message中不能重复。另外，对于Protocol Buffer而言，标签值为1到15的字段在编码时可以得到优化，既标签值和类型信息仅占有一个byte，标签范围是16到2047的将占有两个bytes，而Protocol Buffer可以支持的字段数量则为2的29次方减一。有鉴于此，我们在设计消息结构时，可以尽可能考虑让repeated类型的字段标签位于1到15之间，这样便可以有效的节省编码后的字节数量。

含有枚举字段的Protocol Buffer消息

//在定义Protocol Buffer的消息时，可以使用和C#代码同样的方式添加注释。
enum UserStatus {
  OFFLINE = 0;  //表示处于离线状态的用户
  ONLINE = 1;   //表示处于在线状态的用户
}
message UserInfo {
  required int64 acctID = 1;
  required string name = 2;
  required UserStatus status = 3;
}
这里将给出以上消息定义的关键性说明（仅包括上一小节中没有描述的）。
1. enum是枚举类型定义的关键字，等同于C#中的enum。
2. UserStatus为枚举的名字。
3. 和C#中的枚举不同的是，枚举值之间的分隔符是分号，而不是逗号。
4. OFFLINE/ONLINE为枚举值。
5. 0和1表示枚举值所对应的实际整型值，和C#一样，可以为枚举值指定任意整型值，而无需总是从0开始定义。

含有嵌套消息字段的Protocol Buffer消息

我们可以在同一个.proto文件中定义多个message，这样便可以很容易的实现嵌套消息的定义。如：
enum UserStatus
{
    OFFLINE = 0;
    ONLINE = 1;
}
message UserInfo
{
    required int64 acctID = 1;
    required string name = 2;
    required UserStatus status = 3;
}
message LogonRespMessage
{
    required LoginResult logonResult = 1;
    required UserInfo userInfo = 2;
}
这里将给出以上消息定义的关键性说明（仅包括上两小节中没有描述的）。
1. LogonRespMessage消息的定义中包含另外一个消息类型作为其字段，如UserInfo userInfo。
2. 上例中的UserInfo和LogonRespMessage被定义在同一个.proto文件中，那么我们是否可以包含在其他.proto文件中定义的message呢？Protocol Buffer提供了另外一个关键字import，这样我们便可以将很多通用的message定义在同一个.proto文件中，而其他消息定义文件可以通过import的方式将该文件中定义的消息包含进来，如：
import "myproject/CommonMessages.proto"

限定符(required/optional/repeated)的基本规则

1. 在每个消息中必须至少留有一个required类型的字段。 
2. 每个消息中可以包含0个或多个optional类型的字段。
3. repeated表示的字段可以包含0个或多个数据。需要说明的是，这一点有别于C++/Java中的数组，因为后两者中的数组必须包含至少一个元素。
4. 如果打算在原有消息协议中添加新的字段，同时还要保证老版本的程序能够正常读取或写入，那么对于新添加的字段必须是optional或repeated。道理非常简单，老版本程序无法读取或写入新增的required限定符的字段。

Protocol Buffer消息升级原则

在实际的开发中会存在这样一种应用场景，既消息格式因为某些需求的变化而不得不进行必要的升级，但是有些使用原有消息格式的应用程序暂时又不能被立刻升级，这便要求我们在升级消息格式时要遵守一定的规则，从而可以保证基于新老消息格式的新老程序同时运行。规则如下：
1. 不要修改已经存在字段的标签号。
2. 任何新添加的字段必须是optional和repeated限定符，否则无法保证新老程序在互相传递消息时的消息兼容性。
3. 在原有的消息中，不能移除已经存在的required字段，optional和repeated类型的字段可以被移除，但是他们之前使用的标签号必须被保留，不能被新的字段重用。
4. int32、uint32、int64、uint64和bool等类型之间是兼容的，sint32和sint64是兼容的，string和bytes是兼容的，fixed32和sfixed32，以及fixed64和sfixed64之间是兼容的，这意味着如果想修改原有字段的类型时，为了保证兼容性，只能将其修改为与其原有类型兼容的类型，否则就将打破新老消息格式的兼容性。
5. optional和repeated限定符也是相互兼容的。

Protocol Buff C#工具

Protobuf-net

官方站点：http://code.google.com/p/protobuf-net/
Protobuf-net是第三方中最强大应用最广泛的一个，支持.Net、C#、WCF、VB，并且DEMO丰富，网上可查到的资料也最多。

生成.CS类文件
安装后通过 protogen.exe 就可将.proto文件生成.cs文件(Demo中我将命令封装在/tools/getCS.bat中)：
protogen -i:ProtoMyRequest.proto -o:ProtoMyRequest.cs
protogen -i:ProtoMyResponse.proto -o:ProtoMyResponse.cs
protogen -i:ProtoMyData.proto -o:ProtoMyData.cs
接着将生成的3个.cs文件包含在项目中，同时在项目中引用protobuf-net.dll

Protobuf-csharp-port

官方站点：http://code.google.com/p/protobuf-csharp-port/

Protobuf-csharp-port的文档资料、DEMO、应用范围都不如Protobuf-net，但Protobuf-csharp-port更遵循Google的Protobuf，甚至应用和代码都几乎一样，所以跨平台，Protobuf-csharp-port是不二之选。

生成.CS类文件

先直接使用Google的 protoc.exe 生成二进制文件。
然后通过 protogen.exe 将二进制文件生成C#类文件(Demo中我将命令封装在/tools/getCS.bat中)：

protoc --descriptor_set_out=ProtoMyRequest.protobin --include_imports ProtoMyRequest.proto
protoc --descriptor_set_out=ProtoMyResponse.protobin --include_imports ProtoMyResponse.proto
protoc --descriptor_set_out=ProtoMyData.protobin --include_imports ProtoMyData.proto

protogen ProtoMyRequest.protobin
protogen ProtoMyResponse.protobin
protogen ProtoMyData.protobin
接着将生成的3个.cs文件包含在项目中，同时在项目中引用Google.ProtocolBuffers.dll

六．  长连接和短连接的优缺点
（https://www.zhihu.com/question/39849641/answer/83774680）
tcp:
tcp的好处就是“可靠”，会将体积大的数据包进行分片，保证不会让ip协议进行分片。
会检测数据包是否丢包，丢包重传，有序地发送数据包等等，
坏处就是数据包头比较臃肿，至少有20+的字节（不要小看这20+字节),
在丢包重传时，会阻塞后面的数据包，而且tcp需要保持连接状态才能进行通讯，
在连接数较多时，服务器光在handle这些连接状态上就要消耗不少的性能。
题主所说的“长连接”应该指的是tcp socket，tcp socket是操作系统为tcp协议的实现（说白了就是操作系统为tcp提供的api) 

http: http处于应用层，是基于tcp的实现。它继承了tcp的所有优点。
跟tcp有些不同,http不会一直的保持连接状态，
在早期的http 1.0时期，http请求在得到响应后会立即断开连接，
这样就导致了每次的http请求都必须去进行tcp握手（在数据报文很小时，握手时间甚至会超过数据传送时间），
在1.1版本后使用同一个连接进行多次的http请求，在一段时间内没有再次进行http请求时，会自动断开，
这样就减轻了服务器维护大量链接所产生的开销问题，但是http是应用层，它会产生新的数据报头，在数据包的容量上会更大。

udp: udp 是“不可靠”的：不会丢包重传，会导致ip分片从而丢包，数据包不会按序送达，
只保证到达的包数据是完整的，它的好处就是,不会产生tcp丢包时的队列阻塞，
数据报头较小，只有8个字节，是一个无连接协议。

手游用什么协议？有啥优缺点
tcp：
优点就是tcp的功能太强大了，基本上没有tcp做不了的事，而且基于tcp的第三方库也非常多而且稳定，
开发起来比较顺心。但tcp的缺点也很多，数据报头有20+字节，在一些动作类游戏中，需要非常频繁地与服务器进行交互，
而且通常一个操作指令会很小（基本上都小于20个字节 :P),这就代表一半的带宽开销被用在了数据报头上。
其次就是tcp需要保持连接状态，这个在pc上可能不是问题，在手机上问题就大了。
手机信号不稳定，ios操作系统会将后台非特殊进程挂起，导致游戏断线需要断线重连，也就是重新登陆一次，
做过网游的同学都知道，游戏登陆操作对服务器的开销往往是最大的。
再一个就是tcp丢包重传的特性引起的，每次发送数据包需要check是否包已到达，
队列后的数据包需要等待前一个数据包成功发送后才能进行发送，这样会导致严重的lag，
在手机信号不好时尤为明显。由于大量的tcp连接会带来开销，基于tcp的游戏通常在线人数会有limit,
当然，使用分布式架构或者游戏滚服会解决掉这个问题（tcp分布式架构人人都会做，做的好不好，这个得看功力）。

http：
因为http不需要持续地保持连接，是一个无状态的连接，不会产生tcp所产生的断线重连的问题，
服务器也不需要维护过多的连接。缺点就是需要经常的进行tcp握手操作（不会影响玩家体验），
而且由于http的无状态性，通常游戏数据需要实时保存，不过现在的内存数据库 nosql的兴起和计算机性能的提升，这块劣势已经不存在，
而且越来越多的游戏都采用实时数据保存，防止游戏服务器宕机数据回档的风险。
再一个就是服务器无法主动向客户端推送数据，导致在某些功能上会无法实现。
由于http的无状态性，需要做心跳处理，基于http的游戏服务器可以横向扩展（每一个游戏服务器进程就是一个单纯的逻辑计算器），
数据库架构设计的好的话，一个游戏服很容易实现1亿+的玩家同服的情况。

udp：
优点就是“快”和“小”，udp不会产生tcp的数据包队列阻塞的问题，而且报头数据量很小，
在某些对速度和网络io量有较大要求的玩法时，这2个优点显得尤为重要，而且udp是无连接的，不会产生断线问题，也可以横向扩展。
缺点就是udp的不可靠性，一些实现可靠的udp协议的第三方库很少，而且往往满足不了自己项目的需求，所以要实现可靠的udp要自己动手造一遍轮子，
需要一定的网络基础知识和敢于踩坑的精神 。

推荐方案
方案1 ：完全使用udp，几个项目下来，觉得使用udp做手游服务端真的是perfect match。
没有断线问题，流量小，响应速度快。无奈手游环境开发商们心态比较浮躁，都以稳定来追求利益最大化，市面上完全使用udp的游戏非常少。 

方案2 ：http+udp，这种相对保守一些，逻辑相关的使用http协议，保证游戏逻辑不会出通讯上的问题，推送类的使用udp，
比如聊天，世界公告等等，这些就算你的udp协议写的烂，也不会产生严重问题。
如果实时性要求非常高的战斗功能，请使用udp。

方案 3：tcp+udp，这种方式为了加强连接的可靠性，tcp断了可以用udp继续游戏，两种连接来加强连接的可靠性。在手游MMORPG类型的长连接的游戏中更为合适。

七．  Unity3D的HTTP连接如何实现
短连接可以用.NET库来写，也可以用U3D的内置API的WWW来写。差别不是很大，大部分.NET库可以实现的，WWW也同样能够实现。区别主要还是WWW用协程做，.NET库用线程做，协程方便点，不用做锁的操作，线程麻烦点，要锁要队列要缓存。另外WWW里面已经实现了IP6转换，而使用 .Net则还需要自己解析IP6地址。

其实两边都要缓存和队列，如果没有缓存和队列，当数据量大时会出现很多问题。所以缓存机制在网络层是不可或缺的。

www也有post和get两种方式：
GET:
public WWW(string url); 
POST:
public WWW(string url, WWWForm form); 或
public WWW(string url, byte[] postData);
有时你需要发送head信息可以用
public WWW(string url, byte[] postData, Dictionary<string,string> headers);

最简单的就是设计个类，比如建个名称为HTTPRequest的类，每次请求服务器都调用这个类的方法来处理一个请求的操作。把地址，参数，回调传进去，等待服务器相应和回调。

短连接接口少，大概就是请求接口（包括，地址，参数，参数里包括，GET和POST，HEAD和BODY），回调接口，发生错误接口（错误包括超时，无响应，404，错误页面等）。只要做好这几个接口的封装基本就能搞定单个HTTP请求的组件需求。

接下来我们详细讲解下HTTP实现的几个关键点和难点，以及相关注意事项。这里以WWW为API来实现，核心部分的通信。

（基本发送与接收）
使用WWW发送接收很方便，可以用协程也可以在逻辑更新中进行判断收发过程。
在协程中不太可控，因为协程结束时随着函数调用结束而结束的，而我们需要时常暂停，继续等操作，协程确实不太方便。所以一般我都是把WWW的收发判断移到逻辑更新中Update里去的，这样做容易理解，也容易实现，更容易掌控。

下面是WWW的收发过程：
1.建立实例开始连接和发送请求www = new WWW( URL )，以及设置好，这次请求回应的回调句柄。
2.判断是否完成连接和发送请求，用www.isDone判断是否完成连接与发送。

伪码如下：
void StartRequest(string url, Callback _callback)
{
    www = new WWW(url);
    Callback =  _callback;
}

void Update()
{
    if(www != null)
    {
        if(www.isDone)
        {
            ProcessResponse(www);
            www.Despot();
            www = null;
}
}
}
3.处理数据，先判断有错误存在，如果不是则对数据进行处理，HTTP回应的数据都是文本数据，比如Json格式的，Xml格式的，等等。对数据进行解析后变为具体的类实例，再传给相应的函数句柄进行调用。所以这里数据格式协议也是关键。

void ProcessResponse(WWW _www)
{
    if(_www.error != null)
    {
        NetworkErrorReport(_www.error);
        return;
}
CallbackResponse(_www.text);
}

以上就是用WWW做HTTP请求的基本步骤。看似简单的连接，发送，接收过程，里面需要我们做的事情也不少。这里主要是针对，游戏逻辑中，大量多次，频繁发送HTTP请求的问题的延伸和提出的解决方案。

（多次或者连续发送HTTP请求引起的问题）
多次或者连续请求HTTP是很常见的操作，比如客户端向服务器请求角色信息，并且请求军团信息，并且请求每日任务信息，然后再显示主界面。这种连续的多次的请求HTTP，会同时触发请求线程想服务器做请求操作，而得到服务器返回时，却不知道哪个在先哪个在后，例如军团信息先得到响应，然后再是每日任务信息得到了响应，再是角色信息得到了响应，因为是多个线程发起的多个连接，所以并不能确定响应的顺序也是同请求的顺序是一样的，导致在显示主界面时需要花更多的逻辑去判断请求信息是否得到回应。
所以客户端更希望是，在多次请求发出后，收到的响应也是按原来请求的顺序响应的。所以我主张只开一个线程处理请求，用排队的方式处理请求和响应。

伪码如下：
void RequestHttp(string url)
{
    PushRequest(url);
}
void Update()
{
    If( IsHttpFinished() )
    {
        Request  req = PopRequest();
        StartHttpRequest(req);
}
Else
{
    WaitingforRequestProcess();
}
}

从伪码看出，所有请求都会被推入到队列中，然后当请求空闲时立即开始Http请求。这样就每次都只进行一次请求，请求完毕后再进行下一次，确保了请求顺序和回应顺序的一致性。
但是问题又出来了，每次只发送一个请求，导致请求的数量太多，时间间隔太大，效率不够，当你连续请求10个的时候，由于网络延迟，有可能会等3-5秒，这是让人无法接受的。就单单一个操作造成的10个连续请求能让人等这么久，那么如果操作多了或者频繁了，请求得到的响应就更加久了，需要等待的时间也更加长，导致游戏体验非常差。当然这是在网络状况差的情况下发生，一般情况都不会有延迟感觉。那么为了优化这个问题，我们可以对多个请求进行合并，比如我现在10个请求，合并成一个，响应的结果中包含了这10个请求的数据。这样就快了不少，因为请求减少了，原本10个请求，现在变成了一个，即使网络环境差，丢包需要重发，也只要重发单个数据包就可以了，而不是每丢一次重发一个。

以上在多次连续发送HTTP请求的情况下出现的问题，下面将详细介绍这些解决方案的细节。

（发送队列和接收队列）
队列在请求和响应中起到了缓冲的作用，当连续使用HTTP请求，连续收到HTTP响应的时候，能够依次处理相应的逻辑。
因为全程是在主线程里发生的，所以并不需要线程锁之类的操作。发送时，向队列推送请求实例，在逻辑更新时，判断是否有请求在队列里，有的话推出来，做HTTP请求操作，并将请求的相关信息存起来，当得到服务器响应时，调用请求信息中的回调函数，处理回调句柄。

发送请求伪码
void RequestHttp(Request req)
{
    ListRequest.Push(req);
}

void Update()
{
    If( IsHttpFinished() )
    {
        Request  req = ListRequest.Pop();
        mCurrentRequest = req;
        StartHttpRequest(req);
}
Else
{
    If( HttpIsDone())
{
    ProcessResponse(data);
}
}
}

void ProcessResponse(Response data)
{
    If(mCurrentRequest != null
&& mCurrentRequest.Callback != null)
    {
        mCurrentRequest.Callback(data);
}
}

以上阐述了，在发送HTTP请求时的推入队列操作和在收到请求后的句柄响应操作。

（加速请求与响应，压缩和减少发送次数）
每次发送一个请求，都要等待前面的数据包的回调后才能进行，当数据包频繁发送时，就容易引起巨量延迟的问题。

怎么办？
能不能加快响应速度？可以。压缩数据，以降低宽带使用率，减少丢包时重发的数据包大小，从而提高发送和接受的速度。

具体步骤挺简单的，就是找一个压缩算法，或者压缩组件，比如zip，LZMA等，客户端在发送请求钱，对发送的数据进行压缩，当服务器收到请求数据后，先对请求数据进行解压操作，然后再提取请求数据。客户端得到服务器响应请求的时候也是同样的步骤，先对响应数据进行解压，然后再对响应数据进行解析。

压缩的操作实现起来比较简单，但能得到的效果确实不那么好。因为关键的响应速度还是靠网络环境和服务器的响应时间，宽度的问题只是次要问题，没有网络环境和服务器响应速度的支持，光减少数据大小来提高响应速度，效果肯定让人失望。

能不能减少请求次数？可以，合并数据包，让多次发送的请求数据合并到一个包内，作为一次发送的数据包，相应时也是一样，多个相应数据包在同一个相应数据包内，分别做了客户端可识别的标记。

如何实现呢？
我们以json为例，客户端请求是json格式，服务器响应也是json格式。每次请求，客户端都会发送格式给服务器，服务器收到后解析json格式数据，然后提取变量。
我们在合并请求的时候可以这么做。多个json请求格式，推入一个大的json框中，为每个json数据加一个序列号，代表请求顺序，如下：

请求1
{
    "request-order" : 1,
    "data1" : "i am text",
    "data2" : "i am num",
}

请求2
{
    "request-order" : 2,
    "book" : "i am text",
    "chat" : "i am num",
    "level" : 1，
}

请求3
{
    "request-order" : 3,
    "image" : "i am text",
    "doc" : "i am num",
}

合并后
{
    "order" : 1,
    "data":
    [
        {
            "request-order" : 1,
            "data1" : "i am text",
            "data2" : "i am num",
        }
        ,
        {
            "request-order" : 2,
            "book" : "i am text",
            "chat" : "i am num",
            "level" : 1;
        }
        ,
        {
            "request-order" : 3,
            "image" : "i am text",
            "doc" : "i am num",
        }
    ],
}

合并后多个json被推入数组中发送给服务器，服务器拿到数据后对data中的数据进行提取和处理，处理顺序按照request-order来做，所有响应数据都被推入同一个json实例中，并且附上请求数据中的request-order，再把整个响应数据发送给客户端，当客户端收到数据时，就可以通过request-order知道响应数据的顺序了，再按照响应顺序进行解析和回调。

相应合例子如下。

响应数据1
{
    "response-order" : 1,
    "data1" : "i am text",
    "data2" : "i am num",
    "status" : "success", 
}

响应数据2
{
    "response-order" : 2,
    "data1" : "i am text",
    "data2" : "i am num",
    "status" : "success",
}

响应数据3
{
    "response-order" : 3
    "data1" : "i am text",
    "data2" : "i am num",
    "status" : "success",
}

合并响应数据
{
    "order" : 1,
    "data":
    [
        {
            "response-order" : 1,
            "data1" : "i am text",
            "data2" : "i am num",
            "status" : "success", 
        }
        ,
        {
            "response-order" : 2,
            "data1" : "i am text",
            "data2" : "i am num",
            "status" : "success",
        }
        ,
        {
            "response-order" : 3
            "data1" : "i am text",
            "data2" : "i am num",
            "status" : "success",
        }
    ]
}

合并响应数据后，客户端先提取data数据中的所有数据，先进行排序，以respose-order为基准，从小到大排序，最小的次序先处理，解析，回调。

整个过程就是这样的，对多个请求进行合并后，减少了不少HTTP请求的次数，对速度的提升也是很有效果的。这里还有一些细节问题，比如多少个开始进行合并，或者多少时间内合并一次。我的经验是，为了让HTTP最大效率的得到提升，每次请求得到响应后就应该立即进行下一次HTTP请求，不要有等待合并间隔，反而减低了连接效率。但每次合并数量可以做一些限制，比如有1000个请求，我们不能统统合并了，为了保证发送数据大小和回调数据大小合适，也保证服务器不会以下为了处理1000个数据请求而当机，我们必须限制合并的个数，比如每次最多合并10个请求数据包，来保证减少连接次数减少的情况下，服务器不会在瞬间压力过大。

（其他注意点）
其他注意点，比如数据的解析与回调，针对不同格式的数据解析的步骤也是不一样的，协议后对存储的回调函数进行调用。还有当需要多服务器操作时，需要增加可选择的服务器地址。还有数据超时的重发机制，比如重发3次还是超时，再做弹框的提醒等，都是具体项目中具体应用的逻辑。
可以参考，https://github.com/luzexi/Unity3DNetwork-http


八．  网络加密与压缩
短连接可以用md5前面的所有参数作为校验依据，防止篡改。
加密方式
支持IP6以符合苹果审核，用域名
九．  优化
*短连接用www，做队列，单任务作业，合并请求和回调(每个请求有编号，对应回调)
*长连接自己写，协议可以用protobuff，缩小协议长度
*短连接用md5，token验证参数正确性
*两边加密可以把公钥写在so文件里
*长连接自己写，做队列，锁，多任务作业